{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "import mlflow\n",
    "import mlflow.pytorch \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from pydicom.data import get_testdata_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    " # Import functions from the module\n",
    "import importlib\n",
    "import help_files._0_definitions \n",
    "import  help_files._1_visuals_script\n",
    "# import  help_files._01_load_data\n",
    " # Reload the module to apply the changes to the script\n",
    "importlib.reload(help_files._0_definitions)\n",
    "importlib.reload(help_files._1_visuals_script)\n",
    "# importlib.reload(help_files._01_load_data)\n",
    "import  help_files._1_visuals_script  as pauls_vs\n",
    "# Group by 'condition', 'level', and 'severity' and count occurrences\n",
    "from help_files._0_definitions import count_severity_by_condition_level \n",
    "# Define the path\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.width\", 1000)  # Set a large width to prevent line wrapping\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "### In definitions are all the functions that are used in the notebook and globals\n",
    "with open(\"help_files/_0_definitions.py\") as file:\n",
    "    exec(file.read())\n",
    "    ### In definitions are all the functions that are used in the notebook and globals\n",
    "with open(\"help_files/_0_run_definitions.py\") as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames have been loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "file_names = [\"train_df_3_cat.csv\", \"test_df_3_cat.csv\"]\n",
    "# Load the data from the CSV files\n",
    "dataframes = [pd.read_csv(data_path_vor / file_name) for file_name in file_names]\n",
    "# Unpack the dataframes into separate variables\n",
    "train_df, test_df = dataframes\n",
    "\n",
    "print(\"DataFrames have been loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the whole data set\n"
     ]
    }
   ],
   "source": [
    "# # end sample or small sample    \n",
    "if whole_data_set == True:\n",
    "    print(\"Using the whole data set\")\n",
    "else:\n",
    "    train_df = train_df.sample(n=300, random_state=RSEED)\n",
    "    test_df = test_df.sample(n=300, random_state=RSEED)\n",
    "    display(Markdown('<span style=\"color:red\"> this is a small sample : 48692</span>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calss definition dataloader (do not change over models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class MRILocalizationDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, has_coordinates=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (pd.DataFrame): DataFrame containing image paths and other info.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            has_coordinates (bool, optional): Whether the dataset includes x, y coordinates.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.has_coordinates = has_coordinates\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image path\n",
    "        img_path = self.data.iloc[idx]['image_path']\n",
    "        \n",
    "        # Read the DICOM file\n",
    "        dicom_image = pydicom.dcmread(img_path)\n",
    "        \n",
    "        # Convert the DICOM pixel data to a NumPy array\n",
    "        image_array = dicom_image.pixel_array\n",
    "        \n",
    "        # Convert NumPy array to PIL Image\n",
    "        image = Image.fromarray(image_array)\n",
    "        \n",
    "        # Convert to RGB if necessary (some DICOM files might be grayscale)\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "\n",
    "        # Apply transformations (e.g., resizing, normalization)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Return image with or without coordinates\n",
    "        if self.has_coordinates:\n",
    "            x = torch.tensor(self.data.iloc[idx]['x'], dtype=torch.float32)\n",
    "            y = torch.tensor(self.data.iloc[idx]['y'], dtype=torch.float32)\n",
    "            return image, torch.tensor([x, y])\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import models\n",
    "# %pip install keras\n",
    "# %pip install tensorflow\n",
    "# from tensorflow.keras.callbacks import EarlyStopping  # Import EarlyStopping\n",
    "import numpy as np  # Import numpy for setting the random seed\n",
    "\n",
    "# Define the transformation to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to the expected input size of the model\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "dataset = MRILocalizationDataset(data=train_df, transform=transform)\n",
    "\n",
    "# Split the dataset into training and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 64\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load ResNet-50 and set up for classification\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = train_df['severity'].nunique()\n",
    "\n",
    "model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss functions and optimizer\n",
    "learining_rate = 0.0001 \n",
    "criterion_cel = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learining_rate)\n",
    "num_epochs = 50\n",
    "# Early stopping parameters\n",
    "# Lists to store loss values for plotting\n",
    "train_losses_cel = []\n",
    "val_losses_cel = []\n",
    "\n",
    "# Early stopping parameters\n",
    "diverge_count = 0              # Counter for divergence-based stopping\n",
    "stop_threshold = 0.05           # Threshold for divergence\n",
    "max_diverge_count = 5         # Max number of epochs with diverging validation loss\n",
    "\n",
    "patience_counter = 0           # Counter for plateau-based stopping    \n",
    "patience = 6                 # Number of epochs for validation loss plateau\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "# Calculate number of layers in the model\n",
    "num_layers = len(list(model.children()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 84235.7098, Validation Loss: 83681.1234\n",
      "Epoch [2/50], Train Loss: 83023.2943, Validation Loss: 81403.3736\n",
      "Epoch [3/50], Train Loss: 82614.4420, Validation Loss: 84004.3596\n",
      "Epoch [4/50], Train Loss: 82262.2913, Validation Loss: 82896.3764\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the model, criterion, and optimizer are already defined\n",
    "# Assuming `train_loader` and `val_loader` are the DataLoader for training and validation sets\n",
    "\n",
    "# Define the criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Initialize variables to keep track of the best validation loss\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = \"best_model_weights_epoch_1.pt\"\n",
    "\n",
    "\n",
    "# Adjust the model's output layer to match the target tensor size\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # Output x and y coordinates\n",
    "\n",
    "# MLflow experiment setup\n",
    "experiment_name = \"MRI_Localization_ResNet50\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Training loop with MLflow tracking\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"learning_rate\", learining_rate)\n",
    "    mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"model_architecture\", \"ResNet-50 for Localization\")\n",
    "    mlflow.log_param(\"output_coordinates\", \"x, y\")\n",
    "\n",
    "    # Set descriptive tags for the model\n",
    "    mlflow.set_tag(\"model_description\", \"ResNet-50 for 3 classification and Sagittal T2/STIR and Sagittal T1 images\")\n",
    "\n",
    "    # Example input tensor with the same shape as the model's expected input\n",
    "    example_input = torch.randn(1, 3, 224, 224)  # Batch size 1, 3 color channels, 224x224 image\n",
    "\n",
    "\n",
    "    # Initialize lists to store loss values for plotting\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # Training phase\n",
    "        for images, coordinates in train_loader:\n",
    "            images, coordinates = images.to(device), coordinates.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, coordinates)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)  # Average training loss for the epoch\n",
    "        train_losses.append(train_loss)  # Store train loss for plotting\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():  # Disable gradient tracking for validation\n",
    "            for images, coordinates in val_loader:\n",
    "                images, coordinates = images.to(device), coordinates.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, coordinates)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)  # Average validation loss for the epoch\n",
    "        val_losses.append(val_loss)  # Store validation loss for plotting\n",
    "\n",
    "        # Log losses to MLflow\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Save the model at the current epoch\n",
    "        model_weight_path = f\"epoch_{epoch + 1}.pt\"\n",
    "        torch.save(model.state_dict(), model_weight_path)\n",
    "        mlflow.log_artifact(model_weight_path)  # Log the model weights artifact\n",
    "        os.remove(model_weight_path)  # Optionally delete local file after logging\n",
    "\n",
    "        # Check if validation loss improves and save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0  # Reset patience counter if validation loss improves\n",
    "            best_model_path = f\"best_model_weights_epoch_{epoch + 1}.pt\"\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            mlflow.log_artifact(best_model_path)  # Log the best model weights\n",
    "            os.remove(best_model_path)  # Optionally, delete the local file after logging\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} due to lack of validation loss improvement.\")\n",
    "                break\n",
    "\n",
    "        # Early stopping based on validation loss divergence (optional)\n",
    "        if val_loss > best_val_loss * (1 + stop_threshold):\n",
    "            diverge_count += 1\n",
    "            if diverge_count >= max_diverge_count:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} due to validation loss divergence.\")\n",
    "                break\n",
    "        else:\n",
    "            diverge_count = 0  # Reset diverge count if validation loss doesn't diverge\n",
    "\n",
    "\n",
    "        # Log final model\n",
    "    example_input_np = example_input.numpy()\n",
    "    mlflow.pytorch.log_model(model, \"final_model\", input_example=example_input_np)\n",
    "        \n",
    "\n",
    "    # Plot and log the loss curves as artifacts\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(num_epochs), train_losses, label='Train Loss')\n",
    "    plt.plot(range(num_epochs), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"loss_curve.png\")\n",
    "    mlflow.log_artifact(\"loss_curve.png\")  # Log the loss curve image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sssss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[166], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msssss\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sssss' is not defined"
     ]
    }
   ],
   "source": [
    "sssss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test predicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_df = test_df.drop(['severity', 'condition', 'level', 'series_id', 'missing_image'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  study_id                                            image_path\n",
      "2775207739  data/train_images_origin/2775207739/3249541180/8.dcm\n",
      " 664153360  data/train_images_origin/664153360/1076245514/13.dcm\n",
      "2273432465   data/train_images_origin/2273432465/114306451/9.dcm\n",
      "3777149998  data/train_images_origin/3777149998/3550597941/8.dcm\n",
      "3967802493 data/train_images_origin/3967802493/2054070341/11.dcm\n",
      "2780118855 data/train_images_origin/2780118855/2064060968/14.dcm\n",
      " 247968996   data/train_images_origin/247968996/256361821/14.dcm\n",
      " 957176622   data/train_images_origin/957176622/1889022706/1.dcm\n",
      "4075603869  data/train_images_origin/4075603869/2921580289/3.dcm\n",
      "3605654232    data/train_images_origin/3605654232/26446529/3.dcm\n",
      "1839242409 data/train_images_origin/1839242409/3211434109/13.dcm\n",
      " 779162887  data/train_images_origin/779162887/2596438821/18.dcm\n",
      " 886995462  data/train_images_origin/886995462/3051597267/16.dcm\n",
      "2348702073   data/train_images_origin/2348702073/323466396/5.dcm\n",
      "3550756125  data/train_images_origin/3550756125/2355159919/2.dcm\n",
      "1271819130  data/train_images_origin/1271819130/351635764/18.dcm\n",
      "3955843496 data/train_images_origin/3955843496/3438790057/15.dcm\n",
      " 707927308   data/train_images_origin/707927308/3971759912/9.dcm\n",
      "2139209036 data/train_images_origin/2139209036/2276017852/11.dcm\n",
      " 885579922  data/train_images_origin/885579922/2120705955/10.dcm\n",
      "1028909382  data/train_images_origin/1028909382/1477339972/3.dcm\n",
      "2826913245  data/train_images_origin/2826913245/819860127/10.dcm\n",
      "1750070978 data/train_images_origin/1750070978/1851892747/10.dcm\n",
      "1461368679 data/train_images_origin/1461368679/2332227383/18.dcm\n",
      "3640325492 data/train_images_origin/3640325492/1951216919/17.dcm\n",
      "3912497560 data/train_images_origin/3912497560/2827806606/10.dcm\n",
      "1278694021   data/train_images_origin/1278694021/896910489/5.dcm\n",
      "3053259969 data/train_images_origin/3053259969/1052790448/14.dcm\n",
      "3355993164 data/train_images_origin/3355993164/3005686985/11.dcm\n",
      "2162304486  data/train_images_origin/2162304486/278619831/10.dcm\n",
      "4136088296   data/train_images_origin/4136088296/25009550/12.dcm\n",
      "3053259969 data/train_images_origin/3053259969/1052790448/17.dcm\n",
      " 676719753    data/train_images_origin/676719753/60239014/12.dcm\n",
      "2888359875  data/train_images_origin/2888359875/1229482953/9.dcm\n",
      "2683615288  data/train_images_origin/2683615288/1060438383/1.dcm\n",
      "3485457199 data/train_images_origin/3485457199/3404943724/14.dcm\n",
      " 953639220   data/train_images_origin/953639220/270540558/18.dcm\n",
      "3762703235 data/train_images_origin/3762703235/3997674421/10.dcm\n",
      " 945809437   data/train_images_origin/945809437/1112017435/5.dcm\n",
      "3966998094 data/train_images_origin/3966998094/3899055711/15.dcm\n",
      "1666392091 data/train_images_origin/1666392091/3894977345/18.dcm\n",
      "4029974537 data/train_images_origin/4029974537/2765384875/19.dcm\n",
      "1164861071 data/train_images_origin/1164861071/3163330218/13.dcm\n",
      " 603095830    data/train_images_origin/603095830/77460261/10.dcm\n",
      "3625799781 data/train_images_origin/3625799781/1297988885/14.dcm\n",
      "3924490793  data/train_images_origin/3924490793/2841709587/3.dcm\n",
      "2758707424 data/train_images_origin/2758707424/2525570429/19.dcm\n",
      "3853089836   data/train_images_origin/3853089836/876411051/6.dcm\n",
      "1868615696 data/train_images_origin/1868615696/1304954941/22.dcm\n",
      " 434488359    data/train_images_origin/434488359/152760150/9.dcm\n",
      "2696451534  data/train_images_origin/2696451534/1846537274/2.dcm\n",
      "3922074884 data/train_images_origin/3922074884/1915960810/17.dcm\n",
      "4098077002  data/train_images_origin/4098077002/3387230519/2.dcm\n",
      " 704573554  data/train_images_origin/704573554/1699734064/17.dcm\n",
      " 473465726  data/train_images_origin/473465726/2791294349/10.dcm\n",
      "2006700205  data/train_images_origin/2006700205/2889256302/5.dcm\n",
      "3473524025  data/train_images_origin/3473524025/1697065269/5.dcm\n",
      " 991026205   data/train_images_origin/991026205/1652078757/6.dcm\n",
      " 960760926   data/train_images_origin/960760926/3244075592/8.dcm\n",
      "2966999234   data/train_images_origin/2966999234/721342892/7.dcm\n",
      "1524089207 data/train_images_origin/1524089207/2330513520/10.dcm\n",
      "1904225580 data/train_images_origin/1904225580/3345088118/10.dcm\n",
      "1020394063  data/train_images_origin/1020394063/1523561649/6.dcm\n",
      "3832874334  data/train_images_origin/3832874334/3671717022/9.dcm\n",
      " 734370379   data/train_images_origin/734370379/1655908293/8.dcm\n",
      "3457755755  data/train_images_origin/3457755755/776752953/13.dcm\n",
      "2839406005 data/train_images_origin/2839406005/3923297118/15.dcm\n",
      "1618233546  data/train_images_origin/1618233546/2816981416/5.dcm\n",
      "1721321525  data/train_images_origin/1721321525/3544091430/2.dcm\n",
      "3148156510 data/train_images_origin/3148156510/4209426235/10.dcm\n",
      "3817394595   data/train_images_origin/3817394595/990175634/6.dcm\n",
      "1205664021  data/train_images_origin/1205664021/3886228128/8.dcm\n",
      "2915096892 data/train_images_origin/2915096892/2140831218/10.dcm\n",
      "1408642922  data/train_images_origin/1408642922/679345222/18.dcm\n",
      "4106450023 data/train_images_origin/4106450023/3559440209/13.dcm\n",
      "3955843496  data/train_images_origin/3955843496/3438790057/8.dcm\n",
      " 159721286   data/train_images_origin/159721286/4204680939/1.dcm\n",
      " 377474930  data/train_images_origin/377474930/2668009971/10.dcm\n",
      " 492697281  data/train_images_origin/492697281/1667589476/18.dcm\n",
      "2501638175  data/train_images_origin/2501638175/477334578/14.dcm\n",
      "4271960965  data/train_images_origin/4271960965/2901066339/1.dcm\n",
      "3693117342   data/train_images_origin/3693117342/826409966/6.dcm\n",
      "4287160193  data/train_images_origin/4287160193/1507070277/3.dcm\n",
      " 395898502   data/train_images_origin/395898502/317903133/17.dcm\n",
      "3892114403 data/train_images_origin/3892114403/4017753326/10.dcm\n",
      "1768692511 data/train_images_origin/1768692511/1766321945/11.dcm\n",
      " 416521027   data/train_images_origin/416521027/2597582307/8.dcm\n",
      "3688443239  data/train_images_origin/3688443239/1061884431/9.dcm\n",
      "1302135990  data/train_images_origin/1302135990/3397821355/9.dcm\n",
      "1205664021   data/train_images_origin/1205664021/572344680/2.dcm\n",
      "2504110412  data/train_images_origin/2504110412/3125592759/1.dcm\n",
      "3326102488  data/train_images_origin/3326102488/4089227912/1.dcm\n",
      " 769420103  data/train_images_origin/769420103/1847227775/14.dcm\n",
      "3836739612  data/train_images_origin/3836739612/401031234/17.dcm\n",
      " 642715533  data/train_images_origin/642715533/2855523941/14.dcm\n",
      "1246626043   data/train_images_origin/1246626043/27170521/18.dcm\n",
      "3853089836 data/train_images_origin/3853089836/3151879788/14.dcm\n",
      "4262145542 data/train_images_origin/4262145542/4276471335/14.dcm\n",
      "1353517692 data/train_images_origin/1353517692/1762986309/15.dcm\n",
      "2794192602  data/train_images_origin/2794192602/1829533928/2.dcm\n",
      " 711877989   data/train_images_origin/711877989/1051517571/6.dcm\n",
      "3279376183   data/train_images_origin/3279376183/792897358/3.dcm\n",
      "4000809387  data/train_images_origin/4000809387/3804393004/4.dcm\n",
      "3691609865  data/train_images_origin/3691609865/124455970/10.dcm\n",
      "3163594538  data/train_images_origin/3163594538/2752448967/2.dcm\n",
      "3828017267  data/train_images_origin/3828017267/3343226405/1.dcm\n",
      "   4646740    data/train_images_origin/4646740/3486248476/16.dcm\n",
      "2293787755  data/train_images_origin/2293787755/2466237048/8.dcm\n",
      "2986835162 data/train_images_origin/2986835162/2483725214/13.dcm\n",
      "2318756258  data/train_images_origin/2318756258/416072674/20.dcm\n",
      "1677607138  data/train_images_origin/1677607138/305773513/12.dcm\n",
      "1850731145  data/train_images_origin/1850731145/1725330889/3.dcm\n",
      "1897045431   data/train_images_origin/1897045431/379237928/2.dcm\n",
      "2048265504  data/train_images_origin/2048265504/2998592741/3.dcm\n",
      " 480042730  data/train_images_origin/480042730/2250935329/16.dcm\n",
      "3234424112  data/train_images_origin/3234424112/3240624272/9.dcm\n",
      "3270195628  data/train_images_origin/3270195628/2954527433/6.dcm\n",
      "3426183113   data/train_images_origin/3426183113/776968358/9.dcm\n",
      "2361533111 data/train_images_origin/2361533111/4175535573/14.dcm\n",
      "1143931807  data/train_images_origin/1143931807/1437031388/2.dcm\n",
      "1408642922  data/train_images_origin/1408642922/2290485467/9.dcm\n",
      " 976356113   data/train_images_origin/976356113/2133623285/7.dcm\n",
      "3029953735 data/train_images_origin/3029953735/3791383775/17.dcm\n",
      "1425679446  data/train_images_origin/1425679446/3623899442/2.dcm\n",
      "4171095315 data/train_images_origin/4171095315/3978956866/19.dcm\n",
      "1205664021   data/train_images_origin/1205664021/572344680/5.dcm\n",
      "3154638975  data/train_images_origin/3154638975/2052598012/7.dcm\n",
      "3485457199  data/train_images_origin/3485457199/3404943724/1.dcm\n",
      " 404602713  data/train_images_origin/404602713/2886229355/10.dcm\n",
      "1504031267  data/train_images_origin/1504031267/2784380684/9.dcm\n",
      "3674684193 data/train_images_origin/3674684193/3473821253/12.dcm\n",
      "3824720894 data/train_images_origin/3824720894/4259273683/12.dcm\n",
      "2509066997 data/train_images_origin/2509066997/4048077433/10.dcm\n",
      "1115952008   data/train_images_origin/1115952008/469758184/1.dcm\n",
      "2325650566    data/train_images_origin/2325650566/20477869/3.dcm\n",
      "1827243377  data/train_images_origin/1827243377/3474567852/3.dcm\n",
      "1545888499 data/train_images_origin/1545888499/2917369652/18.dcm\n",
      "2181005070 data/train_images_origin/2181005070/3498146795/10.dcm\n",
      "4244186396 data/train_images_origin/4244186396/3091810859/13.dcm\n",
      "1190473557 data/train_images_origin/1190473557/3244338661/15.dcm\n",
      "3902887884  data/train_images_origin/3902887884/4282493649/8.dcm\n",
      "3528463452  data/train_images_origin/3528463452/3329373458/7.dcm\n",
      "3368217301  data/train_images_origin/3368217301/847395792/12.dcm\n",
      "2719549572 data/train_images_origin/2719549572/2374987445/18.dcm\n",
      "3068678959  data/train_images_origin/3068678959/4149292781/8.dcm\n",
      " 329807127    data/train_images_origin/329807127/386603676/9.dcm\n",
      "2399492744  data/train_images_origin/2399492744/1942345627/9.dcm\n",
      "1879696087 data/train_images_origin/1879696087/3230157587/10.dcm\n",
      " 492697281  data/train_images_origin/492697281/1667589476/14.dcm\n",
      "4078163716 data/train_images_origin/4078163716/2504629441/14.dcm\n",
      "2986835162    data/train_images_origin/2986835162/78752398/5.dcm\n",
      "1820866003  data/train_images_origin/1820866003/131094096/10.dcm\n",
      "2484590654  data/train_images_origin/2484590654/2607944761/1.dcm\n",
      "3880626718 data/train_images_origin/3880626718/1310605220/20.dcm\n",
      "1395246421  data/train_images_origin/1395246421/763239197/13.dcm\n",
      " 178041181   data/train_images_origin/178041181/2495441739/5.dcm\n",
      "1459284649  data/train_images_origin/1459284649/1104843171/8.dcm\n",
      "2713141511 data/train_images_origin/2713141511/3771041996/11.dcm\n",
      " 933559951  data/train_images_origin/933559951/2039681347/11.dcm\n",
      "4163587601  data/train_images_origin/4163587601/133519848/20.dcm\n",
      "2512945281  data/train_images_origin/2512945281/2701329062/5.dcm\n",
      "1008446160  data/train_images_origin/1008446160/2539455828/5.dcm\n",
      "2530679352 data/train_images_origin/2530679352/3989445153/14.dcm\n",
      "1698156042 data/train_images_origin/1698156042/1349877419/16.dcm\n",
      "1012375618  data/train_images_origin/1012375618/352098527/13.dcm\n",
      "   4003253      data/train_images_origin/4003253/702807833/3.dcm\n",
      "3362072295 data/train_images_origin/3362072295/3414299110/17.dcm\n",
      " 886995462   data/train_images_origin/886995462/1238593879/9.dcm\n",
      "1367470327  data/train_images_origin/1367470327/2618650591/5.dcm\n",
      "1212932624 data/train_images_origin/1212932624/4275546294/14.dcm\n",
      "3442533162  data/train_images_origin/3442533162/978923687/10.dcm\n",
      "3207960359  data/train_images_origin/3207960359/4029680789/8.dcm\n",
      "2881985242 data/train_images_origin/2881985242/2304209248/10.dcm\n",
      "1901348744 data/train_images_origin/1901348744/1490272456/10.dcm\n",
      "2097856420  data/train_images_origin/2097856420/2151902888/1.dcm\n",
      "2053213309  data/train_images_origin/2053213309/2972736368/5.dcm\n",
      "2066619590  data/train_images_origin/2066619590/3183444321/5.dcm\n",
      "1460690973  data/train_images_origin/1460690973/301524229/16.dcm\n",
      "3426816011   data/train_images_origin/3426816011/918923835/6.dcm\n",
      "2053506490   data/train_images_origin/2053506490/774221508/6.dcm\n",
      "2266719355 data/train_images_origin/2266719355/3763942448/12.dcm\n",
      "1676531728 data/train_images_origin/1676531728/3775504232/14.dcm\n",
      "1115481506  data/train_images_origin/1115481506/3168836041/7.dcm\n",
      "2348702073   data/train_images_origin/2348702073/323466396/1.dcm\n",
      "4255570773 data/train_images_origin/4255570773/3722788142/11.dcm\n",
      "4058604433 data/train_images_origin/4058604433/2135474355/10.dcm\n",
      "3495818564   data/train_images_origin/3495818564/856763877/6.dcm\n",
      " 106310815  data/train_images_origin/106310815/2473102710/15.dcm\n",
      "2540057310  data/train_images_origin/2540057310/3139146894/6.dcm\n",
      "2097856420 data/train_images_origin/2097856420/3505847202/17.dcm\n",
      " 933831851   data/train_images_origin/933831851/4191352206/3.dcm\n",
      "3128795155  data/train_images_origin/3128795155/483456514/13.dcm\n",
      "4259049254 data/train_images_origin/4259049254/1207877860/16.dcm\n",
      " 296314829   data/train_images_origin/296314829/3463650248/9.dcm\n",
      " 395898502    data/train_images_origin/395898502/369410970/1.dcm\n",
      "2597785056  data/train_images_origin/2597785056/266375569/10.dcm\n",
      "2728988942  data/train_images_origin/2728988942/632466427/12.dcm\n",
      "2008315239  data/train_images_origin/2008315239/754564873/14.dcm\n",
      "1505795551  data/train_images_origin/1505795551/2733545907/1.dcm\n",
      "4137194670   data/train_images_origin/4137194670/687903591/6.dcm\n",
      "2622319181 data/train_images_origin/2622319181/3373306398/16.dcm\n",
      "2872050745   data/train_images_origin/2872050745/766394136/3.dcm\n",
      " 189360935    data/train_images_origin/189360935/122094537/1.dcm\n",
      " 455813081   data/train_images_origin/455813081/2426521082/5.dcm\n",
      "3218815255  data/train_images_origin/3218815255/1342304074/5.dcm\n",
      "4123124185    data/train_images_origin/4123124185/95582042/2.dcm\n",
      "3650821463  data/train_images_origin/3650821463/2242247794/9.dcm\n",
      "1378385941  data/train_images_origin/1378385941/2729244584/1.dcm\n",
      "2565951228  data/train_images_origin/2565951228/4221884084/9.dcm\n",
      "2139209036   data/train_images_origin/2139209036/504942023/6.dcm\n",
      "1012375618  data/train_images_origin/1012375618/4014890929/5.dcm\n",
      "1763343402 data/train_images_origin/1763343402/4240004400/11.dcm\n",
      "1526636609 data/train_images_origin/1526636609/1497385254/12.dcm\n",
      "   8785691      data/train_images_origin/8785691/481125819/5.dcm\n",
      "3732627030   data/train_images_origin/3732627030/23479552/14.dcm\n",
      " 924259603   data/train_images_origin/924259603/107861764/18.dcm\n",
      " 783154228   data/train_images_origin/783154228/3342733127/5.dcm\n",
      "2297295777  data/train_images_origin/2297295777/2376943158/1.dcm\n",
      "2621647501 data/train_images_origin/2621647501/3531341578/12.dcm\n",
      "2607462358  data/train_images_origin/2607462358/384543934/13.dcm\n",
      "2911725373   data/train_images_origin/2911725373/205579604/2.dcm\n",
      " 983365930    data/train_images_origin/983365930/751248046/1.dcm\n",
      "4057365107 data/train_images_origin/4057365107/1903217931/12.dcm\n",
      "1460690973  data/train_images_origin/1460690973/301524229/18.dcm\n",
      "2435837923  data/train_images_origin/2435837923/2566229687/5.dcm\n",
      "1246626043   data/train_images_origin/1246626043/677585315/9.dcm\n",
      "3719530586   data/train_images_origin/3719530586/194470896/7.dcm\n",
      "2510853598   data/train_images_origin/2510853598/557949762/3.dcm\n",
      "3218815255 data/train_images_origin/3218815255/2385755271/10.dcm\n",
      "1536303104   data/train_images_origin/1536303104/650362227/2.dcm\n",
      " 123154253  data/train_images_origin/123154253/2257413721/20.dcm\n",
      "1525303131  data/train_images_origin/1525303131/1885363841/8.dcm\n",
      "2839406005   data/train_images_origin/2839406005/551025985/5.dcm\n",
      "3749556667 data/train_images_origin/3749556667/1440069870/13.dcm\n",
      "1271033295 data/train_images_origin/1271033295/2054979604/16.dcm\n",
      "2797118205  data/train_images_origin/2797118205/1974847306/1.dcm\n",
      " 206642334  data/train_images_origin/206642334/3618533469/10.dcm\n",
      "  60612428   data/train_images_origin/60612428/2349970136/11.dcm\n",
      "2162304486  data/train_images_origin/2162304486/278619831/17.dcm\n",
      "2540057310   data/train_images_origin/2540057310/821488018/2.dcm\n",
      "  52397721   data/train_images_origin/52397721/2452297573/10.dcm\n",
      "3934148010  data/train_images_origin/3934148010/668512855/14.dcm\n",
      "3521369408  data/train_images_origin/3521369408/3910483650/3.dcm\n",
      "1927301799  data/train_images_origin/1927301799/1853929267/8.dcm\n",
      "2109263401   data/train_images_origin/2109263401/92738066/16.dcm\n",
      "  11340341   data/train_images_origin/11340341/2231042680/18.dcm\n",
      " 198104941   data/train_images_origin/198104941/3000797596/9.dcm\n",
      "1558814835 data/train_images_origin/1558814835/3045931836/11.dcm\n",
      "1812153363  data/train_images_origin/1812153363/242672591/12.dcm\n",
      "3185333113  data/train_images_origin/3185333113/2772176740/2.dcm\n",
      "1897045431  data/train_images_origin/1897045431/2252871935/5.dcm\n",
      "1546104377  data/train_images_origin/1546104377/897561121/14.dcm\n",
      " 428900736   data/train_images_origin/428900736/193312628/16.dcm\n",
      "3848110185  data/train_images_origin/3848110185/558524651/18.dcm\n",
      " 289846404   data/train_images_origin/289846404/2682814802/5.dcm\n",
      "  38281420    data/train_images_origin/38281420/2565838687/3.dcm\n",
      "1558814835  data/train_images_origin/1558814835/1029283419/2.dcm\n",
      "2637411510 data/train_images_origin/2637411510/1140760420/16.dcm\n",
      "1307961168 data/train_images_origin/1307961168/4152012235/14.dcm\n",
      "  13317052    data/train_images_origin/13317052/2677627096/5.dcm\n",
      "1904225580 data/train_images_origin/1904225580/3345088118/16.dcm\n",
      "1205664021  data/train_images_origin/1205664021/3886228128/3.dcm\n",
      "2857344475  data/train_images_origin/2857344475/3369324172/1.dcm\n",
      "1271819130   data/train_images_origin/1271819130/351635764/9.dcm\n",
      "2357870240  data/train_images_origin/2357870240/1446524665/5.dcm\n",
      "3154638975  data/train_images_origin/3154638975/1815727780/9.dcm\n",
      "1644861124  data/train_images_origin/1644861124/1595773852/9.dcm\n",
      " 696494906   data/train_images_origin/696494906/1020114276/2.dcm\n",
      "4279958262  data/train_images_origin/4279958262/4023596147/7.dcm\n",
      "2728988942  data/train_images_origin/2728988942/632466427/13.dcm\n",
      "3258126294   data/train_images_origin/3258126294/918902957/4.dcm\n",
      "1261271580   data/train_images_origin/1261271580/813965073/2.dcm\n",
      " 983365930    data/train_images_origin/983365930/680927594/9.dcm\n",
      "2728988942   data/train_images_origin/2728988942/632466427/2.dcm\n",
      "3362964060  data/train_images_origin/3362964060/818865502/14.dcm\n",
      "1431195383  data/train_images_origin/1431195383/3551899591/2.dcm\n",
      "2427880799 data/train_images_origin/2427880799/2570719913/12.dcm\n",
      "3426816011   data/train_images_origin/3426816011/972430749/2.dcm\n",
      "1261271580 data/train_images_origin/1261271580/1629954928/14.dcm\n",
      "4271960965  data/train_images_origin/4271960965/316501793/12.dcm\n",
      " 823937142   data/train_images_origin/823937142/1743883669/1.dcm\n",
      "4246183162 data/train_images_origin/4246183162/2898345470/10.dcm\n",
      "3319644132  data/train_images_origin/3319644132/157107762/13.dcm\n",
      "2323872325 data/train_images_origin/2323872325/2705541433/12.dcm\n",
      "1737682527  data/train_images_origin/1737682527/1258728011/1.dcm\n",
      "3319644132 data/train_images_origin/3319644132/3781889921/13.dcm\n",
      " 594735110  data/train_images_origin/594735110/3717729365/13.dcm\n",
      "1751480356  data/train_images_origin/1751480356/4154954091/9.dcm\n",
      " 711877989   data/train_images_origin/711877989/2747541553/9.dcm\n",
      "2809323451   data/train_images_origin/2809323451/348943421/3.dcm\n",
      "1302048123  data/train_images_origin/1302048123/782258336/14.dcm\n",
      "1835489622  data/train_images_origin/1835489622/2569745110/8.dcm\n",
      "1812655676 data/train_images_origin/1812655676/2408010873/10.dcm\n",
      "3202723468 data/train_images_origin/3202723468/2127329151/13.dcm\n",
      "3252162306  data/train_images_origin/3252162306/2124596461/2.dcm\n",
      "4238265702  data/train_images_origin/4238265702/1938347296/7.dcm\n",
      "1722308532   data/train_images_origin/1722308532/271934733/5.dcm\n",
      "3819260179  data/train_images_origin/3819260179/1735851779/3.dcm\n",
      "2938658366 data/train_images_origin/2938658366/2929023438/14.dcm\n",
      "1504031267 data/train_images_origin/1504031267/2784380684/18.dcm\n"
     ]
    }
   ],
   "source": [
    "print(test_df.to_string(index=False, header=True)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1: data/train_images_origin/2775207739/3249541180/8.dcm - Predicted coordinates (x, y) = (0.62, 0.72)\n",
      "Image 2: data/train_images_origin/664153360/1076245514/13.dcm - Predicted coordinates (x, y) = (3.67, 5.86)\n",
      "Image 3: data/train_images_origin/2273432465/114306451/9.dcm - Predicted coordinates (x, y) = (1.57, 2.37)\n",
      "Image 4: data/train_images_origin/3777149998/3550597941/8.dcm - Predicted coordinates (x, y) = (1.95, 3.06)\n",
      "Image 5: data/train_images_origin/3967802493/2054070341/11.dcm - Predicted coordinates (x, y) = (4.32, 7.06)\n",
      "Image 6: data/train_images_origin/2780118855/2064060968/14.dcm - Predicted coordinates (x, y) = (0.23, -0.08)\n",
      "Image 7: data/train_images_origin/247968996/256361821/14.dcm - Predicted coordinates (x, y) = (8.64, 14.41)\n",
      "Image 8: data/train_images_origin/957176622/1889022706/1.dcm - Predicted coordinates (x, y) = (9.88, 16.94)\n",
      "Image 9: data/train_images_origin/4075603869/2921580289/3.dcm - Predicted coordinates (x, y) = (4.36, 6.97)\n",
      "Image 10: data/train_images_origin/3605654232/26446529/3.dcm - Predicted coordinates (x, y) = (-0.73, -0.35)\n",
      "Image 11: data/train_images_origin/1839242409/3211434109/13.dcm - Predicted coordinates (x, y) = (5.90, 9.58)\n",
      "Image 12: data/train_images_origin/779162887/2596438821/18.dcm - Predicted coordinates (x, y) = (0.38, 0.17)\n",
      "Image 13: data/train_images_origin/886995462/3051597267/16.dcm - Predicted coordinates (x, y) = (-0.13, -0.57)\n",
      "Image 14: data/train_images_origin/2348702073/323466396/5.dcm - Predicted coordinates (x, y) = (9.46, 16.18)\n",
      "Image 15: data/train_images_origin/3550756125/2355159919/2.dcm - Predicted coordinates (x, y) = (0.23, -0.05)\n",
      "Image 16: data/train_images_origin/1271819130/351635764/18.dcm - Predicted coordinates (x, y) = (10.86, 18.38)\n",
      "Image 17: data/train_images_origin/3955843496/3438790057/15.dcm - Predicted coordinates (x, y) = (3.17, 4.98)\n",
      "Image 18: data/train_images_origin/707927308/3971759912/9.dcm - Predicted coordinates (x, y) = (2.86, 4.57)\n",
      "Image 19: data/train_images_origin/2139209036/2276017852/11.dcm - Predicted coordinates (x, y) = (5.77, 9.58)\n",
      "Image 20: data/train_images_origin/885579922/2120705955/10.dcm - Predicted coordinates (x, y) = (2.18, 3.39)\n",
      "Image 21: data/train_images_origin/1028909382/1477339972/3.dcm - Predicted coordinates (x, y) = (8.49, 14.70)\n",
      "Image 22: data/train_images_origin/2826913245/819860127/10.dcm - Predicted coordinates (x, y) = (-7.66, -12.96)\n",
      "Image 23: data/train_images_origin/1750070978/1851892747/10.dcm - Predicted coordinates (x, y) = (8.97, 14.97)\n",
      "Image 24: data/train_images_origin/1461368679/2332227383/18.dcm - Predicted coordinates (x, y) = (6.57, 10.89)\n",
      "Image 25: data/train_images_origin/3640325492/1951216919/17.dcm - Predicted coordinates (x, y) = (0.07, -0.17)\n",
      "Image 26: data/train_images_origin/3912497560/2827806606/10.dcm - Predicted coordinates (x, y) = (0.39, 0.25)\n",
      "Image 27: data/train_images_origin/1278694021/896910489/5.dcm - Predicted coordinates (x, y) = (9.70, 16.04)\n",
      "Image 28: data/train_images_origin/3053259969/1052790448/14.dcm - Predicted coordinates (x, y) = (8.11, 13.83)\n",
      "Image 29: data/train_images_origin/3355993164/3005686985/11.dcm - Predicted coordinates (x, y) = (9.93, 17.16)\n",
      "Image 30: data/train_images_origin/2162304486/278619831/10.dcm - Predicted coordinates (x, y) = (2.37, 3.78)\n",
      "Image 31: data/train_images_origin/4136088296/25009550/12.dcm - Predicted coordinates (x, y) = (2.67, 4.27)\n",
      "Image 32: data/train_images_origin/3053259969/1052790448/17.dcm - Predicted coordinates (x, y) = (8.05, 13.77)\n",
      "Image 33: data/train_images_origin/676719753/60239014/12.dcm - Predicted coordinates (x, y) = (0.25, -0.04)\n",
      "Image 34: data/train_images_origin/2888359875/1229482953/9.dcm - Predicted coordinates (x, y) = (11.67, 19.53)\n",
      "Image 35: data/train_images_origin/2683615288/1060438383/1.dcm - Predicted coordinates (x, y) = (2.03, 3.22)\n",
      "Image 36: data/train_images_origin/3485457199/3404943724/14.dcm - Predicted coordinates (x, y) = (0.30, 0.03)\n",
      "Image 37: data/train_images_origin/953639220/270540558/18.dcm - Predicted coordinates (x, y) = (10.83, 18.22)\n",
      "Image 38: data/train_images_origin/3762703235/3997674421/10.dcm - Predicted coordinates (x, y) = (0.18, -0.13)\n",
      "Image 39: data/train_images_origin/945809437/1112017435/5.dcm - Predicted coordinates (x, y) = (3.16, 5.13)\n",
      "Image 40: data/train_images_origin/3966998094/3899055711/15.dcm - Predicted coordinates (x, y) = (7.50, 13.01)\n",
      "Image 41: data/train_images_origin/1666392091/3894977345/18.dcm - Predicted coordinates (x, y) = (3.51, 5.65)\n",
      "Image 42: data/train_images_origin/4029974537/2765384875/19.dcm - Predicted coordinates (x, y) = (7.12, 12.05)\n",
      "Image 43: data/train_images_origin/1164861071/3163330218/13.dcm - Predicted coordinates (x, y) = (0.23, -0.06)\n",
      "Image 44: data/train_images_origin/603095830/77460261/10.dcm - Predicted coordinates (x, y) = (6.79, 11.62)\n",
      "Image 45: data/train_images_origin/3625799781/1297988885/14.dcm - Predicted coordinates (x, y) = (2.22, 3.59)\n",
      "Image 46: data/train_images_origin/3924490793/2841709587/3.dcm - Predicted coordinates (x, y) = (4.20, 6.91)\n",
      "Image 47: data/train_images_origin/2758707424/2525570429/19.dcm - Predicted coordinates (x, y) = (6.05, 9.92)\n",
      "Image 48: data/train_images_origin/3853089836/876411051/6.dcm - Predicted coordinates (x, y) = (1.92, 2.83)\n",
      "Image 49: data/train_images_origin/1868615696/1304954941/22.dcm - Predicted coordinates (x, y) = (8.26, 14.21)\n",
      "Image 50: data/train_images_origin/434488359/152760150/9.dcm - Predicted coordinates (x, y) = (6.63, 10.99)\n",
      "Image 51: data/train_images_origin/2696451534/1846537274/2.dcm - Predicted coordinates (x, y) = (6.90, 11.38)\n",
      "Image 52: data/train_images_origin/3922074884/1915960810/17.dcm - Predicted coordinates (x, y) = (11.26, 19.09)\n",
      "Image 53: data/train_images_origin/4098077002/3387230519/2.dcm - Predicted coordinates (x, y) = (4.59, 7.49)\n",
      "Image 54: data/train_images_origin/704573554/1699734064/17.dcm - Predicted coordinates (x, y) = (-6.47, -10.81)\n",
      "Image 55: data/train_images_origin/473465726/2791294349/10.dcm - Predicted coordinates (x, y) = (5.88, 9.62)\n",
      "Image 56: data/train_images_origin/2006700205/2889256302/5.dcm - Predicted coordinates (x, y) = (1.72, 2.54)\n",
      "Image 57: data/train_images_origin/3473524025/1697065269/5.dcm - Predicted coordinates (x, y) = (1.62, 2.37)\n",
      "Image 58: data/train_images_origin/991026205/1652078757/6.dcm - Predicted coordinates (x, y) = (4.06, 7.17)\n",
      "Image 59: data/train_images_origin/960760926/3244075592/8.dcm - Predicted coordinates (x, y) = (3.92, 6.59)\n",
      "Image 60: data/train_images_origin/2966999234/721342892/7.dcm - Predicted coordinates (x, y) = (8.02, 13.67)\n",
      "Image 61: data/train_images_origin/1524089207/2330513520/10.dcm - Predicted coordinates (x, y) = (4.48, 7.46)\n",
      "Image 62: data/train_images_origin/1904225580/3345088118/10.dcm - Predicted coordinates (x, y) = (5.42, 9.19)\n",
      "Image 63: data/train_images_origin/1020394063/1523561649/6.dcm - Predicted coordinates (x, y) = (9.95, 16.86)\n",
      "Image 64: data/train_images_origin/3832874334/3671717022/9.dcm - Predicted coordinates (x, y) = (9.18, 15.27)\n",
      "Image 65: data/train_images_origin/734370379/1655908293/8.dcm - Predicted coordinates (x, y) = (9.49, 16.26)\n",
      "Image 66: data/train_images_origin/3457755755/776752953/13.dcm - Predicted coordinates (x, y) = (6.67, 11.36)\n",
      "Image 67: data/train_images_origin/2839406005/3923297118/15.dcm - Predicted coordinates (x, y) = (6.97, 11.86)\n",
      "Image 68: data/train_images_origin/1618233546/2816981416/5.dcm - Predicted coordinates (x, y) = (-1.04, -0.94)\n",
      "Image 69: data/train_images_origin/1721321525/3544091430/2.dcm - Predicted coordinates (x, y) = (4.48, 7.36)\n",
      "Image 70: data/train_images_origin/3148156510/4209426235/10.dcm - Predicted coordinates (x, y) = (0.46, 0.52)\n",
      "Image 71: data/train_images_origin/3817394595/990175634/6.dcm - Predicted coordinates (x, y) = (4.51, 7.45)\n",
      "Image 72: data/train_images_origin/1205664021/3886228128/8.dcm - Predicted coordinates (x, y) = (11.00, 18.92)\n",
      "Image 73: data/train_images_origin/2915096892/2140831218/10.dcm - Predicted coordinates (x, y) = (8.93, 15.10)\n",
      "Image 74: data/train_images_origin/1408642922/679345222/18.dcm - Predicted coordinates (x, y) = (9.15, 15.62)\n",
      "Image 75: data/train_images_origin/4106450023/3559440209/13.dcm - Predicted coordinates (x, y) = (0.25, -0.06)\n",
      "Image 76: data/train_images_origin/3955843496/3438790057/8.dcm - Predicted coordinates (x, y) = (2.06, 3.11)\n",
      "Image 77: data/train_images_origin/159721286/4204680939/1.dcm - Predicted coordinates (x, y) = (8.95, 14.91)\n",
      "Image 78: data/train_images_origin/377474930/2668009971/10.dcm - Predicted coordinates (x, y) = (6.64, 10.96)\n",
      "Image 79: data/train_images_origin/492697281/1667589476/18.dcm - Predicted coordinates (x, y) = (3.74, 6.10)\n",
      "Image 80: data/train_images_origin/2501638175/477334578/14.dcm - Predicted coordinates (x, y) = (-7.95, -13.44)\n",
      "Image 81: data/train_images_origin/4271960965/2901066339/1.dcm - Predicted coordinates (x, y) = (1.21, 1.76)\n",
      "Image 82: data/train_images_origin/3693117342/826409966/6.dcm - Predicted coordinates (x, y) = (2.11, 3.18)\n",
      "Image 83: data/train_images_origin/4287160193/1507070277/3.dcm - Predicted coordinates (x, y) = (0.11, 1.11)\n",
      "Image 84: data/train_images_origin/395898502/317903133/17.dcm - Predicted coordinates (x, y) = (-1.49, -2.69)\n",
      "Image 85: data/train_images_origin/3892114403/4017753326/10.dcm - Predicted coordinates (x, y) = (8.40, 13.79)\n",
      "Image 86: data/train_images_origin/1768692511/1766321945/11.dcm - Predicted coordinates (x, y) = (6.03, 10.31)\n",
      "Image 87: data/train_images_origin/416521027/2597582307/8.dcm - Predicted coordinates (x, y) = (5.48, 9.09)\n",
      "Image 88: data/train_images_origin/3688443239/1061884431/9.dcm - Predicted coordinates (x, y) = (1.48, 2.98)\n",
      "Image 89: data/train_images_origin/1302135990/3397821355/9.dcm - Predicted coordinates (x, y) = (0.10, -0.27)\n",
      "Image 90: data/train_images_origin/1205664021/572344680/2.dcm - Predicted coordinates (x, y) = (11.74, 19.80)\n",
      "Image 91: data/train_images_origin/2504110412/3125592759/1.dcm - Predicted coordinates (x, y) = (5.10, 8.20)\n",
      "Image 92: data/train_images_origin/3326102488/4089227912/1.dcm - Predicted coordinates (x, y) = (6.89, 11.74)\n",
      "Image 93: data/train_images_origin/769420103/1847227775/14.dcm - Predicted coordinates (x, y) = (3.65, 5.89)\n",
      "Image 94: data/train_images_origin/3836739612/401031234/17.dcm - Predicted coordinates (x, y) = (1.14, 1.61)\n",
      "Image 95: data/train_images_origin/642715533/2855523941/14.dcm - Predicted coordinates (x, y) = (6.33, 10.34)\n",
      "Image 96: data/train_images_origin/1246626043/27170521/18.dcm - Predicted coordinates (x, y) = (2.58, 4.02)\n",
      "Image 97: data/train_images_origin/3853089836/3151879788/14.dcm - Predicted coordinates (x, y) = (6.10, 9.95)\n",
      "Image 98: data/train_images_origin/4262145542/4276471335/14.dcm - Predicted coordinates (x, y) = (10.37, 17.49)\n",
      "Image 99: data/train_images_origin/1353517692/1762986309/15.dcm - Predicted coordinates (x, y) = (6.22, 10.21)\n",
      "Image 100: data/train_images_origin/2794192602/1829533928/2.dcm - Predicted coordinates (x, y) = (0.49, 1.14)\n",
      "Image 101: data/train_images_origin/711877989/1051517571/6.dcm - Predicted coordinates (x, y) = (14.45, 24.29)\n",
      "Image 102: data/train_images_origin/3279376183/792897358/3.dcm - Predicted coordinates (x, y) = (1.80, 2.75)\n",
      "Image 103: data/train_images_origin/4000809387/3804393004/4.dcm - Predicted coordinates (x, y) = (0.55, 0.62)\n",
      "Image 104: data/train_images_origin/3691609865/124455970/10.dcm - Predicted coordinates (x, y) = (0.26, -0.02)\n",
      "Image 105: data/train_images_origin/3163594538/2752448967/2.dcm - Predicted coordinates (x, y) = (10.10, 16.95)\n",
      "Image 106: data/train_images_origin/3828017267/3343226405/1.dcm - Predicted coordinates (x, y) = (-6.08, -10.41)\n",
      "Image 107: data/train_images_origin/4646740/3486248476/16.dcm - Predicted coordinates (x, y) = (6.63, 11.11)\n",
      "Image 108: data/train_images_origin/2293787755/2466237048/8.dcm - Predicted coordinates (x, y) = (0.51, 0.57)\n",
      "Image 109: data/train_images_origin/2986835162/2483725214/13.dcm - Predicted coordinates (x, y) = (0.30, 0.03)\n",
      "Image 110: data/train_images_origin/2318756258/416072674/20.dcm - Predicted coordinates (x, y) = (5.43, 9.51)\n",
      "Image 111: data/train_images_origin/1677607138/305773513/12.dcm - Predicted coordinates (x, y) = (0.11, -0.18)\n",
      "Image 112: data/train_images_origin/1850731145/1725330889/3.dcm - Predicted coordinates (x, y) = (1.35, 2.09)\n",
      "Image 113: data/train_images_origin/1897045431/379237928/2.dcm - Predicted coordinates (x, y) = (1.23, 3.13)\n",
      "Image 114: data/train_images_origin/2048265504/2998592741/3.dcm - Predicted coordinates (x, y) = (9.83, 16.59)\n",
      "Image 115: data/train_images_origin/480042730/2250935329/16.dcm - Predicted coordinates (x, y) = (1.36, 2.10)\n",
      "Image 116: data/train_images_origin/3234424112/3240624272/9.dcm - Predicted coordinates (x, y) = (-0.14, -0.54)\n",
      "Image 117: data/train_images_origin/3270195628/2954527433/6.dcm - Predicted coordinates (x, y) = (5.77, 9.45)\n",
      "Image 118: data/train_images_origin/3426183113/776968358/9.dcm - Predicted coordinates (x, y) = (3.27, 5.36)\n",
      "Image 119: data/train_images_origin/2361533111/4175535573/14.dcm - Predicted coordinates (x, y) = (-0.42, -0.97)\n",
      "Image 120: data/train_images_origin/1143931807/1437031388/2.dcm - Predicted coordinates (x, y) = (4.19, 6.74)\n",
      "Image 121: data/train_images_origin/1408642922/2290485467/9.dcm - Predicted coordinates (x, y) = (1.44, 2.03)\n",
      "Image 122: data/train_images_origin/976356113/2133623285/7.dcm - Predicted coordinates (x, y) = (0.99, 1.45)\n",
      "Image 123: data/train_images_origin/3029953735/3791383775/17.dcm - Predicted coordinates (x, y) = (9.75, 16.77)\n",
      "Image 124: data/train_images_origin/1425679446/3623899442/2.dcm - Predicted coordinates (x, y) = (4.08, 6.69)\n",
      "Image 125: data/train_images_origin/4171095315/3978956866/19.dcm - Predicted coordinates (x, y) = (7.18, 12.21)\n",
      "Image 126: data/train_images_origin/1205664021/572344680/5.dcm - Predicted coordinates (x, y) = (11.55, 19.51)\n",
      "Image 127: data/train_images_origin/3154638975/2052598012/7.dcm - Predicted coordinates (x, y) = (2.27, 3.82)\n",
      "Image 128: data/train_images_origin/3485457199/3404943724/1.dcm - Predicted coordinates (x, y) = (0.26, -0.03)\n",
      "Image 129: data/train_images_origin/404602713/2886229355/10.dcm - Predicted coordinates (x, y) = (6.26, 10.38)\n",
      "Image 130: data/train_images_origin/1504031267/2784380684/9.dcm - Predicted coordinates (x, y) = (-5.49, -9.49)\n",
      "Image 131: data/train_images_origin/3674684193/3473821253/12.dcm - Predicted coordinates (x, y) = (6.38, 11.21)\n",
      "Image 132: data/train_images_origin/3824720894/4259273683/12.dcm - Predicted coordinates (x, y) = (8.54, 14.31)\n",
      "Image 133: data/train_images_origin/2509066997/4048077433/10.dcm - Predicted coordinates (x, y) = (8.78, 15.00)\n",
      "Image 134: data/train_images_origin/1115952008/469758184/1.dcm - Predicted coordinates (x, y) = (2.69, 4.36)\n",
      "Image 135: data/train_images_origin/2325650566/20477869/3.dcm - Predicted coordinates (x, y) = (9.56, 16.58)\n",
      "Image 136: data/train_images_origin/1827243377/3474567852/3.dcm - Predicted coordinates (x, y) = (0.32, 0.04)\n",
      "Image 137: data/train_images_origin/1545888499/2917369652/18.dcm - Predicted coordinates (x, y) = (2.80, 4.50)\n",
      "Image 138: data/train_images_origin/2181005070/3498146795/10.dcm - Predicted coordinates (x, y) = (4.86, 8.57)\n",
      "Image 139: data/train_images_origin/4244186396/3091810859/13.dcm - Predicted coordinates (x, y) = (8.36, 13.93)\n",
      "Image 140: data/train_images_origin/1190473557/3244338661/15.dcm - Predicted coordinates (x, y) = (0.15, -0.08)\n",
      "Image 141: data/train_images_origin/3902887884/4282493649/8.dcm - Predicted coordinates (x, y) = (1.71, 2.81)\n",
      "Image 142: data/train_images_origin/3528463452/3329373458/7.dcm - Predicted coordinates (x, y) = (-0.97, -0.82)\n",
      "Image 143: data/train_images_origin/3368217301/847395792/12.dcm - Predicted coordinates (x, y) = (0.91, 1.29)\n",
      "Image 144: data/train_images_origin/2719549572/2374987445/18.dcm - Predicted coordinates (x, y) = (6.93, 11.75)\n",
      "Image 145: data/train_images_origin/3068678959/4149292781/8.dcm - Predicted coordinates (x, y) = (-4.46, -7.63)\n",
      "Image 146: data/train_images_origin/329807127/386603676/9.dcm - Predicted coordinates (x, y) = (3.24, 5.18)\n",
      "Image 147: data/train_images_origin/2399492744/1942345627/9.dcm - Predicted coordinates (x, y) = (-5.74, -9.80)\n",
      "Image 148: data/train_images_origin/1879696087/3230157587/10.dcm - Predicted coordinates (x, y) = (2.42, 3.87)\n",
      "Image 149: data/train_images_origin/492697281/1667589476/14.dcm - Predicted coordinates (x, y) = (3.18, 5.14)\n",
      "Image 150: data/train_images_origin/4078163716/2504629441/14.dcm - Predicted coordinates (x, y) = (0.30, 0.05)\n",
      "Image 151: data/train_images_origin/2986835162/78752398/5.dcm - Predicted coordinates (x, y) = (3.44, 5.56)\n",
      "Image 152: data/train_images_origin/1820866003/131094096/10.dcm - Predicted coordinates (x, y) = (0.30, 0.07)\n",
      "Image 153: data/train_images_origin/2484590654/2607944761/1.dcm - Predicted coordinates (x, y) = (4.08, 6.67)\n",
      "Image 154: data/train_images_origin/3880626718/1310605220/20.dcm - Predicted coordinates (x, y) = (8.47, 14.41)\n",
      "Image 155: data/train_images_origin/1395246421/763239197/13.dcm - Predicted coordinates (x, y) = (0.03, -0.31)\n",
      "Image 156: data/train_images_origin/178041181/2495441739/5.dcm - Predicted coordinates (x, y) = (10.90, 18.71)\n",
      "Image 157: data/train_images_origin/1459284649/1104843171/8.dcm - Predicted coordinates (x, y) = (2.48, 4.09)\n",
      "Image 158: data/train_images_origin/2713141511/3771041996/11.dcm - Predicted coordinates (x, y) = (8.08, 13.48)\n",
      "Image 159: data/train_images_origin/933559951/2039681347/11.dcm - Predicted coordinates (x, y) = (9.11, 15.38)\n",
      "Image 160: data/train_images_origin/4163587601/133519848/20.dcm - Predicted coordinates (x, y) = (6.11, 9.87)\n",
      "Image 161: data/train_images_origin/2512945281/2701329062/5.dcm - Predicted coordinates (x, y) = (1.53, 2.21)\n",
      "Image 162: data/train_images_origin/1008446160/2539455828/5.dcm - Predicted coordinates (x, y) = (5.96, 9.82)\n",
      "Image 163: data/train_images_origin/2530679352/3989445153/14.dcm - Predicted coordinates (x, y) = (2.57, 4.01)\n",
      "Image 164: data/train_images_origin/1698156042/1349877419/16.dcm - Predicted coordinates (x, y) = (0.91, 1.29)\n",
      "Image 165: data/train_images_origin/1012375618/352098527/13.dcm - Predicted coordinates (x, y) = (2.52, 3.94)\n",
      "Image 166: data/train_images_origin/4003253/702807833/3.dcm - Predicted coordinates (x, y) = (2.44, 3.76)\n",
      "Image 167: data/train_images_origin/3362072295/3414299110/17.dcm - Predicted coordinates (x, y) = (4.54, 7.26)\n",
      "Image 168: data/train_images_origin/886995462/1238593879/9.dcm - Predicted coordinates (x, y) = (0.98, 1.40)\n",
      "Image 169: data/train_images_origin/1367470327/2618650591/5.dcm - Predicted coordinates (x, y) = (3.32, 5.40)\n",
      "Image 170: data/train_images_origin/1212932624/4275546294/14.dcm - Predicted coordinates (x, y) = (6.81, 11.28)\n",
      "Image 171: data/train_images_origin/3442533162/978923687/10.dcm - Predicted coordinates (x, y) = (0.16, -0.16)\n",
      "Image 172: data/train_images_origin/3207960359/4029680789/8.dcm - Predicted coordinates (x, y) = (0.37, 0.41)\n",
      "Image 173: data/train_images_origin/2881985242/2304209248/10.dcm - Predicted coordinates (x, y) = (0.10, -0.21)\n",
      "Image 174: data/train_images_origin/1901348744/1490272456/10.dcm - Predicted coordinates (x, y) = (5.51, 9.19)\n",
      "Image 175: data/train_images_origin/2097856420/2151902888/1.dcm - Predicted coordinates (x, y) = (7.69, 12.79)\n",
      "Image 176: data/train_images_origin/2053213309/2972736368/5.dcm - Predicted coordinates (x, y) = (5.34, 9.09)\n",
      "Image 177: data/train_images_origin/2066619590/3183444321/5.dcm - Predicted coordinates (x, y) = (5.19, 8.51)\n",
      "Image 178: data/train_images_origin/1460690973/301524229/16.dcm - Predicted coordinates (x, y) = (4.91, 7.99)\n",
      "Image 179: data/train_images_origin/3426816011/918923835/6.dcm - Predicted coordinates (x, y) = (2.73, 4.34)\n",
      "Image 180: data/train_images_origin/2053506490/774221508/6.dcm - Predicted coordinates (x, y) = (1.09, 1.64)\n",
      "Image 181: data/train_images_origin/2266719355/3763942448/12.dcm - Predicted coordinates (x, y) = (0.77, 1.05)\n",
      "Image 182: data/train_images_origin/1676531728/3775504232/14.dcm - Predicted coordinates (x, y) = (3.02, 4.71)\n",
      "Image 183: data/train_images_origin/1115481506/3168836041/7.dcm - Predicted coordinates (x, y) = (6.03, 9.90)\n",
      "Image 184: data/train_images_origin/2348702073/323466396/1.dcm - Predicted coordinates (x, y) = (9.07, 15.57)\n",
      "Image 185: data/train_images_origin/4255570773/3722788142/11.dcm - Predicted coordinates (x, y) = (5.71, 9.42)\n",
      "Image 186: data/train_images_origin/4058604433/2135474355/10.dcm - Predicted coordinates (x, y) = (11.47, 19.55)\n",
      "Image 187: data/train_images_origin/3495818564/856763877/6.dcm - Predicted coordinates (x, y) = (10.64, 17.69)\n",
      "Image 188: data/train_images_origin/106310815/2473102710/15.dcm - Predicted coordinates (x, y) = (6.19, 10.63)\n",
      "Image 189: data/train_images_origin/2540057310/3139146894/6.dcm - Predicted coordinates (x, y) = (8.07, 13.80)\n",
      "Image 190: data/train_images_origin/2097856420/3505847202/17.dcm - Predicted coordinates (x, y) = (2.37, 3.64)\n",
      "Image 191: data/train_images_origin/933831851/4191352206/3.dcm - Predicted coordinates (x, y) = (9.44, 15.91)\n",
      "Image 192: data/train_images_origin/3128795155/483456514/13.dcm - Predicted coordinates (x, y) = (6.18, 10.63)\n",
      "Image 193: data/train_images_origin/4259049254/1207877860/16.dcm - Predicted coordinates (x, y) = (3.75, 6.30)\n",
      "Image 194: data/train_images_origin/296314829/3463650248/9.dcm - Predicted coordinates (x, y) = (-0.88, -0.70)\n",
      "Image 195: data/train_images_origin/395898502/369410970/1.dcm - Predicted coordinates (x, y) = (1.83, 2.85)\n",
      "Image 196: data/train_images_origin/2597785056/266375569/10.dcm - Predicted coordinates (x, y) = (-15.89, -26.83)\n",
      "Image 197: data/train_images_origin/2728988942/632466427/12.dcm - Predicted coordinates (x, y) = (-1.10, -2.06)\n",
      "Image 198: data/train_images_origin/2008315239/754564873/14.dcm - Predicted coordinates (x, y) = (9.59, 16.54)\n",
      "Image 199: data/train_images_origin/1505795551/2733545907/1.dcm - Predicted coordinates (x, y) = (6.36, 10.91)\n",
      "Image 200: data/train_images_origin/4137194670/687903591/6.dcm - Predicted coordinates (x, y) = (9.66, 16.50)\n",
      "Image 201: data/train_images_origin/2622319181/3373306398/16.dcm - Predicted coordinates (x, y) = (8.03, 13.86)\n",
      "Image 202: data/train_images_origin/2872050745/766394136/3.dcm - Predicted coordinates (x, y) = (4.78, 7.82)\n",
      "Image 203: data/train_images_origin/189360935/122094537/1.dcm - Predicted coordinates (x, y) = (4.55, 7.89)\n",
      "Image 204: data/train_images_origin/455813081/2426521082/5.dcm - Predicted coordinates (x, y) = (3.48, 5.63)\n",
      "Image 205: data/train_images_origin/3218815255/1342304074/5.dcm - Predicted coordinates (x, y) = (0.13, -0.21)\n",
      "Image 206: data/train_images_origin/4123124185/95582042/2.dcm - Predicted coordinates (x, y) = (4.33, 7.11)\n",
      "Image 207: data/train_images_origin/3650821463/2242247794/9.dcm - Predicted coordinates (x, y) = (6.40, 10.47)\n",
      "Image 208: data/train_images_origin/1378385941/2729244584/1.dcm - Predicted coordinates (x, y) = (1.01, 1.49)\n",
      "Image 209: data/train_images_origin/2565951228/4221884084/9.dcm - Predicted coordinates (x, y) = (6.08, 10.20)\n",
      "Image 210: data/train_images_origin/2139209036/504942023/6.dcm - Predicted coordinates (x, y) = (5.69, 9.62)\n",
      "Image 211: data/train_images_origin/1012375618/4014890929/5.dcm - Predicted coordinates (x, y) = (0.31, 0.06)\n",
      "Image 212: data/train_images_origin/1763343402/4240004400/11.dcm - Predicted coordinates (x, y) = (5.33, 9.07)\n",
      "Image 213: data/train_images_origin/1526636609/1497385254/12.dcm - Predicted coordinates (x, y) = (0.89, 1.23)\n",
      "Image 214: data/train_images_origin/8785691/481125819/5.dcm - Predicted coordinates (x, y) = (0.36, 0.13)\n",
      "Image 215: data/train_images_origin/3732627030/23479552/14.dcm - Predicted coordinates (x, y) = (8.86, 14.78)\n",
      "Image 216: data/train_images_origin/924259603/107861764/18.dcm - Predicted coordinates (x, y) = (2.99, 4.85)\n",
      "Image 217: data/train_images_origin/783154228/3342733127/5.dcm - Predicted coordinates (x, y) = (0.63, 0.82)\n",
      "Image 218: data/train_images_origin/2297295777/2376943158/1.dcm - Predicted coordinates (x, y) = (9.00, 15.34)\n",
      "Image 219: data/train_images_origin/2621647501/3531341578/12.dcm - Predicted coordinates (x, y) = (9.42, 16.07)\n",
      "Image 220: data/train_images_origin/2607462358/384543934/13.dcm - Predicted coordinates (x, y) = (1.41, 2.11)\n",
      "Image 221: data/train_images_origin/2911725373/205579604/2.dcm - Predicted coordinates (x, y) = (8.72, 14.76)\n",
      "Image 222: data/train_images_origin/983365930/751248046/1.dcm - Predicted coordinates (x, y) = (8.05, 13.52)\n",
      "Image 223: data/train_images_origin/4057365107/1903217931/12.dcm - Predicted coordinates (x, y) = (0.23, 0.24)\n",
      "Image 224: data/train_images_origin/1460690973/301524229/18.dcm - Predicted coordinates (x, y) = (4.47, 7.31)\n",
      "Image 225: data/train_images_origin/2435837923/2566229687/5.dcm - Predicted coordinates (x, y) = (0.08, 0.85)\n",
      "Image 226: data/train_images_origin/1246626043/677585315/9.dcm - Predicted coordinates (x, y) = (5.30, 8.86)\n",
      "Image 227: data/train_images_origin/3719530586/194470896/7.dcm - Predicted coordinates (x, y) = (7.78, 12.88)\n",
      "Image 228: data/train_images_origin/2510853598/557949762/3.dcm - Predicted coordinates (x, y) = (9.20, 15.57)\n",
      "Image 229: data/train_images_origin/3218815255/2385755271/10.dcm - Predicted coordinates (x, y) = (5.71, 9.62)\n",
      "Image 230: data/train_images_origin/1536303104/650362227/2.dcm - Predicted coordinates (x, y) = (9.23, 16.11)\n",
      "Image 231: data/train_images_origin/123154253/2257413721/20.dcm - Predicted coordinates (x, y) = (5.85, 9.47)\n",
      "Image 232: data/train_images_origin/1525303131/1885363841/8.dcm - Predicted coordinates (x, y) = (6.59, 11.14)\n",
      "Image 233: data/train_images_origin/2839406005/551025985/5.dcm - Predicted coordinates (x, y) = (8.55, 14.69)\n",
      "Image 234: data/train_images_origin/3749556667/1440069870/13.dcm - Predicted coordinates (x, y) = (1.50, 2.25)\n",
      "Image 235: data/train_images_origin/1271033295/2054979604/16.dcm - Predicted coordinates (x, y) = (-9.86, -16.74)\n",
      "Image 236: data/train_images_origin/2797118205/1974847306/1.dcm - Predicted coordinates (x, y) = (0.99, 1.99)\n",
      "Image 237: data/train_images_origin/206642334/3618533469/10.dcm - Predicted coordinates (x, y) = (0.15, -0.17)\n",
      "Image 238: data/train_images_origin/60612428/2349970136/11.dcm - Predicted coordinates (x, y) = (0.22, -0.09)\n",
      "Image 239: data/train_images_origin/2162304486/278619831/17.dcm - Predicted coordinates (x, y) = (4.35, 7.17)\n",
      "Image 240: data/train_images_origin/2540057310/821488018/2.dcm - Predicted coordinates (x, y) = (6.58, 11.10)\n",
      "Image 241: data/train_images_origin/52397721/2452297573/10.dcm - Predicted coordinates (x, y) = (3.67, 6.23)\n",
      "Image 242: data/train_images_origin/3934148010/668512855/14.dcm - Predicted coordinates (x, y) = (0.56, 0.62)\n",
      "Image 243: data/train_images_origin/3521369408/3910483650/3.dcm - Predicted coordinates (x, y) = (5.87, 9.78)\n",
      "Image 244: data/train_images_origin/1927301799/1853929267/8.dcm - Predicted coordinates (x, y) = (7.22, 11.89)\n",
      "Image 245: data/train_images_origin/2109263401/92738066/16.dcm - Predicted coordinates (x, y) = (1.39, 2.02)\n",
      "Image 246: data/train_images_origin/11340341/2231042680/18.dcm - Predicted coordinates (x, y) = (4.80, 7.73)\n",
      "Image 247: data/train_images_origin/198104941/3000797596/9.dcm - Predicted coordinates (x, y) = (4.42, 7.08)\n",
      "Image 248: data/train_images_origin/1558814835/3045931836/11.dcm - Predicted coordinates (x, y) = (-2.70, -4.62)\n",
      "Image 249: data/train_images_origin/1812153363/242672591/12.dcm - Predicted coordinates (x, y) = (8.44, 14.30)\n",
      "Image 250: data/train_images_origin/3185333113/2772176740/2.dcm - Predicted coordinates (x, y) = (6.02, 10.03)\n",
      "Image 251: data/train_images_origin/1897045431/2252871935/5.dcm - Predicted coordinates (x, y) = (-1.01, -0.53)\n",
      "Image 252: data/train_images_origin/1546104377/897561121/14.dcm - Predicted coordinates (x, y) = (3.27, 5.28)\n",
      "Image 253: data/train_images_origin/428900736/193312628/16.dcm - Predicted coordinates (x, y) = (6.85, 11.52)\n",
      "Image 254: data/train_images_origin/3848110185/558524651/18.dcm - Predicted coordinates (x, y) = (4.83, 7.82)\n",
      "Image 255: data/train_images_origin/289846404/2682814802/5.dcm - Predicted coordinates (x, y) = (-0.09, -0.41)\n",
      "Image 256: data/train_images_origin/38281420/2565838687/3.dcm - Predicted coordinates (x, y) = (5.65, 9.20)\n",
      "Image 257: data/train_images_origin/1558814835/1029283419/2.dcm - Predicted coordinates (x, y) = (-5.05, -8.58)\n",
      "Image 258: data/train_images_origin/2637411510/1140760420/16.dcm - Predicted coordinates (x, y) = (3.48, 5.65)\n",
      "Image 259: data/train_images_origin/1307961168/4152012235/14.dcm - Predicted coordinates (x, y) = (7.11, 11.95)\n",
      "Image 260: data/train_images_origin/13317052/2677627096/5.dcm - Predicted coordinates (x, y) = (0.24, -0.08)\n",
      "Image 261: data/train_images_origin/1904225580/3345088118/16.dcm - Predicted coordinates (x, y) = (6.18, 10.54)\n",
      "Image 262: data/train_images_origin/1205664021/3886228128/3.dcm - Predicted coordinates (x, y) = (11.16, 19.18)\n",
      "Image 263: data/train_images_origin/2857344475/3369324172/1.dcm - Predicted coordinates (x, y) = (0.12, -0.08)\n",
      "Image 264: data/train_images_origin/1271819130/351635764/9.dcm - Predicted coordinates (x, y) = (8.93, 15.31)\n",
      "Image 265: data/train_images_origin/2357870240/1446524665/5.dcm - Predicted coordinates (x, y) = (4.54, 7.49)\n",
      "Image 266: data/train_images_origin/3154638975/1815727780/9.dcm - Predicted coordinates (x, y) = (6.14, 10.80)\n",
      "Image 267: data/train_images_origin/1644861124/1595773852/9.dcm - Predicted coordinates (x, y) = (3.41, 5.53)\n",
      "Image 268: data/train_images_origin/696494906/1020114276/2.dcm - Predicted coordinates (x, y) = (0.17, -0.01)\n",
      "Image 269: data/train_images_origin/4279958262/4023596147/7.dcm - Predicted coordinates (x, y) = (2.56, 4.16)\n",
      "Image 270: data/train_images_origin/2728988942/632466427/13.dcm - Predicted coordinates (x, y) = (0.25, 0.11)\n",
      "Image 271: data/train_images_origin/3258126294/918902957/4.dcm - Predicted coordinates (x, y) = (4.96, 7.96)\n",
      "Image 272: data/train_images_origin/1261271580/813965073/2.dcm - Predicted coordinates (x, y) = (5.27, 9.04)\n",
      "Image 273: data/train_images_origin/983365930/680927594/9.dcm - Predicted coordinates (x, y) = (9.81, 16.58)\n",
      "Image 274: data/train_images_origin/2728988942/632466427/2.dcm - Predicted coordinates (x, y) = (1.57, 2.36)\n",
      "Image 275: data/train_images_origin/3362964060/818865502/14.dcm - Predicted coordinates (x, y) = (4.83, 7.77)\n",
      "Image 276: data/train_images_origin/1431195383/3551899591/2.dcm - Predicted coordinates (x, y) = (9.15, 15.37)\n",
      "Image 277: data/train_images_origin/2427880799/2570719913/12.dcm - Predicted coordinates (x, y) = (13.87, 23.35)\n",
      "Image 278: data/train_images_origin/3426816011/972430749/2.dcm - Predicted coordinates (x, y) = (5.38, 8.80)\n",
      "Image 279: data/train_images_origin/1261271580/1629954928/14.dcm - Predicted coordinates (x, y) = (3.89, 6.61)\n",
      "Image 280: data/train_images_origin/4271960965/316501793/12.dcm - Predicted coordinates (x, y) = (4.48, 7.41)\n",
      "Image 281: data/train_images_origin/823937142/1743883669/1.dcm - Predicted coordinates (x, y) = (8.37, 13.77)\n",
      "Image 282: data/train_images_origin/4246183162/2898345470/10.dcm - Predicted coordinates (x, y) = (0.26, -0.06)\n",
      "Image 283: data/train_images_origin/3319644132/157107762/13.dcm - Predicted coordinates (x, y) = (3.02, 4.89)\n",
      "Image 284: data/train_images_origin/2323872325/2705541433/12.dcm - Predicted coordinates (x, y) = (8.50, 14.32)\n",
      "Image 285: data/train_images_origin/1737682527/1258728011/1.dcm - Predicted coordinates (x, y) = (7.92, 13.58)\n",
      "Image 286: data/train_images_origin/3319644132/3781889921/13.dcm - Predicted coordinates (x, y) = (4.64, 7.52)\n",
      "Image 287: data/train_images_origin/594735110/3717729365/13.dcm - Predicted coordinates (x, y) = (7.94, 13.65)\n",
      "Image 288: data/train_images_origin/1751480356/4154954091/9.dcm - Predicted coordinates (x, y) = (2.54, 3.95)\n",
      "Image 289: data/train_images_origin/711877989/2747541553/9.dcm - Predicted coordinates (x, y) = (12.14, 20.55)\n",
      "Image 290: data/train_images_origin/2809323451/348943421/3.dcm - Predicted coordinates (x, y) = (1.47, 2.16)\n",
      "Image 291: data/train_images_origin/1302048123/782258336/14.dcm - Predicted coordinates (x, y) = (7.98, 13.58)\n",
      "Image 292: data/train_images_origin/1835489622/2569745110/8.dcm - Predicted coordinates (x, y) = (10.37, 17.86)\n",
      "Image 293: data/train_images_origin/1812655676/2408010873/10.dcm - Predicted coordinates (x, y) = (3.48, 5.58)\n",
      "Image 294: data/train_images_origin/3202723468/2127329151/13.dcm - Predicted coordinates (x, y) = (1.11, 1.46)\n",
      "Image 295: data/train_images_origin/3252162306/2124596461/2.dcm - Predicted coordinates (x, y) = (7.09, 11.86)\n",
      "Image 296: data/train_images_origin/4238265702/1938347296/7.dcm - Predicted coordinates (x, y) = (5.21, 8.63)\n",
      "Image 297: data/train_images_origin/1722308532/271934733/5.dcm - Predicted coordinates (x, y) = (1.73, 2.84)\n",
      "Image 298: data/train_images_origin/3819260179/1735851779/3.dcm - Predicted coordinates (x, y) = (4.36, 6.98)\n",
      "Image 299: data/train_images_origin/2938658366/2929023438/14.dcm - Predicted coordinates (x, y) = (9.44, 16.17)\n",
      "Image 300: data/train_images_origin/1504031267/2784380684/18.dcm - Predicted coordinates (x, y) = (0.00, -0.37)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from PIL import Image\n",
    "import pydicom  # Import pydicom to handle DICOM files\n",
    "\n",
    "# Step 1: Define the transformation to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to the expected input size of the model\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB (3 channels)\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization\n",
    "])\n",
    "\n",
    "# Step 2: Define a custom Dataset to load images from the DataFrame\n",
    "class MRILocalizationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.data.iloc[idx]['image_path']\n",
    "        dicom_image = pydicom.dcmread(image_path)  # Read the DICOM file\n",
    "        image_array = dicom_image.pixel_array.astype('float32')  # Convert the DICOM pixel data to float32\n",
    "\n",
    "        image = Image.fromarray(image_array)  # Convert NumPy array to PIL Image\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply transformations (including ToTensor)\n",
    "\n",
    "        return image, image_path\n",
    "\n",
    "\n",
    "# Replace <run_id> with your actual run ID and <path_to_model> with the artifact path used during logging\n",
    "model_path = r\"C:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\mlruns\\357139645848513089\\1c2325d59a33452aab3a227c92533df9\\artifacts\\final_model\"\n",
    "loaded_model = mlflow.pytorch.load_model(model_path)\n",
    "\n",
    "loaded_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Check if CUDA is available and use GPU if possible, otherwise fall back to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Ensure the model is moved to the right device\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "\n",
    "# Step 5: Define a function to localize images\n",
    "def localize_images(model, test_df, transform):\n",
    "    dataset = MRILocalizationDataset(test_df, transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)  # Load one image at a time\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():  # No need to track gradients during inference\n",
    "        for images, image_paths in dataloader:\n",
    "            images = images.to(device)  # Move image to the correct device (GPU/CPU)\n",
    "            outputs = model(images)  # Get the model's predictions (x, y coordinates)\n",
    "            predicted_x, predicted_y = outputs[0]  # Assuming model outputs a tuple (x, y)\n",
    "            predictions.append((predicted_x.item(), predicted_y.item(), image_paths[0]))\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Step 6: Get predictions for new images\n",
    "predictions = localize_images(loaded_model, test_df, transform)\n",
    "\n",
    "# Step 7: Print predictions\n",
    "for idx, (x, y, image_path) in enumerate(predictions):\n",
    "    print(f\"Image {idx+1}: {image_path} - Predicted coordinates (x, y) = ({x:.2f}, {y:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[195], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m     17\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 19\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Calculate class probabilities\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     _, predicted_classes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[1;32m--> 273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:161\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    158\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n\u001b[0;32m    160\u001b[0m out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m identity\n\u001b[1;32m--> 161\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m(out)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[1;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# calculate prbabilities and probability list\n",
    "# calculate prbabilities and probability list\n",
    "\n",
    "# FILEPATH: /c:/Users/HP1/Desktop/Spiced/capstone-project/_5_training_localization_3_cat.ipynb\n",
    "test_dataset = MRILocalizationDataset(data=test_data, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Inference loop with probability extraction\n",
    "results = []\n",
    "probabilities_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        probabilities = torch.softmax(outputs, dim=1)  # Calculate class probabilities\n",
    "        _, predicted_classes = torch.max(outputs, 1)\n",
    "        \n",
    "        # Append predictions and probabilities\n",
    "        results.append(predicted_classes.item())\n",
    "        probabilities_list.append(probabilities.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>Probability_Class_0</th>\n",
       "      <th>Probability_Class_1</th>\n",
       "      <th>Predicted_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>2775207739</td>\n",
       "      <td>data/train_images_origin/2775207739/3249541180...</td>\n",
       "      <td>0.4744</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>664153360</td>\n",
       "      <td>data/train_images_origin/664153360/1076245514/...</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>2273432465</td>\n",
       "      <td>data/train_images_origin/2273432465/114306451/...</td>\n",
       "      <td>0.3093</td>\n",
       "      <td>0.6907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8486</th>\n",
       "      <td>3777149998</td>\n",
       "      <td>data/train_images_origin/3777149998/3550597941...</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8959</th>\n",
       "      <td>3967802493</td>\n",
       "      <td>data/train_images_origin/3967802493/2054070341...</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.9396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        study_id                                         image_path  Probability_Class_0  Probability_Class_1  Predicted_Class\n",
       "6296  2775207739  data/train_images_origin/2775207739/3249541180...               0.4744               0.5256                1\n",
       "1496   664153360  data/train_images_origin/664153360/1076245514/...               0.1012               0.8988                1\n",
       "5040  2273432465  data/train_images_origin/2273432465/114306451/...               0.3093               0.6907                1\n",
       "8486  3777149998  data/train_images_origin/3777149998/3550597941...               0.2470               0.7530                1\n",
       "8959  3967802493  data/train_images_origin/3967802493/2054070341...               0.0604               0.9396                1"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list of probabilities to a numpy array for easier manipulation\n",
    "probabilities_array = np.vstack(probabilities_list)\n",
    "\n",
    "# Ensure the length of probabilities_array matches the length of test_df\n",
    "probabilities_array = probabilities_array[:len(test_df)]\n",
    "\n",
    "# Add the probabilities to the test_df DataFrame\n",
    "test_df['Probability_Class_0'] = probabilities_array[:, 0]\n",
    "test_df['Probability_Class_1'] = probabilities_array[:, 1]\n",
    " \n",
    "\n",
    "# Round the probabilities to 4 decimal places\n",
    "test_df['Probability_Class_0'] = test_df['Probability_Class_0'].round(4)\n",
    "test_df['Probability_Class_1'] = test_df['Probability_Class_1'].round(4)\n",
    " \n",
    "# Add the predicted classes to the test_df DataFrame\n",
    "test_df['Predicted_Class'] = results\n",
    "\n",
    "\n",
    "\n",
    "# Display the updated DataFrame\n",
    " \n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'severity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'severity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[191], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m conf_matrix_prob_df \u001b[38;5;241m=\u001b[39m severity_prob_sum_all_classes \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create a confusion matrix from severity and predicted class\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m conf_matrix_severity_pred \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseverity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_Class\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Create a DataFrame from the confusion matrix\u001b[39;00m\n\u001b[0;32m     13\u001b[0m conf_matrix_severity_pred_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     14\u001b[0m     conf_matrix_severity_pred, \n\u001b[0;32m     15\u001b[0m     index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(conf_matrix_severity_pred))], \n\u001b[0;32m     16\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(conf_matrix_severity_pred[\u001b[38;5;241m0\u001b[39m]))]\n\u001b[0;32m     17\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'severity'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Group by severity and sum the Probability_Class_1\n",
    "severity_prob_sum_all_classes = test_df[['Probability_Class_0', 'Probability_Class_1']].mean()\n",
    "\n",
    "# Print the result\n",
    "severity_prob_sum_all_classes\n",
    "# Use severity_prob_sum_all_classes as confusion matrix\n",
    "conf_matrix_prob_df = severity_prob_sum_all_classes \n",
    "# Create a confusion matrix from severity and predicted class\n",
    "conf_matrix_severity_pred = confusion_matrix(test_df['severity'], test_df['Predicted_Class'])\n",
    "\n",
    "# Create a DataFrame from the confusion matrix\n",
    "conf_matrix_severity_pred_df = pd.DataFrame(\n",
    "    conf_matrix_severity_pred, \n",
    "    index=[f\"Actual {i}\" for i in range(len(conf_matrix_severity_pred))], \n",
    "    columns=[f\"Predicted {i}\" for i in range(len(conf_matrix_severity_pred[0]))]\n",
    ")\n",
    "\n",
    "# Print the confusion matrix DataFrame\n",
    "print(conf_matrix_severity_pred_df)\n",
    "\n",
    "# Optionally, display it using a more formatted view (e.g., in Jupyter Notebook)\n",
    "conf_matrix_severity_pred_df.style.background_gradient(cmap='Blues')\n",
    "# Print the confusion matrix DataFrame\n",
    "print(conf_matrix_prob_df)\n",
    "\n",
    "# Optionally, display it using a more formatted view (e.g., in Jupyter Notebook)\n",
    "conf_matrix_prob_df.style.background_gradient(cmap='Blues')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
