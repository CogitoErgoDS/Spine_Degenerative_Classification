{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP1\\Desktop\\Spiced\\ds-artificial-neural-networks\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import optuna\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "KAPPA_SCORER = make_scorer(\n",
    "    cohen_kappa_score, \n",
    "    greater_is_better=True, \n",
    "    weights='quadratic',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial):\n",
    "    params = {\n",
    "        'objective':         'l2',\n",
    "        'verbosity':         -1,\n",
    "        'n_iter':            200,\n",
    "        'random_state':      SEED,\n",
    "        'boosting_type':     'gbdt',\n",
    "        'lambda_l1':         trial.suggest_float('lambda_l1', 1e-3, 10.0, log=True),\n",
    "        'lambda_l2':         trial.suggest_float('lambda_l2', 1e-3, 10.0, log=True),\n",
    "        'learning_rate':     trial.suggest_float('learning_rate', 1e-2, 1e-1, log=True),\n",
    "        'max_depth':         trial.suggest_int('max_depth', 4, 8),\n",
    "        'num_leaves':        trial.suggest_int('num_leaves', 16, 256),\n",
    "        'colsample_bytree':  trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'colsample_bynode':  trial.suggest_float('colsample_bynode', 0.4, 1.0),\n",
    "        'bagging_fraction':  trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq':      trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_data_in_leaf':  trial.suggest_int('min_data_in_leaf', 5, 100),\n",
    "    }\n",
    "    \n",
    "    X = df_train[feature_cols]\n",
    "    y = df_train[target_col]\n",
    "    cv = StratifiedKFold(5, shuffle=True, random_state=SEED)\n",
    "    estimator = CustomLGBMRegressor(**params)\n",
    "\n",
    "    val_scores = cross_val_score(\n",
    "        estimator=estimator, \n",
    "        X=X, y=y, \n",
    "        cv=cv, \n",
    "        scoring=KAPPA_SCORER,\n",
    "    )\n",
    "\n",
    "    return np.mean(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    \n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_time_series(dirname):\n",
    "    ids = os.listdir(dirname)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "    stats, indexes = zip(*results)\n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(estimator, X, y_true):\n",
    "    y_pred = estimator.predict(X).round()\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_rounder(y_pred, thresholds):\n",
    "    return np.where(y_pred < thresholds[0], 0,\n",
    "                    np.where(y_pred < thresholds[1], 1,\n",
    "                             np.where(y_pred < thresholds[2], 2, 3)))\n",
    "\n",
    "def eval_preds(thresholds, y_true, y_pred):\n",
    "    y_pred = threshold_rounder(y_pred, thresholds)\n",
    "    score = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "    return -score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLGBMRegressor(lgb.LGBMRegressor):\n",
    "    '''\n",
    "    Custom LightGBM Regressor\n",
    "    \n",
    "    It optimizes threshold values during fitting.\n",
    "    Main goal is preventing overfit on validation data.\n",
    "    '''\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        super().fit(X, y, **kwargs)\n",
    "        y_pred = super().predict(X, **kwargs)\n",
    "        \n",
    "        self.optimizer = minimize(\n",
    "            eval_preds, \n",
    "            x0=[0.5, 1.5, 2.5], \n",
    "            args=(y, y_pred), \n",
    "            method='Nelder-Mead',\n",
    "        )\n",
    "        \n",
    "    def predict(self, X, **kwargs):\n",
    "        y_pred = super().predict(X, **kwargs)\n",
    "        y_pred = threshold_rounder(y_pred, self.optimizer.x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/kaggle/input/child-mind-institute-problematic-internet-use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tabular Data\n",
    "\n",
    "df_train = pd.read_csv(root / 'train.csv')\n",
    "df_test = pd.read_csv(root / 'test.csv')\n",
    "df_subm = pd.read_csv(root / 'sample_submission.csv', index_col='id')\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Data\n",
    "ts_train = load_time_series(root / \"series_train.parquet\")\n",
    "ts_test = load_time_series(root / \"series_test.parquet\")\n",
    "\n",
    "time_series_cols = ts_train.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, ts_train, how=\"left\", on='id')\n",
    "df_test = pd.merge(df_test, ts_test, how=\"left\", on='id')\n",
    "\n",
    "df_train = df_train.set_index('id')\n",
    "df_test = df_test.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', 'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', 'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "num_cols = ['Basic_Demos-Age', 'Basic_Demos-Sex', 'CGAS-CGAS_Score', 'Physical-BMI', 'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference', 'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP', 'Fitness_Endurance-Max_Stage', 'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND', 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU', 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR', 'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI', 'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM', 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num', 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM', 'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total', 'PAQ_C-PAQ_C_Total', 'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday']\n",
    "tabular_cols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex', 'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI', 'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference', 'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP', 'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage', 'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec', 'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND', 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU', 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR', 'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season', 'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI', 'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM', 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num', 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM', 'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season', 'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T', 'PreInt_EduHx-Season', 'PreInt_EduHx-computerinternet_hoursday']\n",
    "target_col = 'sii'\n",
    "\n",
    "feature_cols = tabular_cols + time_series_cols\n",
    "num_cols = num_cols + time_series_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(\n",
    "    strategy='mean',\n",
    ")\n",
    "\n",
    "df_train[num_cols] = imputer.fit_transform(df_train[num_cols])\n",
    "df_test[num_cols] = imputer.transform(df_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder(\n",
    "    dtype=np.int32,\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-1,\n",
    "    encoded_missing_value=-2,\n",
    ")\n",
    "\n",
    "df_train[cat_cols] = encoder.fit_transform(df_train[cat_cols])\n",
    "df_train[cat_cols] = df_train[cat_cols].astype('category')\n",
    "\n",
    "df_test[cat_cols] = encoder.transform(df_test[cat_cols])\n",
    "df_test[cat_cols] = df_test[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective'       : 'l2',\n",
    "    'verbosity'       : -1,\n",
    "    'n_iter'          : 200,\n",
    "    'lambda_l1'       : 0.005116829730239727,\n",
    "    'lambda_l2'       : 0.0011520776712645852,\n",
    "    'learning_rate'   : 0.02376367323636638,\n",
    "    'max_depth'       : 5,\n",
    "    'num_leaves'      : 207,\n",
    "    'colsample_bytree': 0.7759862336963801,\n",
    "    'colsample_bynode': 0.5110355095943208,\n",
    "    'bagging_fraction': 0.5485770314992224,\n",
    "    'bagging_freq'    : 7,\n",
    "    'min_data_in_leaf': 78,\n",
    "}\n",
    "\n",
    "model = CustomLGBMRegressor(**params, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[feature_cols]\n",
    "y = df_train[target_col]\n",
    "cv = StratifiedKFold(5, shuffle=True, random_state=SEED)\n",
    "\n",
    "val_scores = cross_val_score(\n",
    "    model, X, y, cv=cv, \n",
    "    scoring=KAPPA_SCORER,\n",
    ")\n",
    "\n",
    "print(f'kappa score: {np.mean(val_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VotingRegressor([\n",
    "    ('lgb_0', CustomLGBMRegressor(**params, random_state=12)),\n",
    "    ('lgb_1', CustomLGBMRegressor(**params, random_state=22)),\n",
    "    ('lgb_2', CustomLGBMRegressor(**params, random_state=32)),\n",
    "    ('lgb_3', CustomLGBMRegressor(**params, random_state=42)),\n",
    "    ('lgb_4', CustomLGBMRegressor(**params, random_state=52)),\n",
    "    ('lgb_5', CustomLGBMRegressor(**params, random_state=62)),\n",
    "    ('lgb_6', CustomLGBMRegressor(**params, random_state=72)),\n",
    "    ('lgb_7', CustomLGBMRegressor(**params, random_state=82)),\n",
    "    ('lgb_8', CustomLGBMRegressor(**params, random_state=92)),\n",
    "    ('lgb_9', CustomLGBMRegressor(**params, random_state=102)),\n",
    "])\n",
    "\n",
    "# Training\n",
    "\n",
    "X = df_train[feature_cols]\n",
    "y = df_train[target_col]\n",
    "\n",
    "model.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_subm[target_col] = model.predict(df_test[feature_cols])\n",
    "df_subm[target_col] = df_subm[target_col].round()\n",
    "\n",
    "df_subm.to_csv('submission.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
