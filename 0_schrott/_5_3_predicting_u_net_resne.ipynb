{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "import mlflow\n",
    "import mlflow.pytorch \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from pydicom.data import get_testdata_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    " # Import functions from the module\n",
    "import importlib\n",
    "import help_files._0_definitions \n",
    "import  help_files._1_visuals_script\n",
    "# import  help_files._01_load_data\n",
    " # Reload the module to apply the changes to the script\n",
    "importlib.reload(help_files._0_definitions)\n",
    "importlib.reload(help_files._1_visuals_script)\n",
    "# importlib.reload(help_files._01_load_data)\n",
    "import  help_files._1_visuals_script  as pauls_vs\n",
    "# Group by 'condition', 'level', and 'severity' and count occurrences\n",
    "from help_files._0_definitions import count_severity_by_condition_level \n",
    "# Define the path\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.width\", 1000)  # Set a large width to prevent line wrapping\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### In definitions are all the functions that are used in the notebook and globals\n",
    "with open(\"help_files/_0_definitions.py\") as file:\n",
    "    exec(file.read())\n",
    "    ### In definitions are all the functions that are used in the notebook and globals\n",
    "with open(\"help_files/_0_run_definitions.py\") as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "file_names = [\"train_df_3_cat.csv\", \"test_df_3_cat.csv\"]\n",
    "# Load the data from the CSV files\n",
    "dataframes = [pd.read_csv(data_path_vor / file_name) for file_name in file_names]\n",
    "# Unpack the dataframes into separate variables\n",
    "train_df, test_df = dataframes\n",
    "\n",
    "print(\"DataFrames have been loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining small sample vs. end smaple\n",
    "whole_data_set = False\n",
    "# end sample or small sample    \n",
    "if whole_data_set == True:\n",
    "    print(\"Using the whole data set\")\n",
    "else:\n",
    "\n",
    "    test_df = test_df.sample(n=20, random_state=RSEED)\n",
    "    display(Markdown('<span style=\"color:red\"> this is a small sample : 48692</span>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calss definition dataloader (do not change over models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: U-Net Model and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test predicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_df = test_df.drop(['severity', 'condition', 'level', 'series_id', 'missing_image'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.to_string(index=False, header=True)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <run_id> with your actual run ID and <path_to_model> with the artifact path used during logging\n",
    "model_path = r\"C:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\mlruns\\388846461532362513\\3f95f17d16ec4e53bb1ef451c608886e\\artifacts\\final_model\"\n",
    "model_for_prediciton = mlflow.pytorch.load_model(model_path)\n",
    "\n",
    "model_for_prediciton.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "\n",
    "class MRILocalizationDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx]['image_path']\n",
    "        dicom_image = pydicom.dcmread(img_path)\n",
    "        image_array = dicom_image.pixel_array\n",
    "        image = Image.fromarray(image_array)\n",
    "\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image  # No coordinates returned, as we are predicting them\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_for_prediction.eval()\n",
    "\n",
    "# Prepare the new test dataset (without coordinates) and DataLoader\n",
    "test_dataset = MRILocalizationDataset(data=test_df, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_for_prediction.to(device)\n",
    "\n",
    "# Initialize the list to store predicted coordinates\n",
    "predicted_coords = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model_for_prediction(images)  # Predict x, y coordinates\n",
    "        outputs = outputs.cpu().numpy()\n",
    "# Check the output shape directly\n",
    "print(f\"Output shape: {outputs.shape}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "\n",
    "class MRILocalizationDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx]['image_path']\n",
    "        dicom_image = pydicom.dcmread(img_path)\n",
    "        image_array = dicom_image.pixel_array\n",
    "        image = Image.fromarray(image_array)\n",
    "\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image  # No coordinates returned, as we are predicting them\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_for_prediction.eval()\n",
    "\n",
    "# Prepare the new test dataset (without coordinates) and DataLoader\n",
    "test_dataset = MRILocalizationDataset(data=test_df, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_for_prediction.to(device)\n",
    "\n",
    "# Initialize the list to store predicted coordinates\n",
    "predicted_coords = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model_for_prediction(images)  # Predict x, y coordinates\n",
    "        outputs = outputs.cpu().numpy()\n",
    "\n",
    "        for output in outputs:\n",
    "            x_pred, y_pred = output  # Predicted coordinates for x, y\n",
    "            \n",
    "            # Apply scaling if images were resized during training\n",
    "            scaling_factor = 256 / 128  # Adjust based on your resizing factors\n",
    "            x_original = x_pred * scaling_factor\n",
    "            y_original = y_pred * scaling_factor\n",
    "\n",
    "            predicted_coords.append((x_original, y_original))\n",
    "\n",
    "# Save the predicted coordinates along with the original test data\n",
    "output_df = pd.DataFrame(predicted_coords, columns=['x', 'y'])\n",
    "test_df_with_preds = pd.concat([test_df.reset_index(drop=True), output_df], axis=1)\n",
    "test_df_with_preds.to_csv(\"test_with_predicted_coordinates.csv\", index=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predicted_coords = []  # Initialize the list to store predicted coordinates\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        heatmaps = model(images)\n",
    "        heatmaps = heatmaps.cpu().numpy()\n",
    "\n",
    "        # Check if heatmaps is 4D (batch_size, channels, height, width)\n",
    "        if heatmaps.ndim == 4:\n",
    "            for batch_idx in range(heatmaps.shape[0]):  # Iterate over batch\n",
    "                heatmap = heatmaps[batch_idx, 0]  # Assuming we have only one channel\n",
    "                heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap)) if np.max(heatmap) != np.min(heatmap) else heatmap\n",
    "\n",
    "                if np.max(heatmap) > 0.5:  # Adjust the threshold as needed\n",
    "                    y, x = np.unravel_index(np.argmax(heatmap, axis=None), heatmap.shape)\n",
    "                    predicted_coords.append((x, y))\n",
    "                else:\n",
    "                    predicted_coords.append((np.nan, np.nan))  # Assign NaN if no valid peak\n",
    "        else:\n",
    "            print(f\"Unexpected heatmap dimensions: {heatmaps.shape}\")\n",
    "\n",
    "# Save the predicted coordinates along with the original test data\n",
    "output_df = pd.DataFrame(predicted_coords, columns=['x', 'y'])\n",
    "test_df_with_preds = pd.concat([test_df.reset_index(drop=True), output_df], axis=1)\n",
    "test_df_with_preds.to_csv(\"test_with_predicted_coordinates.csv\", index=False)\n",
    "\n",
    "print(\"Inference complete. Predicted coordinates saved.\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        heatmaps = model(images)\n",
    "        heatmaps = heatmaps.cpu().numpy()\n",
    "\n",
    "        for heatmap in heatmaps:\n",
    "            print(f\"Heatmap shape: {heatmap.shape}\")\n",
    "            print(f\"Heatmap values: {np.min(heatmap)}, {np.max(heatmap)}\")\n",
    "            if heatmap.ndim == 2:\n",
    "                y, x = np.unravel_index(np.argmax(heatmap, axis=None), heatmap.shape)\n",
    "                print(f\"Predicted coordinates: x={x}, y={y}\")\n",
    "                predicted_coords.append((x, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import mlflow\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the trained model from MLflow\n",
    "model_path = \"C:/Users/HP1/Desktop/Spiced/capstone-project/mlruns/491281383988954356/344ed7741b8b4cb9bf87844ab1e511af/artifacts/final_model\"\n",
    "model = mlflow.pytorch.load_model(model_path)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Prepare the new test dataset (without coordinates) and DataLoader\n",
    "test_dataset = MRILocalizationDataset(data=test_df, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)  # Ensure the model is on the right device\n",
    "\n",
    "# Inference on new test data\n",
    "predicted_coords = []\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for images, _ in test_loader:  # Unpack images and ignore labels\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)  # Get model output\n",
    "        outputs = outputs.view(outputs.size(0), -1)  # Reshape to (batch_size, 2) for x, y coordinates\n",
    "        predicted_coords.extend(outputs.cpu().numpy())  # Move to CPU and add to results\n",
    "\n",
    "# Convert the predicted coordinates to a DataFrame\n",
    "output_df = pd.DataFrame(predicted_coords, columns=['x', 'y'])\n",
    "\n",
    "# Combine original test_df with predicted coordinates\n",
    "test_df_with_preds = pd.concat([test_df.reset_index(drop=True), output_df], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
