{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('<span style=\"color:red\">later on to take it back to the original shape : 48692</span>'))\n",
    "1000\n",
    "print(df_end.to_string(index=False, header=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the transform with augmentationl\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load your DataFrame (assuming 'image_path' column contains the file paths)\n",
    "df = pd.read_csv('path/to/your_dataframe.csv')  # Update to your DataFrame path\n",
    "\n",
    "# Set the output base folder\n",
    "output_folder = r'C:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\data\\train_images_transformed'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Loop through each image path in the DataFrame\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    image_path = row['image_path']\n",
    "    relative_path = os.path.relpath(image_path, os.path.commonpath([output_folder, image_path]))\n",
    "    save_dir = os.path.join(output_folder, os.path.dirname(relative_path))\n",
    "    \n",
    "    # Create the corresponding output directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Read the DICOM image\n",
    "    dicom_image = pydicom.dcmread(image_path)\n",
    "    image_array = dicom_image.pixel_array\n",
    "\n",
    "    # Convert to 8-bit (for typical imaging)\n",
    "    image_array = cv2.normalize(image_array, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    image_rgb = cv2.cvtColor(image_array, cv2.COLOR_GRAY2RGB)  # Convert grayscale to RGB for transformations\n",
    "\n",
    "    # Apply transformations\n",
    "    image_tensor = transform(image_rgb)\n",
    "    image_transformed = image_tensor.permute(1, 2, 0).numpy()  # Change back to HxWxC\n",
    "    image_transformed = (image_transformed * 255).astype('uint8')  # Scale back to uint8\n",
    "\n",
    "    # Save the transformed image\n",
    "    output_path = os.path.join(save_dir, os.path.basename(image_path).replace('.dcm', '.png'))\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(image_transformed, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Pre-transformation complete! Total time: {total_time:.2f} seconds.\")\n",
    "print(f\"Average time per image: {total_time / len(df):.4f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from torchvision import transforms\n",
    "\n",
    "%pip install tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the transform with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Paths for original and augmented images\n",
    "input_folder = r'C:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\data\\train_images'\n",
    "output_folder = r'C:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\data\\train_images_transformed'\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Traverse each subfolder and process images\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    for file_name in tqdm(files):\n",
    "        image_path = os.path.join(root, file_name)\n",
    "        relative_path = os.path.relpath(root, input_folder)\n",
    "        save_dir = os.path.join(output_folder, relative_path)\n",
    "        \n",
    "        # Create the corresponding output directory if it doesn't exist\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Load and process each image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Warning: Could not read image {image_path}\")\n",
    "            continue\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_tensor = transform(image)\n",
    "        image_transformed = image_tensor.permute(1, 2, 0).numpy()\n",
    "        image_transformed = (image_transformed * 255).astype('uint8')\n",
    "\n",
    "        # Save the transformed image\n",
    "        output_path = os.path.join(save_dir, file_name)\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(image_transformed, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Pre-transformation complete! Total time: {total_time:.2f} seconds.\")\n",
    "print(f\"Average time per image: {total_time / len(glob.glob(os.path.join(input_folder, '**', '*.*'), recursive=True)):.4f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is pretransformation file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from torchvision import transformslk\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the transform with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Path to your images and where to save augmented images\n",
    "input_folder = 'path/to/original/images'\n",
    "output_folder = 'path/to/augmented/images'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Process and save images\n",
    "for image_path in tqdm(glob.glob(os.path.join(input_folder, '*.*'))):  # Adjust for your image file types\n",
    "    image = cv2.imread(image_path)  # Read the image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB if using OpenCV\n",
    "\n",
    "    # Apply transformations\n",
    "    image_tensor = transform(image)\n",
    "\n",
    "    # Convert back to numpy array and save\n",
    "    image_transformed = image_tensor.permute(1, 2, 0).numpy()  # Change back to HxWxC\n",
    "    image_transformed = (image_transformed * 255).astype('uint8')  # Scale back to uint8\n",
    "\n",
    "    # Save the transformed image\n",
    "    output_path = os.path.join(output_folder, os.path.basename(image_path))\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(image_transformed, cv2.COLOR_RGB2BGR))  # Convert back to BGR for OpenCV\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Pre-transformation complete! Total time: {total_time:.2f} seconds.\")\n",
    "print(f\"Average time per image: {total_time / len(glob.glob(os.path.join(input_folder, '*.*'))):.4f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "data_path = Path('C:/Users/HP1/Desktop/Spiced/child-mind-institute-problematic-internet-use/series_train.parquet/id=00f332d1')\n",
    " \n",
    "\n",
    "# Read the Parquet file\n",
    "df = pd.read_parquet(data_path  /\"part-0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_persons(dataframes, study_ids_to_keep, all_studies=False):\n",
    "    if all_studies:\n",
    "        return dataframes  # Return all DataFrames if all_studies is True\n",
    "    \n",
    "    filtered_dataframes = []\n",
    "    for df in dataframes:\n",
    "        # Filter the DataFrame based on study_ids_to_keep\n",
    "        filtered_df = df[df['study_id'].isin(study_ids_to_keep)]\n",
    "        filtered_dataframes.append(filtered_df)  # Append the filtered DataFrame to the list\n",
    "\n",
    "    return filtered_dataframes \n",
    "\n",
    " \n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'study_id': [4003253, 4003254, 4003253, 4003255],\n",
    "    'patient_name': ['Alice', 'Bob', 'Charlie', 'David']\n",
    "}\n",
    "\n",
    "df_image_paths = pd.DataFrame(data)\n",
    "\n",
    "# Using the corrected function\n",
    "study_ids_to_keep = [4003253]\n",
    "dataframes = [df_image_paths]\n",
    "\n",
    "filtered_dataframes = keep_persons(dataframes, study_ids_to_keep, all_studies=False)\n",
    "\n",
    "# Print the filtered DataFrames\n",
    "for filtered_df in filtered_dataframes:\n",
    "    print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the df_train DataFrame\n",
    "df_train = pd.DataFrame({\n",
    "    \"site_id\": [2, 2, 2, 2, 2],\n",
    "    \"patient_id\": [10006, 10006, 10006, 10006, 10011],\n",
    "    \"image_id\": [462822612, 1459541791, 1864590858, 1874946579, 220375232],\n",
    "    \"laterality\": [\"L\", \"L\", \"R\", \"R\", \"L\"],\n",
    "    \"view\": [\"CC\", \"MLO\", \"MLO\", \"CC\", \"CC\"],\n",
    "    \"age\": [61.0, 61.0, 61.0, 61.0, 55.0],\n",
    "    \"cancer\": [0, 0, 0, 0, 0],\n",
    "    \"biopsy\": [0, 0, 0, 0, 0],\n",
    "    \"invasive\": [0, 0, 0, 0, 0],\n",
    "    \"BIRADS\": [np.nan, np.nan, np.nan, np.nan, 0.0],\n",
    "    \"implant\": [0, 0, 0, 0, 0],\n",
    "    \"density\": [np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "    \"machine_id\": [29, 29, 29, 29, 21],\n",
    "    \"difficult_negative_case\": [False, False, False, False, True]\n",
    "})\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create the 'data' DataFrame with the 'class' column\n",
    "data = pd.DataFrame(\n",
    "    np.concatenate([\n",
    "        ['Total'] * len(df_train),  # Label 'Total' for each row in df_train\n",
    "        ['Malignant Cancer'] * len(df_train[df_train['cancer'] == 1]),  # Label 'Malignant Cancer' for rows with cancer == 1\n",
    "        ['Invasive Cancer'] * len(df_train[(df_train['cancer'] == 1) & (df_train['invasive'] == 1)])  # Label 'Invasive Cancer' for rows with cancer == 1 and invasive == 1\n",
    "    ]),\n",
    "    columns=[\"class\"]\n",
    ")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The not-malignant cancer cases were limited to biopsy cases.\n",
    "DF_train = df_train[df_train['biopsy'] == 1].reset_index(drop = True)\n",
    "DF_train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
