{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is pretransformation file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "# Function to create a bounding box around (x, y) coordinates\n",
    "def create_bounding_box(image, x, y, box_size=50):\n",
    "    \"\"\"\n",
    "    Draw a bounding box around the (x, y) coordinates on the given image.\n",
    "    The box size is centered around the (x, y) coordinates.\n",
    "    \"\"\"\n",
    "    image = image.convert('RGB')  # Convert to RGB\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Box size (width, height)\n",
    "    half_box = box_size // 2\n",
    "    \n",
    "    # Calculate the top-left and bottom-right corners of the bounding box\n",
    "    left = x - half_box\n",
    "    top = y - half_box\n",
    "    right = x + half_box\n",
    "    bottom = y + half_box\n",
    "    \n",
    "    # Draw the bounding box (in red color)\n",
    "    draw.rectangle([left, top, right, bottom], outline=\"red\", width=3)\n",
    "    \n",
    "    return image, left, top, right, bottom  # Return image and bounding box coordinates\n",
    "\n",
    "# Function to process all images and update the bounding boxes\n",
    "def process_images_and_create_boxes(df, box_size=50):\n",
    "    \"\"\"\n",
    "    Process each image in the DataFrame to create bounding boxes.\n",
    "    Updates the DataFrame with the bounding box coordinates.\n",
    "    \"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        # Skip rows with missing coordinates\n",
    "        if pd.isna(row['x']) or pd.isna(row['y']):\n",
    "            print(f\"Skipping index {index} due to missing x/y coordinates\")\n",
    "            continue\n",
    "        \n",
    "        image_path = row['image_path']\n",
    "        x = row['x']\n",
    "        y = row['y']\n",
    "\n",
    "        # Read the DICOM image\n",
    "        try:\n",
    "            dicom_image = pydicom.dcmread(image_path)\n",
    "            image = dicom_image.pixel_array.astype(float)\n",
    "            image = (image / image.max() * 255).astype('uint8')  # Normalize image\n",
    "\n",
    "            # Convert grayscale to RGB if necessary\n",
    "            if len(image.shape) == 2:  # Grayscale image\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            # Convert the image to a PIL Image object for bounding box drawing\n",
    "            image = Image.fromarray(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading DICOM image at index {index}: {e}\")\n",
    "            continue  # Skip invalid images\n",
    "\n",
    "        # Create a bounding box around the (x, y) coordinates\n",
    "        image_with_box, left, top, right, bottom = create_bounding_box(image, x, y, box_size)\n",
    "\n",
    "        # Update DataFrame with bounding box coordinates\n",
    "        df.at[index, 'x_min'] = left\n",
    "        df.at[index, 'y_min'] = top\n",
    "        df.at[index, 'x_max'] = right\n",
    "        df.at[index, 'y_max'] = bottom\n",
    "\n",
    "        # Optionally: Save image with box if needed (example saving the first image)\n",
    "        if index == 0:  # You can change this to save multiple or all images\n",
    "            image_with_box.save(f\"image_with_box_{index}.png\")\n",
    "        \n",
    "        print(f\"Updated bounding box for index {index}: x_min={left}, y_min={top}, x_max={right}, y_max={bottom}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Assuming train_df is already loaded\n",
    "# Process images and update bounding boxes\n",
    "train_df = process_images_and_create_boxes(train_df)\n",
    "\n",
    "# Save the updated DataFrame with bounding boxes\n",
    "train_df.to_csv('train_with_boxes.csv', index=False)\n",
    "\n",
    "# Print the updated bounding boxes\n",
    "print(train_df[['x_min', 'y_min', 'x_max', 'y_max']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import pydicom\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Create a new experiment in MLflow\n",
    "Resnet50_class_seg1_seg1_basic = \"Resnet50_class_seg1_seg1_basic\"\n",
    "mlflow.set_experiment(Resnet50_class_seg1_seg1_basic)\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, mode='classification'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (pd.DataFrame): Data containing image paths and corresponding labels.\n",
    "            transform (callable, optional): Optional transformation to apply to images.\n",
    "            mode (str): Mode can be 'localization' or 'classification'.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        # Return the number of samples in the dataset (usually rows in your DataFrame)\n",
    "        return len(self.data)\n",
    "    \n",
    "    def create_bounding_box(self, x, y, image_shape):\n",
    "        \"\"\"\n",
    "        Create a bounding box based on the x, y coordinates.\n",
    "        Assumes a small bounding box around the coordinates.\n",
    "        \"\"\"\n",
    "        margin = 20  # Example margin for the bounding box\n",
    "        x_min = max(0, int(x - margin))\n",
    "        y_min = max(0, int(y - margin))\n",
    "        x_max = min(image_shape[1], int(x + margin))\n",
    "        y_max = min(image_shape[0], int(y + margin))\n",
    "        return x_min, y_min, x_max, y_max\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image_tensor, label) where label is either a class label (for classification)\n",
    "                   or coordinates (for localization).\n",
    "        \"\"\"\n",
    "        row = self.data.iloc[index]\n",
    "        image_path = row['image_path']\n",
    "        x, y = row['x'], row['y']\n",
    "        label = row['severity']  # Use severity for classification tasks\n",
    "        \n",
    "        dicom_image = pydicom.dcmread(image_path)\n",
    "        image = dicom_image.pixel_array.astype(float)\n",
    "        image = (image / image.max() * 255).astype('uint8')  # Normalize\n",
    "\n",
    "        # Convert grayscale to RGB if necessary\n",
    "        if len(image.shape) == 2:  # Grayscale image\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        # Apply transformations\n",
    "        image_tensor = self.transform(image) if self.transform else torch.from_numpy(image).permute(2, 0, 1)\n",
    "\n",
    "        if self.mode == 'localization':\n",
    "            # Create a bounding box for localization\n",
    "            x_min, y_min, x_max, y_max = self.create_bounding_box(x, y, image.shape)\n",
    "            bounding_box = torch.tensor([x_min, y_min, x_max, y_max], dtype=torch.float32)\n",
    "            return image_tensor, bounding_box\n",
    "        elif self.mode == 'classification':\n",
    "            # Crop the image to the bounding box if in classification mode after localization\n",
    "            x_min, y_min, x_max, y_max = self.create_bounding_box(x, y, image.shape)\n",
    "            cropped_image = image[y_min:y_max, x_min:x_max]\n",
    "            cropped_image_tensor = self.transform(cropped_image) if self.transform else torch.from_numpy(cropped_image).permute(2, 0, 1)\n",
    "            \n",
    "            # Ensure label is of type long (for CrossEntropyLoss)\n",
    "            return cropped_image_tensor, torch.tensor(label).long()  # Ensure label is long tensor\n",
    "\n",
    "\n",
    "# Ensure the data only contains .dcm files\n",
    "train_data = train_data[train_data['image_path'].str.endswith('.dcm')]\n",
    "\n",
    "# Create the dataset\n",
    "dataset = MRIDataset(data=train_data, transform=transform)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split indices for training and validation datasets\n",
    "train_indices, val_indices = train_test_split(\n",
    "    list(range(len(dataset))), test_size=0.2, random_state=42, stratify=dataset.data['severity']\n",
    ")\n",
    "\n",
    "# Create subsets based on the indices\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load ResNet-50 and set up for classification\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = train_data['severity'].nunique()\n",
    "\n",
    "model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "learning_rate = 0.0001\n",
    "criterion_cel = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 20\n",
    "\n",
    "# Early stopping parameters\n",
    "diverge_count = 0              # Counter for divergence-based stopping\n",
    "stop_threshold = 0.3           # Threshold for divergence\n",
    "max_diverge_count = 3          # Max number of epochs with diverging validation loss\n",
    "patience = 5  # Number of epochs to wait for improvement before early stopping\n",
    " \n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"num_classes\", num_classes)\n",
    "    mlflow.log_param(\"model_architecture\", \"ResNet-50\")\n",
    "    \n",
    "    # Log early stopping parameters\n",
    "    mlflow.log_param(\"stop_threshold\", stop_threshold)\n",
    "    mlflow.log_param(\"max_diverge_count\", max_diverge_count)\n",
    "    mlflow.log_param(\"patience\", patience)\n",
    "    \n",
    "    # Set descriptive tags for the model\n",
    "    mlflow.set_tag(\"model_description\", \"ResNet-50 for classification using MRI images\")\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    example_input = torch.randn(1, 3, 224, 224)  # Batch size 1, 3 color channels, 224x224 image\n",
    "    train_losses_cel = []  # List to store training losses\n",
    "    val_losses_cel = []  # List to store validation losses\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss_cel_train = 0.0\n",
    "\n",
    "        for images, labels in train_loader: \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Cross Entropy Loss\n",
    "            loss_cel = criterion_cel(outputs, labels)\n",
    "            running_loss_cel_train += loss_cel.item()\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss_cel.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate average training loss for the epoch\n",
    "        epoch_loss_cel_train = running_loss_cel_train / len(train_loader)\n",
    "        train_losses_cel.append(epoch_loss_cel_train)\n",
    "\n",
    "        # Log training loss to MLflow\n",
    "        mlflow.log_metric(\"train_loss_cel\", epoch_loss_cel_train, step=epoch)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss_cel_val = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Cross Entropy Loss for validation\n",
    "                loss_cel = criterion_cel(outputs, labels)\n",
    "                running_loss_cel_val += loss_cel.item()\n",
    "\n",
    "        # Calculate validation loss for the epoch\n",
    "        epoch_loss_cel_val = running_loss_cel_val / len(val_loader)\n",
    "        val_losses_cel.append(epoch_loss_cel_val)\n",
    "\n",
    "        # Log validation loss to MLflow\n",
    "        mlflow.log_metric(\"val_loss_cel\", epoch_loss_cel_val, step=epoch)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "              f'Train Cross Entropy Loss: {epoch_loss_cel_train:.4f}, '\n",
    "              f'Validation Cross Entropy Loss: {epoch_loss_cel_val:.4f}')\n",
    "\n",
    "        # Save weights for each epoch\n",
    "        epoch_weight_path = f\"model_weights_epoch_{epoch + 1}.pt\"\n",
    "        torch.save(model.state_dict(), epoch_weight_path)\n",
    "        mlflow.log_artifact(epoch_weight_path)  # Log model weights as artifact for each epoch\n",
    "        os.remove(epoch_weight_path)  # Optionally, delete the local file after logging\n",
    "\n",
    "        # Check for early stopping (divergence-based stopping)\n",
    "        if epoch_loss_cel_val > epoch_loss_cel_train * (1 + stop_threshold):\n",
    "            diverge_count += 1\n",
    "            if diverge_count >= max_diverge_count:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} due to divergence.\")\n",
    "                break\n",
    "        else:\n",
    "            diverge_count = 0\n",
    "\n",
    "        # Check for early stopping (patience-based stopping)\n",
    "        if epoch_loss_cel_val < best_val_loss:\n",
    "            best_val_loss = epoch_loss_cel_val\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} due to no improvement in validation loss.\")\n",
    "                break\n",
    "\n",
    "    # Final model log\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('path_to_your_image.dcm')\n",
    "image = transform(image)\n",
    "print(image.shape)  # Expected output: torch.Size([3, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import pydicom\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Create a new experiment in MLflow\n",
    "Resnet50_class_seg1_seg1_basic = \"Resnet50_class_seg1_seg1_basic\"\n",
    "mlflow.set_experiment(Resnet50_class_seg1_seg1_basic)\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define the Dataset class\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.data['severity'] = self.data['severity'].astype(int)  # Ensure severity is an integer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        image_path = row['image_path']\n",
    "        label = row['severity']  # Use severity for the label\n",
    "\n",
    "        dicom_image = pydicom.dcmread(image_path)\n",
    "        image = dicom_image.pixel_array.astype(float)\n",
    "        image = (image / image.max() * 255).astype('uint8')  # Normalize\n",
    "\n",
    "        # Convert grayscale to RGB if necessary\n",
    "        if len(image.shape) == 2:  # Grayscale image\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        image_tensor = self.transform(image) if self.transform else torch.from_numpy(image).permute(2, 0, 1)\n",
    "        return image_tensor, torch.tensor(label).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# Ensure the data only contains .dcm files\n",
    "train_data = train_data[train_data['image_path'].str.endswith('.dcm')]\n",
    "\n",
    "# Create the dataset\n",
    "dataset = MRIDataset(data=train_data, transform=transform)\n",
    "\n",
    "# Split the dataset into training and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load ResNet-50 and set up for classification\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = train_data['severity'].nunique()\n",
    "\n",
    "model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "learning_rate = 0.0001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 20\n",
    "\n",
    "# Early stopping parameters\n",
    "diverge_count = 0              # Counter for divergence-based stopping\n",
    "stop_threshold = 0.3           # Threshold for divergence\n",
    "max_diverge_count = 3          # Max number of epochs with diverging validation loss\n",
    "patience = 5  # Number of epochs to wait for improvement before early stopping\n",
    "# Early stopping parameters\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"learning_rate\", 'learning_rate')\n",
    "    mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "    mlflow.log_param(\"batch_size\", 'batch_size')\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"num_classes\", num_classes)\n",
    "    mlflow.log_param(\"model_architecture\", \"ResNet-50\")\n",
    "    \n",
    "    # Log early stopping parameters\n",
    "    mlflow.log_param(\"stop_threshold\", stop_threshold)\n",
    "    mlflow.log_param(\"max_diverge_count\", max_diverge_count)\n",
    "    mlflow.log_param(\"patience\", patience)\n",
    "    \n",
    "    # Set descriptive tags for the model\n",
    "    mlflow.set_tag(\"model_description\", \"ResNet-50 for classification using MRI images\")\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss_train = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss_train += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss_train = running_loss_train / len(train_loader)\n",
    "        train_losses.append(epoch_loss_train)\n",
    "\n",
    "        # Log training loss to MLflow\n",
    "        mlflow.log_metric(\"train_loss\", epoch_loss_train, step=epoch)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss_val = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss_val += loss.item()\n",
    "\n",
    "        epoch_loss_val = running_loss_val / len(val_loader)\n",
    "        val_losses.append(epoch_loss_val)\n",
    "\n",
    "        # Log validation loss to MLflow\n",
    "        mlflow.log_metric(\"val_loss\", epoch_loss_val, step=epoch)\n",
    "\n",
    "        # Early stopping\n",
    "        if epoch_loss_val < best_val_loss:\n",
    "            best_val_loss = epoch_loss_val\n",
    "            patience_counter = 0  # Reset patience counter\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= 5:\n",
    "            print(\"Early stopping due to no improvement in validation loss.\")\n",
    "            break\n",
    "\n",
    "# Log the trained model to MLflow\n",
    "mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "# Optionally, plot the training/validation losses\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transformation and class\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import random\n",
    "# Set random seed for reproducibility\n",
    "seed = 42  # You can choose any integer\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)  # Set seed for numpy\n",
    "random.seed(seed)  # Set seed for random module\n",
    "\n",
    "# Create a new experiment\n",
    "Resnet50_class_seg1_seg1_basic = \"Resnet50_class_seg1_seg1_basic\"\n",
    "mlflow.set_experiment(Resnet50_class_seg1_seg1_basic)\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# %pip install torch torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import pydicom\n",
    "# %pip install opencv-python\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the transform with augmentation: I already tranformed i tbfore \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    #transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.RandomRotation(4),       # Randomly rotate the image by Â±10 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color properties\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "        # Ensure severity is in integer format\n",
    "        self.data['severity'] = self.data['severity'].astype(int)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        image_path = row['image_path']\n",
    "        label = row['severity']  # Use severity for the label\n",
    "\n",
    "        dicom_image = pydicom.dcmread(image_path)\n",
    "        image = dicom_image.pixel_array.astype(float)\n",
    "        image = (image / image.max() * 255).astype('uint8')  # Normalize\n",
    "\n",
    "        # Convert the image to RGB if it is grayscale\n",
    "        if len(image.shape) == 2:  # Grayscale\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        # Apply transformations including augmentation\n",
    "        image_tensor = self.transform(image) if self.transform else torch.from_numpy(image).permute(2, 0, 1)\n",
    "\n",
    "        return image_tensor, torch.tensor(label).long()  # Return label as tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import models\n",
    "# %pip install keras\n",
    "# %pip install tensorflow\n",
    "# from tensorflow.keras.callbacks import EarlyStopping  # Import EarlyStopping\n",
    "import numpy as np  # Import numpy for setting the random seed\n",
    "\n",
    " \n",
    "\n",
    "# Ensure the data only contains .dcm files\n",
    "train_data = train_data[train_data['image_path'].str.endswith('.dcm')]\n",
    "\n",
    "# Create the dataset\n",
    "dataset = MRIDataset(data=train_data, transform=transform)\n",
    "\n",
    "# Split the dataset into training and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 16\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load ResNet-50 and set up for classification\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = train_df['severity'].nunique()\n",
    "\n",
    "model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss functions and optimizer\n",
    "learining_rate = 0.0001 \n",
    "criterion_cel = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learining_rate)\n",
    "num_epochs = 20\n",
    "\n",
    "# Early stopping parameters\n",
    "# Lists to store loss values for plotting\n",
    "train_losses_cel = []\n",
    "val_losses_cel = []\n",
    "\n",
    "# Early stopping parameters\n",
    "diverge_count = 0              # Counter for divergence-based stopping\n",
    "stop_threshold = 0.3           # Threshold for divergence\n",
    "max_diverge_count = 3          # Max number of epochs with diverging validation loss\n",
    "patience = 5  # Number of epochs to wait for improvement before early stopping\n",
    "\n",
    "\n",
    "# Calculate number of layers in the model\n",
    "num_layers = len(list(model.children()))\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"learning_rate\", 'learning_rate')\n",
    "    mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "    mlflow.log_param(\"batch_size\", 'batch_size')\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"num_classes\", num_classes)\n",
    "    mlflow.log_param(\"model_architecture\", \"ResNet-50\")\n",
    "    \n",
    "    # Log early stopping parameters\n",
    "    mlflow.log_param(\"stop_threshold\", stop_threshold)\n",
    "    mlflow.log_param(\"max_diverge_count\", max_diverge_count)\n",
    "    mlflow.log_param(\"patience\", patience)\n",
    "\n",
    "    # Set descriptive tags for the model\n",
    "    mlflow.set_tag(\"model_description\", \"ResNet-50 for 3 cat and Sagittal T2/STIR and Sagittal T1 images\")\n",
    "\n",
    "    # Example input tensor with the same shape as the model's expected input\n",
    "    example_input = torch.randn(1, 3, 224, 224)  # Batch size 1, 3 color channels, 224x224 image\n",
    "    best_val_loss = float('inf')  # Initialize best validation loss\n",
    "    patience_counter = 0  # Plateau counter\n",
    "    \n",
    "    diverge_count = 0  # Counter for divergence-based stopping\n",
    "\n",
    "    train_losses_cel = []  # List to store training losses\n",
    "    val_losses_cel = []  # List to store validation losses\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss_cel_train = 0.0\n",
    "\n",
    "        for images, labels in train_loader: \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Cross Entropy Loss\n",
    "            loss_cel = criterion_cel(outputs, labels)\n",
    "            running_loss_cel_train += loss_cel.item()\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss_cel.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate average training loss for the epoch\n",
    "        epoch_loss_cel_train = running_loss_cel_train / len(train_loader)\n",
    "        train_losses_cel.append(epoch_loss_cel_train)\n",
    "\n",
    "        # Log training loss to MLflow\n",
    "        mlflow.log_metric(\"train_loss_cel\", epoch_loss_cel_train, step=epoch)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss_cel_val = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Cross Entropy Loss for validation\n",
    "                loss_cel = criterion_cel(outputs, labels)\n",
    "                running_loss_cel_val += loss_cel.item()\n",
    "\n",
    "        # Calculate validation loss for the epoch\n",
    "        epoch_loss_cel_val = running_loss_cel_val / len(val_loader)\n",
    "        val_losses_cel.append(epoch_loss_cel_val)\n",
    "\n",
    "        # Log validation loss to MLflow\n",
    "        mlflow.log_metric(\"val_loss_cel\", epoch_loss_cel_val, step=epoch)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "              f'Train Cross Entropy Loss: {epoch_loss_cel_train:.4f}, '\n",
    "              f'Validation Cross Entropy Loss: {epoch_loss_cel_val:.4f}')\n",
    "\n",
    "        # Save weights for each epoch\n",
    "        epoch_weight_path = f\"model_weights_epoch_{epoch + 1}.pt\"\n",
    "        torch.save(model.state_dict(), epoch_weight_path)\n",
    "        mlflow.log_artifact(epoch_weight_path)  # Log model weights as artifact for each epoch\n",
    "        os.remove(epoch_weight_path)  # Optionally, delete the local file after logging\n",
    "\n",
    "        # Check for early stopping (divergence-based stopping)\n",
    "        if epoch_loss_cel_val > epoch_loss_cel_train * (1 + stop_threshold):\n",
    "            diverge_count += 1\n",
    "            if diverge_count >= max_diverge_count:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} due to validation loss diverging.\")\n",
    "                break\n",
    "        else:\n",
    "            diverge_count = 0  # Reset diverge count if validation loss is not diverging\n",
    "\n",
    "        # Check for early stopping (plateau-based stopping)\n",
    "        if epoch_loss_cel_val < best_val_loss:\n",
    "            best_val_loss = epoch_loss_cel_val\n",
    "            patience_counter = 0  # Reset plateau counter if validation loss improves\n",
    "            # Save the model weights when validation loss improves (best model)\n",
    "            best_model_weight_path = f\"best_model_weights_epoch_{epoch + 1}.pt\"\n",
    "            torch.save(model.state_dict(), best_model_weight_path)\n",
    "            mlflow.log_artifact(best_model_weight_path)  # Log the best model weights\n",
    "            os.remove(best_model_weight_path)  # Optionally, delete the local file after logging\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} due to lack of validation loss improvement.\")\n",
    "                break\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    # Log final model\n",
    "    example_input_np = example_input.numpy()\n",
    "    mlflow.pytorch.log_model(model, \"final_model\", input_example=example_input_np)\n",
    "\n",
    "    # Plot and log the loss curves as artifacts\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses_cel, label='Train Cross Entropy Loss')\n",
    "    plt.plot(val_losses_cel, label='Validation Cross Entropy Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Cross Entropy Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"cross_entropy_loss.png\")\n",
    "    mlflow.log_artifact(\"cross_entropy_loss.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import pydicom\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, mode='classification', box_size=50):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.box_size = box_size\n",
    "\n",
    "    def create_bounding_box(self, x, y, img_shape):\n",
    "        x_min = max(0, int(x - self.box_size / 2))\n",
    "        y_min = max(0, int(y - self.box_size / 2))\n",
    "        x_max = min(img_shape[1], int(x + self.box_size / 2))\n",
    "        y_max = min(img_shape[0], int(y + self.box_size / 2))\n",
    "        return x_min, y_min, x_max, y_max\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        image_path = row['image_path']\n",
    "        x, y = row['x'], row['y']\n",
    "        label = row['condition'] if self.mode == 'classification' else (x, y)\n",
    "\n",
    "        dicom_image = pydicom.dcmread(image_path)\n",
    "        image = dicom_image.pixel_array.astype(float)\n",
    "        image = (image / image.max() * 255).astype('uint8')  # Normalize\n",
    "\n",
    "        if self.mode == 'localization':\n",
    "            x_min, y_min, x_max, y_max = self.create_bounding_box(x, y, image.shape)\n",
    "            roi = image[y_min:y_max, x_min:x_max]\n",
    "            roi = cv2.resize(roi, (224, 224))\n",
    "            image_tensor = self.transform(roi) if self.transform else roi\n",
    "        else:\n",
    "            annotated_image = image.copy()\n",
    "            cv2.circle(annotated_image, (int(x), int(y)), 10, (255, 0, 0), -1)\n",
    "            annotated_image = cv2.resize(annotated_image, (224, 224))\n",
    "            image_tensor = self.transform(annotated_image) if self.transform else annotated_image\n",
    "\n",
    "        # Convert grayscale (1 channel) to RGB (3 channels)\n",
    "        if image_tensor.ndim == 2:\n",
    "            image_tensor = torch.from_numpy(image_tensor).unsqueeze(0)  # Add channel dimension\n",
    "        image_tensor = image_tensor.repeat(3, 1, 1)  # Duplicate to 3 channels\n",
    "\n",
    "        return image_tensor, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "# Transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "])\n",
    "\n",
    "# Sample Data for one person  \n",
    "data = pd.DataFrame({\n",
    "    'image_path': ['data/train_images_origin/1028909382/1477339972/24.dcm'],\n",
    "    'x': [324.88], 'y': [485.87], 'condition': [1]    # since als persons belong to persons with df_end\n",
    "})\n",
    "dataset = MRIDataset(data=data, transform=transform, mode='classification')\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Load ResNet-50 and Set Mode\n",
    "mode = 'classification'  # my goal is to classify the images\n",
    "num_classes = 3   # \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "if mode == 'classification':\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "else:\n",
    "    model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() if mode == 'classification' else nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        if mode == 'classification':\n",
    "            loss = criterion(outputs, labels)\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_persons(dataframes, study_ids_to_keep, all_studies=False):\n",
    "    if all_studies:\n",
    "        return dataframes  # Return all DataFrames if all_studies is True\n",
    "    \n",
    "    filtered_dataframes = []\n",
    "    for df in dataframes:\n",
    "        # Filter the DataFrame based on study_ids_to_keep\n",
    "        filtered_df = df[df['study_id'].isin(study_ids_to_keep)]\n",
    "        filtered_dataframes.append(filtered_df)  # Append the filtered DataFrame to the list\n",
    "\n",
    "    return filtered_dataframes \n",
    "\n",
    " \n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'study_id': [4003253, 4003254, 4003253, 4003255],\n",
    "    'patient_name': ['Alice', 'Bob', 'Charlie', 'David']\n",
    "}\n",
    "\n",
    "df_image_paths = pd.DataFrame(data)\n",
    "\n",
    "# Using the corrected function\n",
    "study_ids_to_keep = [4003253]\n",
    "dataframes = [df_image_paths]\n",
    "\n",
    "filtered_dataframes = keep_persons(dataframes, study_ids_to_keep, all_studies=False)\n",
    "\n",
    "# Print the filtered DataFrames\n",
    "for filtered_df in filtered_dataframes:\n",
    "    print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the df_train DataFrame\n",
    "df_train = pd.DataFrame({\n",
    "    \"site_id\": [2, 2, 2, 2, 2],\n",
    "    \"patient_id\": [10006, 10006, 10006, 10006, 10011],\n",
    "    \"image_id\": [462822612, 1459541791, 1864590858, 1874946579, 220375232],\n",
    "    \"laterality\": [\"L\", \"L\", \"R\", \"R\", \"L\"],\n",
    "    \"view\": [\"CC\", \"MLO\", \"MLO\", \"CC\", \"CC\"],\n",
    "    \"age\": [61.0, 61.0, 61.0, 61.0, 55.0],\n",
    "    \"cancer\": [0, 0, 0, 0, 0],\n",
    "    \"biopsy\": [0, 0, 0, 0, 0],\n",
    "    \"invasive\": [0, 0, 0, 0, 0],\n",
    "    \"BIRADS\": [np.nan, np.nan, np.nan, np.nan, 0.0],\n",
    "    \"implant\": [0, 0, 0, 0, 0],\n",
    "    \"density\": [np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "    \"machine_id\": [29, 29, 29, 29, 21],\n",
    "    \"difficult_negative_case\": [False, False, False, False, True]\n",
    "})\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create the 'data' DataFrame with the 'class' column\n",
    "data = pd.DataFrame(\n",
    "    np.concatenate([\n",
    "        ['Total'] * len(df_train),  # Label 'Total' for each row in df_train\n",
    "        ['Malignant Cancer'] * len(df_train[df_train['cancer'] == 1]),  # Label 'Malignant Cancer' for rows with cancer == 1\n",
    "        ['Invasive Cancer'] * len(df_train[(df_train['cancer'] == 1) & (df_train['invasive'] == 1)])  # Label 'Invasive Cancer' for rows with cancer == 1 and invasive == 1\n",
    "    ]),\n",
    "    columns=[\"class\"]\n",
    ")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The not-malignant cancer cases were limited to biopsy cases.\n",
    "DF_train = df_train[df_train['biopsy'] == 1].reset_index(drop = True)\n",
    "DF_train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
