{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FklhSI0Gg9R"
   },
   "source": [
    "Before getting started, import the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# import cv2  # Uncomment if you need cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tensorflow  \n",
    "import pydicom\n",
    "from pydicom.data import get_testdata_files\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "# from torchvision import transforms\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    " # Import functions from the module\n",
    "import importlib\n",
    "import help_files._0_definitions \n",
    "import  help_files._1_visuals_script\n",
    "# import  help_files._01_load_data\n",
    " # Reload the module to apply the changes to the script\n",
    "importlib.reload(help_files._0_definitions)\n",
    "importlib.reload(help_files._1_visuals_script)\n",
    "# importlib.reload(help_files._01_load_data)\n",
    "import  help_files._1_visuals_script  as pauls_vs\n",
    "\n",
    "# Define the path\n",
    "from pathlib import Path\n",
    "# Define the path\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "### In definitions are all the functions that are used in the notebook and globals\n",
    "with open(\"help_files/_0_definitions.py\") as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from _01_load_data\n",
    "file_names = [\"X_train.csv\", \"X_train_coor.csv\", \"X_train_des.csv\"]\n",
    "dataframes = [pd.read_csv(data_path_vor / file_name) for file_name in file_names]\n",
    "X_train, X_train_coor, X_train_des = dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>spinal_canal_stenosis_l1_l2</th>\n",
       "      <th>spinal_canal_stenosis_l2_l3</th>\n",
       "      <th>spinal_canal_stenosis_l3_l4</th>\n",
       "      <th>spinal_canal_stenosis_l4_l5</th>\n",
       "      <th>spinal_canal_stenosis_l5_s1</th>\n",
       "      <th>left_neural_foraminal_narrowing_l1_l2</th>\n",
       "      <th>left_neural_foraminal_narrowing_l2_l3</th>\n",
       "      <th>left_neural_foraminal_narrowing_l3_l4</th>\n",
       "      <th>left_neural_foraminal_narrowing_l4_l5</th>\n",
       "      <th>...</th>\n",
       "      <th>left_subarticular_stenosis_l1_l2</th>\n",
       "      <th>left_subarticular_stenosis_l2_l3</th>\n",
       "      <th>left_subarticular_stenosis_l3_l4</th>\n",
       "      <th>left_subarticular_stenosis_l4_l5</th>\n",
       "      <th>left_subarticular_stenosis_l5_s1</th>\n",
       "      <th>right_subarticular_stenosis_l1_l2</th>\n",
       "      <th>right_subarticular_stenosis_l2_l3</th>\n",
       "      <th>right_subarticular_stenosis_l3_l4</th>\n",
       "      <th>right_subarticular_stenosis_l4_l5</th>\n",
       "      <th>right_subarticular_stenosis_l5_s1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4646740</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7143189</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8785691</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10728036</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>4282019580</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>4283570761</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>4284048608</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>4287160193</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1975 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        study_id spinal_canal_stenosis_l1_l2 spinal_canal_stenosis_l2_l3   \n",
       "0        4003253                 Normal/Mild                 Normal/Mild  \\\n",
       "1        4646740                 Normal/Mild                 Normal/Mild   \n",
       "2        7143189                 Normal/Mild                 Normal/Mild   \n",
       "3        8785691                 Normal/Mild                 Normal/Mild   \n",
       "4       10728036                 Normal/Mild                 Normal/Mild   \n",
       "...          ...                         ...                         ...   \n",
       "1970  4282019580                 Normal/Mild                 Normal/Mild   \n",
       "1971  4283570761                 Normal/Mild                 Normal/Mild   \n",
       "1972  4284048608                 Normal/Mild                 Normal/Mild   \n",
       "1973  4287160193                 Normal/Mild                    Moderate   \n",
       "1974  4290709089                 Normal/Mild                 Normal/Mild   \n",
       "\n",
       "     spinal_canal_stenosis_l3_l4 spinal_canal_stenosis_l4_l5   \n",
       "0                    Normal/Mild                 Normal/Mild  \\\n",
       "1                       Moderate                      Severe   \n",
       "2                    Normal/Mild                 Normal/Mild   \n",
       "3                    Normal/Mild                 Normal/Mild   \n",
       "4                    Normal/Mild                 Normal/Mild   \n",
       "...                          ...                         ...   \n",
       "1970                 Normal/Mild                 Normal/Mild   \n",
       "1971                 Normal/Mild                 Normal/Mild   \n",
       "1972                 Normal/Mild                      Severe   \n",
       "1973                 Normal/Mild                 Normal/Mild   \n",
       "1974                 Normal/Mild                 Normal/Mild   \n",
       "\n",
       "     spinal_canal_stenosis_l5_s1 left_neural_foraminal_narrowing_l1_l2   \n",
       "0                    Normal/Mild                           Normal/Mild  \\\n",
       "1                    Normal/Mild                           Normal/Mild   \n",
       "2                    Normal/Mild                           Normal/Mild   \n",
       "3                    Normal/Mild                           Normal/Mild   \n",
       "4                    Normal/Mild                           Normal/Mild   \n",
       "...                          ...                                   ...   \n",
       "1970                 Normal/Mild                           Normal/Mild   \n",
       "1971                 Normal/Mild                           Normal/Mild   \n",
       "1972                 Normal/Mild                           Normal/Mild   \n",
       "1973                 Normal/Mild                           Normal/Mild   \n",
       "1974                 Normal/Mild                           Normal/Mild   \n",
       "\n",
       "     left_neural_foraminal_narrowing_l2_l3   \n",
       "0                              Normal/Mild  \\\n",
       "1                              Normal/Mild   \n",
       "2                              Normal/Mild   \n",
       "3                              Normal/Mild   \n",
       "4                              Normal/Mild   \n",
       "...                                    ...   \n",
       "1970                           Normal/Mild   \n",
       "1971                           Normal/Mild   \n",
       "1972                           Normal/Mild   \n",
       "1973                           Normal/Mild   \n",
       "1974                           Normal/Mild   \n",
       "\n",
       "     left_neural_foraminal_narrowing_l3_l4   \n",
       "0                              Normal/Mild  \\\n",
       "1                              Normal/Mild   \n",
       "2                              Normal/Mild   \n",
       "3                              Normal/Mild   \n",
       "4                              Normal/Mild   \n",
       "...                                    ...   \n",
       "1970                           Normal/Mild   \n",
       "1971                           Normal/Mild   \n",
       "1972                           Normal/Mild   \n",
       "1973                           Normal/Mild   \n",
       "1974                           Normal/Mild   \n",
       "\n",
       "     left_neural_foraminal_narrowing_l4_l5  ...   \n",
       "0                                 Moderate  ...  \\\n",
       "1                                 Moderate  ...   \n",
       "2                              Normal/Mild  ...   \n",
       "3                                 Moderate  ...   \n",
       "4                              Normal/Mild  ...   \n",
       "...                                    ...  ...   \n",
       "1970                              Moderate  ...   \n",
       "1971                           Normal/Mild  ...   \n",
       "1972                           Normal/Mild  ...   \n",
       "1973                              Moderate  ...   \n",
       "1974                           Normal/Mild  ...   \n",
       "\n",
       "     left_subarticular_stenosis_l1_l2 left_subarticular_stenosis_l2_l3   \n",
       "0                         Normal/Mild                      Normal/Mild  \\\n",
       "1                         Normal/Mild                      Normal/Mild   \n",
       "2                         Normal/Mild                      Normal/Mild   \n",
       "3                         Normal/Mild                      Normal/Mild   \n",
       "4                         Normal/Mild                      Normal/Mild   \n",
       "...                               ...                              ...   \n",
       "1970                      Normal/Mild                      Normal/Mild   \n",
       "1971                      Normal/Mild                      Normal/Mild   \n",
       "1972                      Normal/Mild                      Normal/Mild   \n",
       "1973                      Normal/Mild                           Severe   \n",
       "1974                      Normal/Mild                      Normal/Mild   \n",
       "\n",
       "     left_subarticular_stenosis_l3_l4 left_subarticular_stenosis_l4_l5   \n",
       "0                         Normal/Mild                         Moderate  \\\n",
       "1                         Normal/Mild                           Severe   \n",
       "2                         Normal/Mild                      Normal/Mild   \n",
       "3                         Normal/Mild                      Normal/Mild   \n",
       "4                         Normal/Mild                      Normal/Mild   \n",
       "...                               ...                              ...   \n",
       "1970                      Normal/Mild                         Moderate   \n",
       "1971                      Normal/Mild                      Normal/Mild   \n",
       "1972                      Normal/Mild                           Severe   \n",
       "1973                         Moderate                         Moderate   \n",
       "1974                      Normal/Mild                      Normal/Mild   \n",
       "\n",
       "     left_subarticular_stenosis_l5_s1 right_subarticular_stenosis_l1_l2   \n",
       "0                         Normal/Mild                       Normal/Mild  \\\n",
       "1                         Normal/Mild                       Normal/Mild   \n",
       "2                         Normal/Mild                       Normal/Mild   \n",
       "3                         Normal/Mild                       Normal/Mild   \n",
       "4                         Normal/Mild                       Normal/Mild   \n",
       "...                               ...                               ...   \n",
       "1970                      Normal/Mild                       Normal/Mild   \n",
       "1971                      Normal/Mild                       Normal/Mild   \n",
       "1972                      Normal/Mild                       Normal/Mild   \n",
       "1973                      Normal/Mild                       Normal/Mild   \n",
       "1974                      Normal/Mild                       Normal/Mild   \n",
       "\n",
       "     right_subarticular_stenosis_l2_l3 right_subarticular_stenosis_l3_l4   \n",
       "0                          Normal/Mild                       Normal/Mild  \\\n",
       "1                             Moderate                          Moderate   \n",
       "2                          Normal/Mild                       Normal/Mild   \n",
       "3                          Normal/Mild                       Normal/Mild   \n",
       "4                          Normal/Mild                       Normal/Mild   \n",
       "...                                ...                               ...   \n",
       "1970                       Normal/Mild                          Moderate   \n",
       "1971                       Normal/Mild                       Normal/Mild   \n",
       "1972                       Normal/Mild                       Normal/Mild   \n",
       "1973                       Normal/Mild                          Moderate   \n",
       "1974                       Normal/Mild                       Normal/Mild   \n",
       "\n",
       "     right_subarticular_stenosis_l4_l5 right_subarticular_stenosis_l5_s1  \n",
       "0                          Normal/Mild                       Normal/Mild  \n",
       "1                             Moderate                       Normal/Mild  \n",
       "2                          Normal/Mild                       Normal/Mild  \n",
       "3                          Normal/Mild                       Normal/Mild  \n",
       "4                             Moderate                       Normal/Mild  \n",
       "...                                ...                               ...  \n",
       "1970                          Moderate                          Moderate  \n",
       "1971                       Normal/Mild                       Normal/Mild  \n",
       "1972                            Severe                       Normal/Mild  \n",
       "1973                          Moderate                       Normal/Mild  \n",
       "1974                       Normal/Mild                       Normal/Mild  \n",
       "\n",
       "[1975 rows x 26 columns]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1975 entries, 0 to 1974\n",
      "Data columns (total 26 columns):\n",
      " #   Column                                  Non-Null Count  Dtype \n",
      "---  ------                                  --------------  ----- \n",
      " 0   study_id                                1975 non-null   int64 \n",
      " 1   spinal_canal_stenosis_l1_l2             1974 non-null   object\n",
      " 2   spinal_canal_stenosis_l2_l3             1974 non-null   object\n",
      " 3   spinal_canal_stenosis_l3_l4             1974 non-null   object\n",
      " 4   spinal_canal_stenosis_l4_l5             1974 non-null   object\n",
      " 5   spinal_canal_stenosis_l5_s1             1974 non-null   object\n",
      " 6   left_neural_foraminal_narrowing_l1_l2   1973 non-null   object\n",
      " 7   left_neural_foraminal_narrowing_l2_l3   1973 non-null   object\n",
      " 8   left_neural_foraminal_narrowing_l3_l4   1973 non-null   object\n",
      " 9   left_neural_foraminal_narrowing_l4_l5   1973 non-null   object\n",
      " 10  left_neural_foraminal_narrowing_l5_s1   1973 non-null   object\n",
      " 11  right_neural_foraminal_narrowing_l1_l2  1967 non-null   object\n",
      " 12  right_neural_foraminal_narrowing_l2_l3  1967 non-null   object\n",
      " 13  right_neural_foraminal_narrowing_l3_l4  1967 non-null   object\n",
      " 14  right_neural_foraminal_narrowing_l4_l5  1967 non-null   object\n",
      " 15  right_neural_foraminal_narrowing_l5_s1  1967 non-null   object\n",
      " 16  left_subarticular_stenosis_l1_l2        1811 non-null   object\n",
      " 17  left_subarticular_stenosis_l2_l3        1893 non-null   object\n",
      " 18  left_subarticular_stenosis_l3_l4        1972 non-null   object\n",
      " 19  left_subarticular_stenosis_l4_l5        1972 non-null   object\n",
      " 20  left_subarticular_stenosis_l5_s1        1964 non-null   object\n",
      " 21  right_subarticular_stenosis_l1_l2       1814 non-null   object\n",
      " 22  right_subarticular_stenosis_l2_l3       1893 non-null   object\n",
      " 23  right_subarticular_stenosis_l3_l4       1973 non-null   object\n",
      " 24  right_subarticular_stenosis_l4_l5       1973 non-null   object\n",
      " 25  right_subarticular_stenosis_l5_s1       1968 non-null   object\n",
      "dtypes: int64(1), object(25)\n",
      "memory usage: 401.3+ KB\n",
      "            study_id spinal_canal_stenosis_l1_l2 spinal_canal_stenosis_l2_l3   \n",
      "count   1.975000e+03                        1974                        1974  \\\n",
      "unique           NaN                           3                           3   \n",
      "top              NaN                 Normal/Mild                 Normal/Mild   \n",
      "freq             NaN                        1886                        1770   \n",
      "mean    2.160989e+09                         NaN                         NaN   \n",
      "std     1.236621e+09                         NaN                         NaN   \n",
      "min     4.003253e+06                         NaN                         NaN   \n",
      "25%     1.094775e+09                         NaN                         NaN   \n",
      "50%     2.197997e+09                         NaN                         NaN   \n",
      "75%     3.221041e+09                         NaN                         NaN   \n",
      "max     4.290709e+09                         NaN                         NaN   \n",
      "\n",
      "       spinal_canal_stenosis_l3_l4 spinal_canal_stenosis_l4_l5   \n",
      "count                         1974                        1974  \\\n",
      "unique                           3                           3   \n",
      "top                    Normal/Mild                 Normal/Mild   \n",
      "freq                          1622                        1482   \n",
      "mean                           NaN                         NaN   \n",
      "std                            NaN                         NaN   \n",
      "min                            NaN                         NaN   \n",
      "25%                            NaN                         NaN   \n",
      "50%                            NaN                         NaN   \n",
      "75%                            NaN                         NaN   \n",
      "max                            NaN                         NaN   \n",
      "\n",
      "       spinal_canal_stenosis_l5_s1 left_neural_foraminal_narrowing_l1_l2   \n",
      "count                         1974                                  1973  \\\n",
      "unique                           3                                     3   \n",
      "top                    Normal/Mild                           Normal/Mild   \n",
      "freq                          1904                                  1908   \n",
      "mean                           NaN                                   NaN   \n",
      "std                            NaN                                   NaN   \n",
      "min                            NaN                                   NaN   \n",
      "25%                            NaN                                   NaN   \n",
      "50%                            NaN                                   NaN   \n",
      "75%                            NaN                                   NaN   \n",
      "max                            NaN                                   NaN   \n",
      "\n",
      "       left_neural_foraminal_narrowing_l2_l3   \n",
      "count                                   1973  \\\n",
      "unique                                     3   \n",
      "top                              Normal/Mild   \n",
      "freq                                    1791   \n",
      "mean                                     NaN   \n",
      "std                                      NaN   \n",
      "min                                      NaN   \n",
      "25%                                      NaN   \n",
      "50%                                      NaN   \n",
      "75%                                      NaN   \n",
      "max                                      NaN   \n",
      "\n",
      "       left_neural_foraminal_narrowing_l3_l4   \n",
      "count                                   1973  \\\n",
      "unique                                     3   \n",
      "top                              Normal/Mild   \n",
      "freq                                    1522   \n",
      "mean                                     NaN   \n",
      "std                                      NaN   \n",
      "min                                      NaN   \n",
      "25%                                      NaN   \n",
      "50%                                      NaN   \n",
      "75%                                      NaN   \n",
      "max                                      NaN   \n",
      "\n",
      "       left_neural_foraminal_narrowing_l4_l5  ...   \n",
      "count                                   1973  ...  \\\n",
      "unique                                     3  ...   \n",
      "top                              Normal/Mild  ...   \n",
      "freq                                    1204  ...   \n",
      "mean                                     NaN  ...   \n",
      "std                                      NaN  ...   \n",
      "min                                      NaN  ...   \n",
      "25%                                      NaN  ...   \n",
      "50%                                      NaN  ...   \n",
      "75%                                      NaN  ...   \n",
      "max                                      NaN  ...   \n",
      "\n",
      "       left_subarticular_stenosis_l1_l2 left_subarticular_stenosis_l2_l3   \n",
      "count                              1811                             1893  \\\n",
      "unique                                3                                3   \n",
      "top                         Normal/Mild                      Normal/Mild   \n",
      "freq                               1690                             1555   \n",
      "mean                                NaN                              NaN   \n",
      "std                                 NaN                              NaN   \n",
      "min                                 NaN                              NaN   \n",
      "25%                                 NaN                              NaN   \n",
      "50%                                 NaN                              NaN   \n",
      "75%                                 NaN                              NaN   \n",
      "max                                 NaN                              NaN   \n",
      "\n",
      "       left_subarticular_stenosis_l3_l4 left_subarticular_stenosis_l4_l5   \n",
      "count                              1972                             1972  \\\n",
      "unique                                3                                3   \n",
      "top                         Normal/Mild                      Normal/Mild   \n",
      "freq                               1324                              887   \n",
      "mean                                NaN                              NaN   \n",
      "std                                 NaN                              NaN   \n",
      "min                                 NaN                              NaN   \n",
      "25%                                 NaN                              NaN   \n",
      "50%                                 NaN                              NaN   \n",
      "75%                                 NaN                              NaN   \n",
      "max                                 NaN                              NaN   \n",
      "\n",
      "       left_subarticular_stenosis_l5_s1 right_subarticular_stenosis_l1_l2   \n",
      "count                              1964                              1814  \\\n",
      "unique                                3                                 3   \n",
      "top                         Normal/Mild                       Normal/Mild   \n",
      "freq                               1408                              1680   \n",
      "mean                                NaN                               NaN   \n",
      "std                                 NaN                               NaN   \n",
      "min                                 NaN                               NaN   \n",
      "25%                                 NaN                               NaN   \n",
      "50%                                 NaN                               NaN   \n",
      "75%                                 NaN                               NaN   \n",
      "max                                 NaN                               NaN   \n",
      "\n",
      "       right_subarticular_stenosis_l2_l3 right_subarticular_stenosis_l3_l4   \n",
      "count                               1893                              1973  \\\n",
      "unique                                 3                                 3   \n",
      "top                          Normal/Mild                       Normal/Mild   \n",
      "freq                                1577                              1322   \n",
      "mean                                 NaN                               NaN   \n",
      "std                                  NaN                               NaN   \n",
      "min                                  NaN                               NaN   \n",
      "25%                                  NaN                               NaN   \n",
      "50%                                  NaN                               NaN   \n",
      "75%                                  NaN                               NaN   \n",
      "max                                  NaN                               NaN   \n",
      "\n",
      "       right_subarticular_stenosis_l4_l5 right_subarticular_stenosis_l5_s1  \n",
      "count                               1973                              1968  \n",
      "unique                                 3                                 3  \n",
      "top                          Normal/Mild                       Normal/Mild  \n",
      "freq                                 891                              1399  \n",
      "mean                                 NaN                               NaN  \n",
      "std                                  NaN                               NaN  \n",
      "min                                  NaN                               NaN  \n",
      "25%                                  NaN                               NaN  \n",
      "50%                                  NaN                               NaN  \n",
      "75%                                  NaN                               NaN  \n",
      "max                                  NaN                               NaN  \n",
      "\n",
      "[11 rows x 26 columns]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics of the dataframe\n",
    "summary = X_train.describe(include='all')\n",
    "\n",
    "# Information about the dataframe\n",
    "info = X_train.info()\n",
    "\n",
    "# Display the summary and info\n",
    "print(summary)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "study_id                                   int64\n",
       "spinal_canal_stenosis_l1_l2               object\n",
       "spinal_canal_stenosis_l2_l3               object\n",
       "spinal_canal_stenosis_l3_l4               object\n",
       "spinal_canal_stenosis_l4_l5               object\n",
       "spinal_canal_stenosis_l5_s1               object\n",
       "left_neural_foraminal_narrowing_l1_l2     object\n",
       "left_neural_foraminal_narrowing_l2_l3     object\n",
       "left_neural_foraminal_narrowing_l3_l4     object\n",
       "left_neural_foraminal_narrowing_l4_l5     object\n",
       "left_neural_foraminal_narrowing_l5_s1     object\n",
       "right_neural_foraminal_narrowing_l1_l2    object\n",
       "right_neural_foraminal_narrowing_l2_l3    object\n",
       "right_neural_foraminal_narrowing_l3_l4    object\n",
       "right_neural_foraminal_narrowing_l4_l5    object\n",
       "right_neural_foraminal_narrowing_l5_s1    object\n",
       "left_subarticular_stenosis_l1_l2          object\n",
       "left_subarticular_stenosis_l2_l3          object\n",
       "left_subarticular_stenosis_l3_l4          object\n",
       "left_subarticular_stenosis_l4_l5          object\n",
       "left_subarticular_stenosis_l5_s1          object\n",
       "right_subarticular_stenosis_l1_l2         object\n",
       "right_subarticular_stenosis_l2_l3         object\n",
       "right_subarticular_stenosis_l3_l4         object\n",
       "right_subarticular_stenosis_l4_l5         object\n",
       "right_subarticular_stenosis_l5_s1         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>spinal_canal_stenosis_l1_l2</th>\n",
       "      <th>spinal_canal_stenosis_l2_l3</th>\n",
       "      <th>spinal_canal_stenosis_l3_l4</th>\n",
       "      <th>spinal_canal_stenosis_l4_l5</th>\n",
       "      <th>spinal_canal_stenosis_l5_s1</th>\n",
       "      <th>left_neural_foraminal_narrowing_l1_l2</th>\n",
       "      <th>left_neural_foraminal_narrowing_l2_l3</th>\n",
       "      <th>left_neural_foraminal_narrowing_l3_l4</th>\n",
       "      <th>left_neural_foraminal_narrowing_l4_l5</th>\n",
       "      <th>...</th>\n",
       "      <th>left_subarticular_stenosis_l1_l2</th>\n",
       "      <th>left_subarticular_stenosis_l2_l3</th>\n",
       "      <th>left_subarticular_stenosis_l3_l4</th>\n",
       "      <th>left_subarticular_stenosis_l4_l5</th>\n",
       "      <th>left_subarticular_stenosis_l5_s1</th>\n",
       "      <th>right_subarticular_stenosis_l1_l2</th>\n",
       "      <th>right_subarticular_stenosis_l2_l3</th>\n",
       "      <th>right_subarticular_stenosis_l3_l4</th>\n",
       "      <th>right_subarticular_stenosis_l4_l5</th>\n",
       "      <th>right_subarticular_stenosis_l5_s1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4646740</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7143189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8785691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10728036</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>4282019580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>4283570761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>4284048608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>4287160193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1975 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        study_id  spinal_canal_stenosis_l1_l2  spinal_canal_stenosis_l2_l3   \n",
       "0        4003253                          1.0                          1.0  \\\n",
       "1        4646740                          1.0                          1.0   \n",
       "2        7143189                          1.0                          1.0   \n",
       "3        8785691                          1.0                          1.0   \n",
       "4       10728036                          1.0                          1.0   \n",
       "...          ...                          ...                          ...   \n",
       "1970  4282019580                          1.0                          1.0   \n",
       "1971  4283570761                          1.0                          1.0   \n",
       "1972  4284048608                          1.0                          1.0   \n",
       "1973  4287160193                          1.0                          2.0   \n",
       "1974  4290709089                          1.0                          1.0   \n",
       "\n",
       "      spinal_canal_stenosis_l3_l4  spinal_canal_stenosis_l4_l5   \n",
       "0                             1.0                          1.0  \\\n",
       "1                             2.0                          3.0   \n",
       "2                             1.0                          1.0   \n",
       "3                             1.0                          1.0   \n",
       "4                             1.0                          1.0   \n",
       "...                           ...                          ...   \n",
       "1970                          1.0                          1.0   \n",
       "1971                          1.0                          1.0   \n",
       "1972                          1.0                          3.0   \n",
       "1973                          1.0                          1.0   \n",
       "1974                          1.0                          1.0   \n",
       "\n",
       "      spinal_canal_stenosis_l5_s1  left_neural_foraminal_narrowing_l1_l2   \n",
       "0                             1.0                                    1.0  \\\n",
       "1                             1.0                                    1.0   \n",
       "2                             1.0                                    1.0   \n",
       "3                             1.0                                    1.0   \n",
       "4                             1.0                                    1.0   \n",
       "...                           ...                                    ...   \n",
       "1970                          1.0                                    1.0   \n",
       "1971                          1.0                                    1.0   \n",
       "1972                          1.0                                    1.0   \n",
       "1973                          1.0                                    1.0   \n",
       "1974                          1.0                                    1.0   \n",
       "\n",
       "      left_neural_foraminal_narrowing_l2_l3   \n",
       "0                                       1.0  \\\n",
       "1                                       1.0   \n",
       "2                                       1.0   \n",
       "3                                       1.0   \n",
       "4                                       1.0   \n",
       "...                                     ...   \n",
       "1970                                    1.0   \n",
       "1971                                    1.0   \n",
       "1972                                    1.0   \n",
       "1973                                    1.0   \n",
       "1974                                    1.0   \n",
       "\n",
       "      left_neural_foraminal_narrowing_l3_l4   \n",
       "0                                       1.0  \\\n",
       "1                                       1.0   \n",
       "2                                       1.0   \n",
       "3                                       1.0   \n",
       "4                                       1.0   \n",
       "...                                     ...   \n",
       "1970                                    1.0   \n",
       "1971                                    1.0   \n",
       "1972                                    1.0   \n",
       "1973                                    1.0   \n",
       "1974                                    1.0   \n",
       "\n",
       "      left_neural_foraminal_narrowing_l4_l5  ...   \n",
       "0                                       2.0  ...  \\\n",
       "1                                       2.0  ...   \n",
       "2                                       1.0  ...   \n",
       "3                                       2.0  ...   \n",
       "4                                       1.0  ...   \n",
       "...                                     ...  ...   \n",
       "1970                                    2.0  ...   \n",
       "1971                                    1.0  ...   \n",
       "1972                                    1.0  ...   \n",
       "1973                                    2.0  ...   \n",
       "1974                                    1.0  ...   \n",
       "\n",
       "      left_subarticular_stenosis_l1_l2  left_subarticular_stenosis_l2_l3   \n",
       "0                                  1.0                               1.0  \\\n",
       "1                                  1.0                               1.0   \n",
       "2                                  1.0                               1.0   \n",
       "3                                  1.0                               1.0   \n",
       "4                                  1.0                               1.0   \n",
       "...                                ...                               ...   \n",
       "1970                               1.0                               1.0   \n",
       "1971                               1.0                               1.0   \n",
       "1972                               1.0                               1.0   \n",
       "1973                               1.0                               3.0   \n",
       "1974                               1.0                               1.0   \n",
       "\n",
       "      left_subarticular_stenosis_l3_l4  left_subarticular_stenosis_l4_l5   \n",
       "0                                  1.0                               2.0  \\\n",
       "1                                  1.0                               3.0   \n",
       "2                                  1.0                               1.0   \n",
       "3                                  1.0                               1.0   \n",
       "4                                  1.0                               1.0   \n",
       "...                                ...                               ...   \n",
       "1970                               1.0                               2.0   \n",
       "1971                               1.0                               1.0   \n",
       "1972                               1.0                               3.0   \n",
       "1973                               2.0                               2.0   \n",
       "1974                               1.0                               1.0   \n",
       "\n",
       "      left_subarticular_stenosis_l5_s1  right_subarticular_stenosis_l1_l2   \n",
       "0                                  1.0                                1.0  \\\n",
       "1                                  1.0                                1.0   \n",
       "2                                  1.0                                1.0   \n",
       "3                                  1.0                                1.0   \n",
       "4                                  1.0                                1.0   \n",
       "...                                ...                                ...   \n",
       "1970                               1.0                                1.0   \n",
       "1971                               1.0                                1.0   \n",
       "1972                               1.0                                1.0   \n",
       "1973                               1.0                                1.0   \n",
       "1974                               1.0                                1.0   \n",
       "\n",
       "      right_subarticular_stenosis_l2_l3  right_subarticular_stenosis_l3_l4   \n",
       "0                                   1.0                                1.0  \\\n",
       "1                                   2.0                                2.0   \n",
       "2                                   1.0                                1.0   \n",
       "3                                   1.0                                1.0   \n",
       "4                                   1.0                                1.0   \n",
       "...                                 ...                                ...   \n",
       "1970                                1.0                                2.0   \n",
       "1971                                1.0                                1.0   \n",
       "1972                                1.0                                1.0   \n",
       "1973                                1.0                                2.0   \n",
       "1974                                1.0                                1.0   \n",
       "\n",
       "      right_subarticular_stenosis_l4_l5  right_subarticular_stenosis_l5_s1  \n",
       "0                                   1.0                                1.0  \n",
       "1                                   2.0                                1.0  \n",
       "2                                   1.0                                1.0  \n",
       "3                                   1.0                                1.0  \n",
       "4                                   2.0                                1.0  \n",
       "...                                 ...                                ...  \n",
       "1970                                2.0                                2.0  \n",
       "1971                                1.0                                1.0  \n",
       "1972                                3.0                                1.0  \n",
       "1973                                2.0                                1.0  \n",
       "1974                                1.0                                1.0  \n",
       "\n",
       "[1975 rows x 26 columns]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of columns to iterate through\n",
    "columns_to_iterate = [\n",
    "    'spinal_canal_stenosis_l1_l2', 'spinal_canal_stenosis_l2_l3', 'spinal_canal_stenosis_l3_l4',\n",
    "    'spinal_canal_stenosis_l4_l5', 'spinal_canal_stenosis_l5_s1', 'left_neural_foraminal_narrowing_l1_l2',\n",
    "    'left_neural_foraminal_narrowing_l2_l3', 'left_neural_foraminal_narrowing_l3_l4', 'left_neural_foraminal_narrowing_l4_l5',\n",
    "    'left_neural_foraminal_narrowing_l5_s1', 'right_neural_foraminal_narrowing_l1_l2', 'right_neural_foraminal_narrowing_l2_l3',\n",
    "    'right_neural_foraminal_narrowing_l3_l4', 'right_neural_foraminal_narrowing_l4_l5', 'right_neural_foraminal_narrowing_l5_s1',\n",
    "    'left_subarticular_stenosis_l1_l2', 'left_subarticular_stenosis_l2_l3', 'left_subarticular_stenosis_l3_l4',\n",
    "    'left_subarticular_stenosis_l4_l5', 'left_subarticular_stenosis_l5_s1', 'right_subarticular_stenosis_l1_l2',\n",
    "    'right_subarticular_stenosis_l2_l3', 'right_subarticular_stenosis_l3_l4', 'right_subarticular_stenosis_l4_l5',\n",
    "    'right_subarticular_stenosis_l5_s1'\n",
    "]\n",
    "\n",
    "\n",
    "# Example operation: Fill missing values with 'Unknown'\n",
    "for column in columns_to_iterate:\n",
    "    X_train[column] = X_train[column].map({'Normal/Mild': 1, 'Moderate': 2, 'Severe': 3})\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Condition  Normal/Mild  Moderate  Severe   \n",
      "0              spinal_canal_stenosis_l1_l2         1886        67      21  \\\n",
      "1              spinal_canal_stenosis_l2_l3         1770       151      53   \n",
      "2              spinal_canal_stenosis_l3_l4         1622       230     122   \n",
      "3              spinal_canal_stenosis_l4_l5         1482       237     255   \n",
      "4              spinal_canal_stenosis_l5_s1         1904        51      19   \n",
      "5    left_neural_foraminal_narrowing_l1_l2         1908        63       2   \n",
      "6    left_neural_foraminal_narrowing_l2_l3         1791       171      11   \n",
      "7    left_neural_foraminal_narrowing_l3_l4         1522       411      40   \n",
      "8    left_neural_foraminal_narrowing_l4_l5         1204       629     140   \n",
      "9    left_neural_foraminal_narrowing_l5_s1         1247       520     206   \n",
      "10  right_neural_foraminal_narrowing_l1_l2         1891        63      13   \n",
      "11  right_neural_foraminal_narrowing_l2_l3         1793       168       6   \n",
      "12  right_neural_foraminal_narrowing_l3_l4         1512       414      41   \n",
      "13  right_neural_foraminal_narrowing_l4_l5         1208       629     130   \n",
      "14  right_neural_foraminal_narrowing_l5_s1         1281       496     190   \n",
      "15        left_subarticular_stenosis_l1_l2         1690        93      28   \n",
      "16        left_subarticular_stenosis_l2_l3         1555       255      83   \n",
      "17        left_subarticular_stenosis_l3_l4         1324       454     194   \n",
      "18        left_subarticular_stenosis_l4_l5          887       624     461   \n",
      "19        left_subarticular_stenosis_l5_s1         1408       409     147   \n",
      "20       right_subarticular_stenosis_l1_l2         1680       110      24   \n",
      "21       right_subarticular_stenosis_l2_l3         1577       243      73   \n",
      "22       right_subarticular_stenosis_l3_l4         1322       454     197   \n",
      "23       right_subarticular_stenosis_l4_l5          891       622     460   \n",
      "24       right_subarticular_stenosis_l5_s1         1399       396     173   \n",
      "\n",
      "    Normal/Mild (%)  Moderate (%)  Severe (%)  \n",
      "0         95.542047      3.394124    1.063830  \n",
      "1         89.665653      7.649443    2.684904  \n",
      "2         82.168186     11.651469    6.180344  \n",
      "3         75.075988     12.006079   12.917933  \n",
      "4         96.453901      2.583587    0.962513  \n",
      "5         96.705525      3.193107    0.101368  \n",
      "6         90.775469      8.667005    0.557527  \n",
      "7         77.141409     20.831221    2.027369  \n",
      "8         61.023822     31.880385    7.095793  \n",
      "9         63.203244     26.355803   10.440953  \n",
      "10        96.136248      3.202847    0.660905  \n",
      "11        91.154042      8.540925    0.305033  \n",
      "12        76.868327     21.047280    2.084392  \n",
      "13        61.413320     31.977631    6.609049  \n",
      "14        65.124555     25.216065    9.659380  \n",
      "15        93.318609      5.135284    1.546107  \n",
      "16        82.144744     13.470681    4.384575  \n",
      "17        67.139959     23.022312    9.837728  \n",
      "18        44.979716     31.643002   23.377282  \n",
      "19        71.690428     20.824847    7.484725  \n",
      "20        92.613010      6.063947    1.323043  \n",
      "21        83.306920     12.836767    3.856313  \n",
      "22        67.004562     23.010644    9.984795  \n",
      "23        45.159655     31.525596   23.314749  \n",
      "24        71.087398     20.121951    8.790650  \n",
      "       spinal_canal_stenosis_l1_l2  spinal_canal_stenosis_l2_l3   \n",
      "count                  1974.000000                  1974.000000  \\\n",
      "mean                      1.055218                     1.130193   \n",
      "std                       0.271077                     0.408687   \n",
      "min                       1.000000                     1.000000   \n",
      "25%                       1.000000                     1.000000   \n",
      "50%                       1.000000                     1.000000   \n",
      "75%                       1.000000                     1.000000   \n",
      "max                       3.000000                     3.000000   \n",
      "\n",
      "       spinal_canal_stenosis_l3_l4  spinal_canal_stenosis_l4_l5   \n",
      "count                  1974.000000                  1974.000000  \\\n",
      "mean                      1.240122                     1.378419   \n",
      "std                       0.553376                     0.702728   \n",
      "min                       1.000000                     1.000000   \n",
      "25%                       1.000000                     1.000000   \n",
      "50%                       1.000000                     1.000000   \n",
      "75%                       1.000000                     1.000000   \n",
      "max                       3.000000                     3.000000   \n",
      "\n",
      "       spinal_canal_stenosis_l5_s1  left_neural_foraminal_narrowing_l1_l2   \n",
      "count                  1974.000000                            1973.000000  \\\n",
      "mean                      1.045086                               1.033958   \n",
      "std                       0.249670                               0.186682   \n",
      "min                       1.000000                               1.000000   \n",
      "25%                       1.000000                               1.000000   \n",
      "50%                       1.000000                               1.000000   \n",
      "75%                       1.000000                               1.000000   \n",
      "max                       3.000000                               3.000000   \n",
      "\n",
      "       left_neural_foraminal_narrowing_l2_l3   \n",
      "count                            1973.000000  \\\n",
      "mean                                1.097821   \n",
      "std                                 0.315361   \n",
      "min                                 1.000000   \n",
      "25%                                 1.000000   \n",
      "50%                                 1.000000   \n",
      "75%                                 1.000000   \n",
      "max                                 3.000000   \n",
      "\n",
      "       left_neural_foraminal_narrowing_l3_l4   \n",
      "count                            1973.000000  \\\n",
      "mean                                1.248860   \n",
      "std                                 0.477065   \n",
      "min                                 1.000000   \n",
      "25%                                 1.000000   \n",
      "50%                                 1.000000   \n",
      "75%                                 1.000000   \n",
      "max                                 3.000000   \n",
      "\n",
      "       left_neural_foraminal_narrowing_l4_l5   \n",
      "count                            1973.000000  \\\n",
      "mean                                1.460720   \n",
      "std                                 0.624957   \n",
      "min                                 1.000000   \n",
      "25%                                 1.000000   \n",
      "50%                                 1.000000   \n",
      "75%                                 2.000000   \n",
      "max                                 3.000000   \n",
      "\n",
      "       left_neural_foraminal_narrowing_l5_s1  ...   \n",
      "count                            1973.000000  ...  \\\n",
      "mean                                1.472377  ...   \n",
      "std                                 0.676970  ...   \n",
      "min                                 1.000000  ...   \n",
      "25%                                 1.000000  ...   \n",
      "50%                                 1.000000  ...   \n",
      "75%                                 2.000000  ...   \n",
      "max                                 3.000000  ...   \n",
      "\n",
      "       left_subarticular_stenosis_l1_l2  left_subarticular_stenosis_l2_l3   \n",
      "count                       1811.000000                       1893.000000  \\\n",
      "mean                           1.082275                          1.222398   \n",
      "std                            0.326323                          0.510653   \n",
      "min                            1.000000                          1.000000   \n",
      "25%                            1.000000                          1.000000   \n",
      "50%                            1.000000                          1.000000   \n",
      "75%                            1.000000                          1.000000   \n",
      "max                            3.000000                          3.000000   \n",
      "\n",
      "       left_subarticular_stenosis_l3_l4  left_subarticular_stenosis_l4_l5   \n",
      "count                       1972.000000                       1972.000000  \\\n",
      "mean                           1.426978                          1.783976   \n",
      "std                            0.664565                          0.798265   \n",
      "min                            1.000000                          1.000000   \n",
      "25%                            1.000000                          1.000000   \n",
      "50%                            1.000000                          2.000000   \n",
      "75%                            2.000000                          2.000000   \n",
      "max                            3.000000                          3.000000   \n",
      "\n",
      "       left_subarticular_stenosis_l5_s1  right_subarticular_stenosis_l1_l2   \n",
      "count                       1964.000000                        1814.000000  \\\n",
      "mean                           1.357943                           1.087100   \n",
      "std                            0.616204                           0.325627   \n",
      "min                            1.000000                           1.000000   \n",
      "25%                            1.000000                           1.000000   \n",
      "50%                            1.000000                           1.000000   \n",
      "75%                            2.000000                           1.000000   \n",
      "max                            3.000000                           3.000000   \n",
      "\n",
      "       right_subarticular_stenosis_l2_l3  right_subarticular_stenosis_l3_l4   \n",
      "count                        1893.000000                        1973.000000  \\\n",
      "mean                            1.205494                           1.429802   \n",
      "std                             0.490428                           0.667078   \n",
      "min                             1.000000                           1.000000   \n",
      "25%                             1.000000                           1.000000   \n",
      "50%                             1.000000                           1.000000   \n",
      "75%                             1.000000                           2.000000   \n",
      "max                             3.000000                           3.000000   \n",
      "\n",
      "       right_subarticular_stenosis_l4_l5  right_subarticular_stenosis_l5_s1  \n",
      "count                        1973.000000                        1968.000000  \n",
      "mean                            1.781551                           1.377033  \n",
      "std                             0.798340                           0.641015  \n",
      "min                             1.000000                           1.000000  \n",
      "25%                             1.000000                           1.000000  \n",
      "50%                             2.000000                           1.000000  \n",
      "75%                             2.000000                           2.000000  \n",
      "max                             3.000000                           3.000000  \n",
      "\n",
      "[8 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the distribution data\n",
    "distribution_data = []\n",
    "\n",
    "# Calculate the distribution for each column\n",
    "for column in columns_to_iterate:\n",
    "    counts = X_train[column].value_counts().sort_index()\n",
    "    total_counts = counts.sum()\n",
    "    distribution_data.append({\n",
    "        'Condition': column,\n",
    "        'Normal/Mild': counts.get(1.0, 0),\n",
    "        'Moderate': counts.get(2.0, 0),\n",
    "        'Severe': counts.get(3.0, 0)\n",
    "    })\n",
    "    distribution_data[-1]['Normal/Mild (%)'] = (counts.get(1.0, 0) / total_counts) * 100\n",
    "    distribution_data[-1]['Moderate (%)'] = (counts.get(2.0, 0) / total_counts) * 100\n",
    "    distribution_data[-1]['Severe (%)'] = (counts.get(3.0, 0) / total_counts) * 100\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "distribution_df = pd.DataFrame(distribution_data)\n",
    "\n",
    "# Display the distribution DataFrame\n",
    "print(distribution_df)\n",
    "\n",
    "# Summarize the columns to iterate\n",
    "summary_stats = X_train[columns_to_iterate].describe(include='all')\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>2448190387</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4646740</td>\n",
       "      <td>3201256954</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4646740</td>\n",
       "      <td>3486248476</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6289</th>\n",
       "      <td>4287160193</td>\n",
       "      <td>1507070277</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>4287160193</td>\n",
       "      <td>1820446240</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6291</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>3274612423</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>3390218084</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        study_id   series_id series_description\n",
       "0        4003253   702807833   Sagittal T2/STIR\n",
       "1        4003253  1054713880        Sagittal T1\n",
       "2        4003253  2448190387           Axial T2\n",
       "3        4646740  3201256954           Axial T2\n",
       "4        4646740  3486248476        Sagittal T1\n",
       "...          ...         ...                ...\n",
       "6289  4287160193  1507070277   Sagittal T2/STIR\n",
       "6290  4287160193  1820446240           Axial T2\n",
       "6291  4290709089  3274612423   Sagittal T2/STIR\n",
       "6292  4290709089  3390218084           Axial T2\n",
       "6293  4290709089  4237840455        Sagittal T1\n",
       "\n",
       "[6294 rows x 3 columns]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>categorie</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id                              categorie  severity\n",
       "0   4003253  left_neural_foraminal_narrowing_l1_l2       1.0\n",
       "1   4003253  left_neural_foraminal_narrowing_l2_l3       1.0\n",
       "2   4003253  left_neural_foraminal_narrowing_l3_l4       1.0\n",
       "3   4003253  left_neural_foraminal_narrowing_l4_l5       2.0\n",
       "4   4003253  left_neural_foraminal_narrowing_l5_s1       1.0"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_list = ['spinal_canal_stenosis_l1_l2', 'spinal_canal_stenosis_l2_l3', 'spinal_canal_stenosis_l3_l4', 'spinal_canal_stenosis_l4_l5', 'spinal_canal_stenosis_l5_s1', 'left_neural_foraminal_narrowing_l1_l2', 'left_neural_foraminal_narrowing_l2_l3', 'left_neural_foraminal_narrowing_l3_l4', 'left_neural_foraminal_narrowing_l4_l5', 'left_neural_foraminal_narrowing_l5_s1', 'right_neural_foraminal_narrowing_l1_l2', 'right_neural_foraminal_narrowing_l2_l3', 'right_neural_foraminal_narrowing_l3_l4', 'right_neural_foraminal_narrowing_l4_l5', 'right_neural_foraminal_narrowing_l5_s1', 'left_subarticular_stenosis_l1_l2', 'left_subarticular_stenosis_l2_l3', 'left_subarticular_stenosis_l3_l4', 'left_subarticular_stenosis_l4_l5', 'left_subarticular_stenosis_l5_s1', 'right_subarticular_stenosis_l1_l2', 'right_subarticular_stenosis_l2_l3', 'right_subarticular_stenosis_l3_l4', 'right_subarticular_stenosis_l4_l5', 'right_subarticular_stenosis_l5_s1']  \n",
    "# Assuming df is your DataFrame\n",
    "reshaped_train = pd.melt(X_train, \n",
    "                  id_vars=[\"study_id\"],  # Keep study_id as is\n",
    "                  var_name=\"categorie\",  # New column for the condition names\n",
    "                  value_name=\"severity\")   # New column for the values\n",
    "\n",
    "# Display the reshaped DataFrame\n",
    "# Ensure the file is not open in another program and you have write permissions\n",
    "# reshaped_train.to_csv(path / \"starfor_sorting_new.csv\",  index=False)\n",
    " \n",
    " \n",
    "X_train = reshaped_train\n",
    "X_train = X_train.sort_values(by=['study_id', 'categorie'], ignore_index=True)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>categorie</th>\n",
       "      <th>severity</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l1_l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l2_l3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l3_l4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l4_l5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l5_s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49370</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>spinal_canal_stenosis_l1_l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l1_l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49371</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>spinal_canal_stenosis_l2_l3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l2_l3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49372</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>spinal_canal_stenosis_l3_l4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l3_l4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49373</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>spinal_canal_stenosis_l4_l5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l4_l5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49374</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>spinal_canal_stenosis_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l5_s1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49375 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         study_id                              categorie  severity   \n",
       "0         4003253  left_neural_foraminal_narrowing_l1_l2       1.0  \\\n",
       "1         4003253  left_neural_foraminal_narrowing_l2_l3       1.0   \n",
       "2         4003253  left_neural_foraminal_narrowing_l3_l4       1.0   \n",
       "3         4003253  left_neural_foraminal_narrowing_l4_l5       2.0   \n",
       "4         4003253  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "...           ...                                    ...       ...   \n",
       "49370  4290709089            spinal_canal_stenosis_l1_l2       1.0   \n",
       "49371  4290709089            spinal_canal_stenosis_l2_l3       1.0   \n",
       "49372  4290709089            spinal_canal_stenosis_l3_l4       1.0   \n",
       "49373  4290709089            spinal_canal_stenosis_l4_l5       1.0   \n",
       "49374  4290709089            spinal_canal_stenosis_l5_s1       1.0   \n",
       "\n",
       "                             condition  level  \n",
       "0      left_neural_foraminal_narrowing  l1_l2  \n",
       "1      left_neural_foraminal_narrowing  l2_l3  \n",
       "2      left_neural_foraminal_narrowing  l3_l4  \n",
       "3      left_neural_foraminal_narrowing  l4_l5  \n",
       "4      left_neural_foraminal_narrowing  l5_s1  \n",
       "...                                ...    ...  \n",
       "49370            spinal_canal_stenosis  l1_l2  \n",
       "49371            spinal_canal_stenosis  l2_l3  \n",
       "49372            spinal_canal_stenosis  l3_l4  \n",
       "49373            spinal_canal_stenosis  l4_l5  \n",
       "49374            spinal_canal_stenosis  l5_s1  \n",
       "\n",
       "[49375 rows x 5 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the string into two parts: 'spinal_canal_stenosis' and 'l1_l2'\n",
    "split_columns = X_train['categorie'].str.rsplit('_', n=2)\n",
    "# Combine the first part as 'condition' and the last two parts as 'level'\n",
    "X_train['condition'] = split_columns.str[0]\n",
    "X_train['level'] = split_columns.str[1] + '_' + split_columns.str[2]\n",
    "\n",
    "X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>categorie</th>\n",
       "      <th>severity</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l1/l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l2/l3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l3/l4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l4/l5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id                              categorie  severity   \n",
       "0   4003253  left_neural_foraminal_narrowing_l1_l2       1.0  \\\n",
       "1   4003253  left_neural_foraminal_narrowing_l2_l3       1.0   \n",
       "2   4003253  left_neural_foraminal_narrowing_l3_l4       1.0   \n",
       "3   4003253  left_neural_foraminal_narrowing_l4_l5       2.0   \n",
       "4   4003253  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "\n",
       "                         condition  level  \n",
       "0  left neural foraminal narrowing  l1/l2  \n",
       "1  left neural foraminal narrowing  l2/l3  \n",
       "2  left neural foraminal narrowing  l3/l4  \n",
       "3  left neural foraminal narrowing  l4/l5  \n",
       "4  left neural foraminal narrowing  l5/s1  "
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['condition'] = X_train['condition'].str.replace('_', ' ')\n",
    "X_train['level'] = X_train['level'].str.replace('_', '/')\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_coor['condition'] = X_train_coor['condition'].str.lower()\n",
    "X_train_coor['level'] = X_train_coor['level'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal canal stenosis</td>\n",
       "      <td>l1/l2</td>\n",
       "      <td>322.831858</td>\n",
       "      <td>227.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal canal stenosis</td>\n",
       "      <td>l2/l3</td>\n",
       "      <td>320.571429</td>\n",
       "      <td>295.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal canal stenosis</td>\n",
       "      <td>l3/l4</td>\n",
       "      <td>323.030303</td>\n",
       "      <td>371.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal canal stenosis</td>\n",
       "      <td>l4/l5</td>\n",
       "      <td>335.292035</td>\n",
       "      <td>427.327434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal canal stenosis</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>353.415929</td>\n",
       "      <td>483.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48687</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>11</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l1/l2</td>\n",
       "      <td>219.465940</td>\n",
       "      <td>97.831063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48688</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>12</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l2/l3</td>\n",
       "      <td>205.340599</td>\n",
       "      <td>140.207085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48689</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>12</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l3/l4</td>\n",
       "      <td>202.724796</td>\n",
       "      <td>181.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48690</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>12</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l4/l5</td>\n",
       "      <td>202.933333</td>\n",
       "      <td>219.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48691</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>12</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>211.813953</td>\n",
       "      <td>259.534884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48692 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         study_id   series_id  instance_number   \n",
       "0         4003253   702807833                8  \\\n",
       "1         4003253   702807833                8   \n",
       "2         4003253   702807833                8   \n",
       "3         4003253   702807833                8   \n",
       "4         4003253   702807833                8   \n",
       "...           ...         ...              ...   \n",
       "48687  4290709089  4237840455               11   \n",
       "48688  4290709089  4237840455               12   \n",
       "48689  4290709089  4237840455               12   \n",
       "48690  4290709089  4237840455               12   \n",
       "48691  4290709089  4237840455               12   \n",
       "\n",
       "                             condition  level           x           y  \n",
       "0                spinal canal stenosis  l1/l2  322.831858  227.964602  \n",
       "1                spinal canal stenosis  l2/l3  320.571429  295.714286  \n",
       "2                spinal canal stenosis  l3/l4  323.030303  371.818182  \n",
       "3                spinal canal stenosis  l4/l5  335.292035  427.327434  \n",
       "4                spinal canal stenosis  l5/s1  353.415929  483.964602  \n",
       "...                                ...    ...         ...         ...  \n",
       "48687  left neural foraminal narrowing  l1/l2  219.465940   97.831063  \n",
       "48688  left neural foraminal narrowing  l2/l3  205.340599  140.207085  \n",
       "48689  left neural foraminal narrowing  l3/l4  202.724796  181.013624  \n",
       "48690  left neural foraminal narrowing  l4/l5  202.933333  219.733333  \n",
       "48691  left neural foraminal narrowing  l5/s1  211.813953  259.534884  \n",
       "\n",
       "[48692 rows x 7 columns]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_coor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select which kind of damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         study_id                              categorie  severity   \n",
      "4         4003253  left_neural_foraminal_narrowing_l5_s1       1.0  \\\n",
      "29        4646740  left_neural_foraminal_narrowing_l5_s1       2.0   \n",
      "54        7143189  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
      "79        8785691  left_neural_foraminal_narrowing_l5_s1       2.0   \n",
      "104      10728036  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
      "...           ...                                    ...       ...   \n",
      "49254  4282019580  left_neural_foraminal_narrowing_l5_s1       2.0   \n",
      "49279  4283570761  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
      "49304  4284048608  left_neural_foraminal_narrowing_l5_s1       3.0   \n",
      "49329  4287160193  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
      "49354  4290709089  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
      "\n",
      "                             condition  level  \n",
      "4      left neural foraminal narrowing  l5/s1  \n",
      "29     left neural foraminal narrowing  l5/s1  \n",
      "54     left neural foraminal narrowing  l5/s1  \n",
      "79     left neural foraminal narrowing  l5/s1  \n",
      "104    left neural foraminal narrowing  l5/s1  \n",
      "...                                ...    ...  \n",
      "49254  left neural foraminal narrowing  l5/s1  \n",
      "49279  left neural foraminal narrowing  l5/s1  \n",
      "49304  left neural foraminal narrowing  l5/s1  \n",
      "49329  left neural foraminal narrowing  l5/s1  \n",
      "49354  left neural foraminal narrowing  l5/s1  \n",
      "\n",
      "[1975 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# keep only subarticular stenosis left right\n",
    "\n",
    "# Filter the DataFrame to keep only rows where the condition is either left_subarticular_stenosis_l4_l5 or right_subarticular_stenosis_l4_l5\n",
    "filtered_df = X_train[(X_train['condition'].str.contains('left neural foraminal narrowing')) & (X_train['level'] == 'l5/s1')]\n",
    "print(filtered_df)\n",
    "\n",
    "X_train = filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>categorie</th>\n",
       "      <th>severity</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4646740</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>7143189</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>8785691</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>10728036</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49254</th>\n",
       "      <td>4282019580</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49279</th>\n",
       "      <td>4283570761</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49304</th>\n",
       "      <td>4284048608</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49329</th>\n",
       "      <td>4287160193</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49354</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1975 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         study_id                              categorie  severity   \n",
       "4         4003253  left_neural_foraminal_narrowing_l5_s1       1.0  \\\n",
       "29        4646740  left_neural_foraminal_narrowing_l5_s1       2.0   \n",
       "54        7143189  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "79        8785691  left_neural_foraminal_narrowing_l5_s1       2.0   \n",
       "104      10728036  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "...           ...                                    ...       ...   \n",
       "49254  4282019580  left_neural_foraminal_narrowing_l5_s1       2.0   \n",
       "49279  4283570761  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "49304  4284048608  left_neural_foraminal_narrowing_l5_s1       3.0   \n",
       "49329  4287160193  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "49354  4290709089  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "\n",
       "                             condition  level  \n",
       "4      left neural foraminal narrowing  l5/s1  \n",
       "29     left neural foraminal narrowing  l5/s1  \n",
       "54     left neural foraminal narrowing  l5/s1  \n",
       "79     left neural foraminal narrowing  l5/s1  \n",
       "104    left neural foraminal narrowing  l5/s1  \n",
       "...                                ...    ...  \n",
       "49254  left neural foraminal narrowing  l5/s1  \n",
       "49279  left neural foraminal narrowing  l5/s1  \n",
       "49304  left neural foraminal narrowing  l5/s1  \n",
       "49329  left neural foraminal narrowing  l5/s1  \n",
       "49354  left neural foraminal narrowing  l5/s1  \n",
       "\n",
       "[1975 rows x 5 columns]"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique study_id in X_train: 1975\n",
      "Number of unique study_id in X_train_coor: 1974\n"
     ]
    }
   ],
   "source": [
    "unique_study_ids_train = X_train['study_id'].nunique()\n",
    "unique_study_ids_train_coor = X_train_coor['study_id'].nunique()\n",
    "\n",
    "print(f\"Number of unique study_id in X_train: {unique_study_ids_train}\")\n",
    "print(f\"Number of unique study_id in X_train_coor: {unique_study_ids_train_coor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    " # get rid of persons with no coordinates\n",
    "X_train = X_train[X_train['study_id'].isin(X_train_coor['study_id'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique study_id in X_train: 1974\n",
      "Number of unique study_id in X_train_coor: 1974\n"
     ]
    }
   ],
   "source": [
    "unique_study_ids_train = X_train['study_id'].nunique()\n",
    "unique_study_ids_train_coor = X_train_coor['study_id'].nunique()\n",
    "\n",
    "print(f\"Number of unique study_id in X_train: {unique_study_ids_train}\")\n",
    "print(f\"Number of unique study_id in X_train_coor: {unique_study_ids_train_coor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>categorie</th>\n",
       "      <th>severity</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>series_id</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>1.054714e+09</td>\n",
       "      <td>11.0</td>\n",
       "      <td>197.100569</td>\n",
       "      <td>289.457306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4646740</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>3.486248e+09</td>\n",
       "      <td>7.0</td>\n",
       "      <td>235.980844</td>\n",
       "      <td>360.313610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7143189</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>3.219733e+09</td>\n",
       "      <td>12.0</td>\n",
       "      <td>199.493128</td>\n",
       "      <td>272.418121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8785691</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>1.570287e+09</td>\n",
       "      <td>11.0</td>\n",
       "      <td>189.656176</td>\n",
       "      <td>254.389937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10728036</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>2.399638e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>270.972740</td>\n",
       "      <td>380.878049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id                              categorie  severity   \n",
       "0   4003253  left_neural_foraminal_narrowing_l5_s1       1.0  \\\n",
       "1   4646740  left_neural_foraminal_narrowing_l5_s1       2.0   \n",
       "2   7143189  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "3   8785691  left_neural_foraminal_narrowing_l5_s1       2.0   \n",
       "4  10728036  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "\n",
       "                         condition  level     series_id  instance_number   \n",
       "0  left neural foraminal narrowing  l5/s1  1.054714e+09             11.0  \\\n",
       "1  left neural foraminal narrowing  l5/s1  3.486248e+09              7.0   \n",
       "2  left neural foraminal narrowing  l5/s1  3.219733e+09             12.0   \n",
       "3  left neural foraminal narrowing  l5/s1  1.570287e+09             11.0   \n",
       "4  left neural foraminal narrowing  l5/s1  2.399638e+09             15.0   \n",
       "\n",
       "            x           y  \n",
       "0  197.100569  289.457306  \n",
       "1  235.980844  360.313610  \n",
       "2  199.493128  272.418121  \n",
       "3  189.656176  254.389937  \n",
       "4  270.972740  380.878049  "
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a left join on multiple variables\n",
    "merged_df = pd.merge(X_train, X_train_coor, on=['study_id', 'condition', 'level'], how='left')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in X_train: 1974\n",
      "Rows in X_train_coor: 48692\n",
      "Rows in merged_df: 1974\n",
      "Rows in merged_df without matching rows in X_train_coor: 2\n",
      "Rows in merged_df with matches from X_train_coor: 1972\n"
     ]
    }
   ],
   "source": [
    "# Count total rows in each DataFrame before the merge\n",
    "print(f\"Rows in X_train: {len(X_train)}\")\n",
    "print(f\"Rows in X_train_coor: {len(X_train_coor)}\")\n",
    "\n",
    "# Count total rows in the merged DataFrame\n",
    "print(f\"Rows in merged_df: {len(merged_df)}\")\n",
    "\n",
    "# Find out how many rows have missing values in columns from X_train_coor after the merge\n",
    "# Assuming columns from X_train_coor start with a common prefix or are listed in a known list\n",
    "columns_from_X_train_coor = [col for col in X_train_coor.columns if col not in ['study_id', 'condition', 'level']]\n",
    "missing_rows = merged_df[columns_from_X_train_coor].isnull().all(axis=1).sum()\n",
    "\n",
    "# Create a new DataFrame for study_ids with at least one row having missing values in columns from X_train_coor\n",
    "missing_study_ids = merged_df[merged_df[columns_from_X_train_coor].isnull().any(axis=1)]['study_id'].unique()\n",
    "missing_persons_df = merged_df[merged_df['study_id'].isin(missing_study_ids)]\n",
    "missing_persons_df = missing_persons_df.sort_values(by=['study_id', 'categorie'], ignore_index=True)\n",
    " \n",
    "\n",
    "print(f\"Rows in merged_df without matching rows in X_train_coor: {missing_rows}\")\n",
    "print(f\"Rows in merged_df with matches from X_train_coor: {len(merged_df) - missing_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>categorie</th>\n",
       "      <th>severity</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>series_id</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2492114990</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2780132468</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     study_id                              categorie  severity   \n",
       "0  2492114990  left_neural_foraminal_narrowing_l5_s1       NaN  \\\n",
       "1  2780132468  left_neural_foraminal_narrowing_l5_s1       NaN   \n",
       "\n",
       "                         condition  level  series_id  instance_number   x   y  \n",
       "0  left neural foraminal narrowing  l5/s1        NaN              NaN NaN NaN  \n",
       "1  left neural foraminal narrowing  l5/s1        NaN              NaN NaN NaN  "
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_persons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:red\">later on to take it back to the original shape : 48692</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# drop rows with missing values in columns from X_train_coor\n",
    "\n",
    "merged_df = merged_df.dropna(subset=columns_from_X_train_coor)\n",
    "\n",
    "display(Markdown('<span style=\"color:red\">later on to take it back to the original shape : 48692</span>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>categorie</th>\n",
       "      <th>severity</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>series_id</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>1.054714e+09</td>\n",
       "      <td>11.0</td>\n",
       "      <td>197.100569</td>\n",
       "      <td>289.457306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4646740</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>3.486248e+09</td>\n",
       "      <td>7.0</td>\n",
       "      <td>235.980844</td>\n",
       "      <td>360.313610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7143189</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>3.219733e+09</td>\n",
       "      <td>12.0</td>\n",
       "      <td>199.493128</td>\n",
       "      <td>272.418121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8785691</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>1.570287e+09</td>\n",
       "      <td>11.0</td>\n",
       "      <td>189.656176</td>\n",
       "      <td>254.389937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10728036</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>2.399638e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>270.972740</td>\n",
       "      <td>380.878049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>4282019580</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>3.029775e+09</td>\n",
       "      <td>7.0</td>\n",
       "      <td>254.937163</td>\n",
       "      <td>358.448833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>4283570761</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>2.708429e+09</td>\n",
       "      <td>12.0</td>\n",
       "      <td>265.773330</td>\n",
       "      <td>360.763486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>4284048608</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>1.875151e+09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>209.969231</td>\n",
       "      <td>344.861538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>4287160193</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>3.278933e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>195.571875</td>\n",
       "      <td>265.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>4.237840e+09</td>\n",
       "      <td>12.0</td>\n",
       "      <td>211.813953</td>\n",
       "      <td>259.534884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1972 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        study_id                              categorie  severity   \n",
       "0        4003253  left_neural_foraminal_narrowing_l5_s1       1.0  \\\n",
       "1        4646740  left_neural_foraminal_narrowing_l5_s1       2.0   \n",
       "2        7143189  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "3        8785691  left_neural_foraminal_narrowing_l5_s1       2.0   \n",
       "4       10728036  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "...          ...                                    ...       ...   \n",
       "1969  4282019580  left_neural_foraminal_narrowing_l5_s1       2.0   \n",
       "1970  4283570761  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "1971  4284048608  left_neural_foraminal_narrowing_l5_s1       3.0   \n",
       "1972  4287160193  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "1973  4290709089  left_neural_foraminal_narrowing_l5_s1       1.0   \n",
       "\n",
       "                            condition  level     series_id  instance_number   \n",
       "0     left neural foraminal narrowing  l5/s1  1.054714e+09             11.0  \\\n",
       "1     left neural foraminal narrowing  l5/s1  3.486248e+09              7.0   \n",
       "2     left neural foraminal narrowing  l5/s1  3.219733e+09             12.0   \n",
       "3     left neural foraminal narrowing  l5/s1  1.570287e+09             11.0   \n",
       "4     left neural foraminal narrowing  l5/s1  2.399638e+09             15.0   \n",
       "...                               ...    ...           ...              ...   \n",
       "1969  left neural foraminal narrowing  l5/s1  3.029775e+09              7.0   \n",
       "1970  left neural foraminal narrowing  l5/s1  2.708429e+09             12.0   \n",
       "1971  left neural foraminal narrowing  l5/s1  1.875151e+09             17.0   \n",
       "1972  left neural foraminal narrowing  l5/s1  3.278933e+08              4.0   \n",
       "1973  left neural foraminal narrowing  l5/s1  4.237840e+09             12.0   \n",
       "\n",
       "               x           y  \n",
       "0     197.100569  289.457306  \n",
       "1     235.980844  360.313610  \n",
       "2     199.493128  272.418121  \n",
       "3     189.656176  254.389937  \n",
       "4     270.972740  380.878049  \n",
       "...          ...         ...  \n",
       "1969  254.937163  358.448833  \n",
       "1970  265.773330  360.763486  \n",
       "1971  209.969231  344.861538  \n",
       "1972  195.571875  265.176471  \n",
       "1973  211.813953  259.534884  \n",
       "\n",
       "[1972 rows x 9 columns]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder with images: preparing paths for meargin with main data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create paths to the folders including images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>2448190387</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4646740</td>\n",
       "      <td>3201256954</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4646740</td>\n",
       "      <td>3486248476</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6289</th>\n",
       "      <td>4287160193</td>\n",
       "      <td>1507070277</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>4287160193</td>\n",
       "      <td>1820446240</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6291</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>3274612423</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>3390218084</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        study_id   series_id series_description\n",
       "0        4003253   702807833   Sagittal T2/STIR\n",
       "1        4003253  1054713880        Sagittal T1\n",
       "2        4003253  2448190387           Axial T2\n",
       "3        4646740  3201256954           Axial T2\n",
       "4        4646740  3486248476        Sagittal T1\n",
       "...          ...         ...                ...\n",
       "6289  4287160193  1507070277   Sagittal T2/STIR\n",
       "6290  4287160193  1820446240           Axial T2\n",
       "6291  4290709089  3274612423   Sagittal T2/STIR\n",
       "6292  4290709089  3390218084           Axial T2\n",
       "6293  4290709089  4237840455        Sagittal T1\n",
       "\n",
       "[6294 rows x 3 columns]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_des"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define which mri type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "study_id               int64\n",
       "series_id              int64\n",
       "series_description    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_des.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4646740</td>\n",
       "      <td>3666319702</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7143189</td>\n",
       "      <td>132939515</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8785691</td>\n",
       "      <td>481125819</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10728036</td>\n",
       "      <td>3491739931</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    study_id   series_id series_description\n",
       "0    4003253   702807833   Sagittal T2/STIR\n",
       "5    4646740  3666319702   Sagittal T2/STIR\n",
       "6    7143189   132939515   Sagittal T2/STIR\n",
       "9    8785691   481125819   Sagittal T2/STIR\n",
       "15  10728036  3491739931   Sagittal T2/STIR"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_des = X_train_des[X_train_des['series_description'] == 'Sagittal T2/STIR']\n",
    "\n",
    "X_train_des.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train_images\\4003253\\702807833\\1.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train_images\\4003253\\702807833\\2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train_images\\4003253\\702807833\\3.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train_images\\4003253\\702807833\\4.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train_images\\4003253\\702807833\\5.dcm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  image_path\n",
       "0  data/train_images\\4003253\\702807833\\1.dcm\n",
       "1  data/train_images\\4003253\\702807833\\2.dcm\n",
       "2  data/train_images\\4003253\\702807833\\3.dcm\n",
       "3  data/train_images\\4003253\\702807833\\4.dcm\n",
       "4  data/train_images\\4003253\\702807833\\5.dcm"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using train_table\n",
    "import re\n",
    "\n",
    "def paths_to_images(df, data_dir):\n",
    "    image_paths = []\n",
    "    for study_id, series_id in zip(df['study_id'], df['series_id']):\n",
    "        study_dir = os.path.join(data_dir, str(study_id))\n",
    "        series_dir = os.path.join(study_dir, str(series_id))\n",
    "        \n",
    "        # List images in the series directory\n",
    "        images = os.listdir(series_dir)\n",
    "        # Create full paths for each image\n",
    "        image_paths.extend([os.path.join(series_dir, img) for img in images])\n",
    "        \n",
    "    return image_paths\n",
    "\n",
    "image_paths = paths_to_images(X_train_des, os.path.join(\"data/train_images\"))\n",
    "\n",
    "# Sort the image paths to ensure numerical order\n",
    "def numerical_sort(value):\n",
    "    parts = re.split(r'(\\d+)', value)\n",
    "    return [int(part) if part.isdigit() else part for part in parts]\n",
    "\n",
    "image_paths = sorted(image_paths, key=numerical_sort)\n",
    "image_paths[:75]\n",
    "\n",
    "df_image_paths = pd.DataFrame(image_paths, columns=['image_path'])\n",
    "df_image_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  old one wiht all images\\n# Using real folders and images\\n# path to images folder and images inside the folder\\nimport re\\n# Define the main directory\\nmain_dir = \"data/train_images\"\\n\\ndef paths_to_images_2(main_dir):\\n    image_paths = []\\n    # Walk through the directory structure starting from the main directory\\n    for root, subdirs, files in os.walk(main_dir):\\n        for file in files:\\n            # Create the full path for each image\\n            print(file)\\n            file_path = os.path.join(root, file)\\n            image_paths.append(file_path)\\n\\n    return image_paths\\n\\npaths_to_images_2(main_dir)\\n\\n\\n\\n################   sort path images in numerical order  \\n# Define the main directory\\nmain_dir = \"data/train_images\"\\n\\n# Get the image paths\\nimage_paths = paths_to_images_2(main_dir)\\n\\n# Sort the image paths to ensure numerical order\\ndef numerical_sort(value):\\n    parts = re.split(r\\'(\\\\d+)\\', value)\\n    return [int(part) if part.isdigit() else part for part in parts]\\n\\nimage_paths = sorted(image_paths, key=numerical_sort)\\nimage_paths[:75]\\n\\ndf_image_paths = pd.DataFrame(image_paths, columns=[\\'image_path\\'])\\ndf_image_paths.head()\\n'"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"  old one wiht all images\n",
    "# Using real folders and images\n",
    "# path to images folder and images inside the folder\n",
    "import re\n",
    "# Define the main directory\n",
    "main_dir = \"data/train_images\"\n",
    "\n",
    "def paths_to_images_2(main_dir):\n",
    "    image_paths = []\n",
    "    # Walk through the directory structure starting from the main directory\n",
    "    for root, subdirs, files in os.walk(main_dir):\n",
    "        for file in files:\n",
    "            # Create the full path for each image\n",
    "            print(file)\n",
    "            file_path = os.path.join(root, file)\n",
    "            image_paths.append(file_path)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "paths_to_images_2(main_dir)\n",
    "\n",
    "\n",
    "\n",
    "################   sort path images in numerical order  \n",
    "# Define the main directory\n",
    "main_dir = \"data/train_images\"\n",
    "\n",
    "# Get the image paths\n",
    "image_paths = paths_to_images_2(main_dir)\n",
    "\n",
    "# Sort the image paths to ensure numerical order\n",
    "def numerical_sort(value):\n",
    "    parts = re.split(r'(\\d+)', value)\n",
    "    return [int(part) if part.isdigit() else part for part in parts]\n",
    "\n",
    "image_paths = sorted(image_paths, key=numerical_sort)\n",
    "image_paths[:75]\n",
    "\n",
    "df_image_paths = pd.DataFrame(image_paths, columns=['image_path'])\n",
    "df_image_paths.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train_images/4003253/702807833/1.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train_images/4003253/702807833/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train_images/4003253/702807833/3.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train_images/4003253/702807833/4.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train_images/4003253/702807833/5.dcm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  image_path\n",
       "0  data/train_images/4003253/702807833/1.dcm\n",
       "1  data/train_images/4003253/702807833/2.dcm\n",
       "2  data/train_images/4003253/702807833/3.dcm\n",
       "3  data/train_images/4003253/702807833/4.dcm\n",
       "4  data/train_images/4003253/702807833/5.dcm"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_image_paths['image_path'] = df_image_paths['image_path'].str.replace('\\\\', '/')\n",
    "df_image_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train_images/4003253/702807833/1.dcm</td>\n",
       "      <td>4003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train_images/4003253/702807833/2.dcm</td>\n",
       "      <td>4003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train_images/4003253/702807833/3.dcm</td>\n",
       "      <td>4003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train_images/4003253/702807833/4.dcm</td>\n",
       "      <td>4003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train_images/4003253/702807833/5.dcm</td>\n",
       "      <td>4003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>data/train_images/10728036/3491739931/7.dcm</td>\n",
       "      <td>10728036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>data/train_images/10728036/3491739931/8.dcm</td>\n",
       "      <td>10728036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>data/train_images/10728036/3491739931/9.dcm</td>\n",
       "      <td>10728036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>data/train_images/10728036/3491739931/10.dcm</td>\n",
       "      <td>10728036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>data/train_images/10728036/3491739931/11.dcm</td>\n",
       "      <td>10728036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      image_path  study_id\n",
       "0      data/train_images/4003253/702807833/1.dcm   4003253\n",
       "1      data/train_images/4003253/702807833/2.dcm   4003253\n",
       "2      data/train_images/4003253/702807833/3.dcm   4003253\n",
       "3      data/train_images/4003253/702807833/4.dcm   4003253\n",
       "4      data/train_images/4003253/702807833/5.dcm   4003253\n",
       "..                                           ...       ...\n",
       "70   data/train_images/10728036/3491739931/7.dcm  10728036\n",
       "71   data/train_images/10728036/3491739931/8.dcm  10728036\n",
       "72   data/train_images/10728036/3491739931/9.dcm  10728036\n",
       "73  data/train_images/10728036/3491739931/10.dcm  10728036\n",
       "74  data/train_images/10728036/3491739931/11.dcm  10728036\n",
       "\n",
       "[75 rows x 2 columns]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the path and extract the study_id\n",
    "def safe_int_conversion(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except OverflowError:\n",
    "        return None  # or handle it in another way\n",
    "\n",
    "df_image_paths['study_id'] = df_image_paths['image_path'].apply(lambda x: safe_int_conversion(x.split('/')[2]))\n",
    " \n",
    "df_image_paths['study_id'] = df_image_paths['study_id'].astype(int)\n",
    "df_image_paths.head(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_path    object\n",
       "study_id       int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_image_paths.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train_images/4003253/702807833/1.dcm</td>\n",
       "      <td>4003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train_images/4003253/702807833/2.dcm</td>\n",
       "      <td>4003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train_images/4003253/702807833/3.dcm</td>\n",
       "      <td>4003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train_images/4003253/702807833/4.dcm</td>\n",
       "      <td>4003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train_images/4003253/702807833/5.dcm</td>\n",
       "      <td>4003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33564</th>\n",
       "      <td>data/train_images/4290709089/3274612423/11.dcm</td>\n",
       "      <td>-4258207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33565</th>\n",
       "      <td>data/train_images/4290709089/3274612423/12.dcm</td>\n",
       "      <td>-4258207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33566</th>\n",
       "      <td>data/train_images/4290709089/3274612423/13.dcm</td>\n",
       "      <td>-4258207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33567</th>\n",
       "      <td>data/train_images/4290709089/3274612423/14.dcm</td>\n",
       "      <td>-4258207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33568</th>\n",
       "      <td>data/train_images/4290709089/3274612423/15.dcm</td>\n",
       "      <td>-4258207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33569 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           image_path  study_id\n",
       "0           data/train_images/4003253/702807833/1.dcm   4003253\n",
       "1           data/train_images/4003253/702807833/2.dcm   4003253\n",
       "2           data/train_images/4003253/702807833/3.dcm   4003253\n",
       "3           data/train_images/4003253/702807833/4.dcm   4003253\n",
       "4           data/train_images/4003253/702807833/5.dcm   4003253\n",
       "...                                               ...       ...\n",
       "33564  data/train_images/4290709089/3274612423/11.dcm  -4258207\n",
       "33565  data/train_images/4290709089/3274612423/12.dcm  -4258207\n",
       "33566  data/train_images/4290709089/3274612423/13.dcm  -4258207\n",
       "33567  data/train_images/4290709089/3274612423/14.dcm  -4258207\n",
       "33568  data/train_images/4290709089/3274612423/15.dcm  -4258207\n",
       "\n",
       "[33569 rows x 2 columns]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only selected persons \n",
    "from help_files._0_definitions import keep_persons, study_ids_to_keep, all_persons\n",
    "\n",
    "voraluf = keep_persons(df_image_paths, study_ids_to_keep, all_persons)\n",
    "df_image_paths = voraluf\n",
    "df_image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join  X_train and df_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at average there are 81 images per person\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "df_image_paths['count'] = df_image_paths.groupby('study_id').cumcount() + 1\n",
    "df_image_paths['count_per_person'] = df_image_paths.groupby('study_id')['study_id'].transform('count')\n",
    "df_image_paths['mean_per_of_raws'] = df_image_paths.groupby('study_id').first()['count_per_person'].mean()\n",
    "df_image_paths['first_row_flag'] = df_image_paths.groupby('study_id').cumcount().apply(lambda x: 1 if x == 0 else 0)\n",
    "df_image_paths['mean_per_of_raws2'] = np.where(df_image_paths['first_row_flag'] == 1, df_image_paths['count_per_person'].mean(), np.nan)\n",
    "df_image_paths.head(75)\n",
    "\"\"\"\n",
    "print(\"at average there are 81 images per person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99933750\n",
      "95000000\n",
      "3944052\n"
     ]
    }
   ],
   "source": [
    "# 81 images per person as average multiplied by 25 persons for each person multiplied by 49350 persons \n",
    "print(81*25*49350)\n",
    "## estimated for 1900 raws per person  multiplied by 50000 persons \n",
    "print(1900*50000)\n",
    "print(48692 *81)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>severity</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>series_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>1.054714e+09</td>\n",
       "      <td>197.100569</td>\n",
       "      <td>289.457306</td>\n",
       "      <td>data/train_images/4003253/702807833/1.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>1.054714e+09</td>\n",
       "      <td>197.100569</td>\n",
       "      <td>289.457306</td>\n",
       "      <td>data/train_images/4003253/702807833/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>1.054714e+09</td>\n",
       "      <td>197.100569</td>\n",
       "      <td>289.457306</td>\n",
       "      <td>data/train_images/4003253/702807833/3.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>1.054714e+09</td>\n",
       "      <td>197.100569</td>\n",
       "      <td>289.457306</td>\n",
       "      <td>data/train_images/4003253/702807833/4.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>1.054714e+09</td>\n",
       "      <td>197.100569</td>\n",
       "      <td>289.457306</td>\n",
       "      <td>data/train_images/4003253/702807833/5.dcm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id  severity                        condition  level     series_id   \n",
       "0   4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09  \\\n",
       "1   4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
       "2   4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
       "3   4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
       "4   4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
       "\n",
       "            x           y                                 image_path  \n",
       "0  197.100569  289.457306  data/train_images/4003253/702807833/1.dcm  \n",
       "1  197.100569  289.457306  data/train_images/4003253/702807833/2.dcm  \n",
       "2  197.100569  289.457306  data/train_images/4003253/702807833/3.dcm  \n",
       "3  197.100569  289.457306  data/train_images/4003253/702807833/4.dcm  \n",
       "4  197.100569  289.457306  data/train_images/4003253/702807833/5.dcm  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join 1 to many: X_train and df_image_paths\n",
    "df_end = merged_df.merge(df_image_paths, on='study_id', how='left')\n",
    "df_end.head()\n",
    "df_end = df_end.drop(columns=['categorie', 'instance_number'])\n",
    "df_end.shape\n",
    "\n",
    "# Define data_path_vor\n",
    " \n",
    " \n",
    "df_end.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    study_id  severity                        condition  level     series_id   \n",
      "0    4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09  \\\n",
      "1    4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "2    4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "3    4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "4    4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "5    4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "6    4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "7    4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "8    4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "9    4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "10   4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "11   4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "12   4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "13   4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "14   4003253       1.0  left neural foraminal narrowing  l5/s1  1.054714e+09   \n",
      "15   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "16   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "17   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "18   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "19   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "20   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "21   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "22   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "23   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "24   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "25   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "26   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "27   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "28   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "29   4646740       2.0  left neural foraminal narrowing  l5/s1  3.486248e+09   \n",
      "\n",
      "             x           y                                   image_path  \n",
      "0   197.100569  289.457306    data/train_images/4003253/702807833/1.dcm  \n",
      "1   197.100569  289.457306    data/train_images/4003253/702807833/2.dcm  \n",
      "2   197.100569  289.457306    data/train_images/4003253/702807833/3.dcm  \n",
      "3   197.100569  289.457306    data/train_images/4003253/702807833/4.dcm  \n",
      "4   197.100569  289.457306    data/train_images/4003253/702807833/5.dcm  \n",
      "5   197.100569  289.457306    data/train_images/4003253/702807833/6.dcm  \n",
      "6   197.100569  289.457306    data/train_images/4003253/702807833/7.dcm  \n",
      "7   197.100569  289.457306    data/train_images/4003253/702807833/8.dcm  \n",
      "8   197.100569  289.457306    data/train_images/4003253/702807833/9.dcm  \n",
      "9   197.100569  289.457306   data/train_images/4003253/702807833/10.dcm  \n",
      "10  197.100569  289.457306   data/train_images/4003253/702807833/11.dcm  \n",
      "11  197.100569  289.457306   data/train_images/4003253/702807833/12.dcm  \n",
      "12  197.100569  289.457306   data/train_images/4003253/702807833/13.dcm  \n",
      "13  197.100569  289.457306   data/train_images/4003253/702807833/14.dcm  \n",
      "14  197.100569  289.457306   data/train_images/4003253/702807833/15.dcm  \n",
      "15  235.980844  360.313610   data/train_images/4646740/3666319702/1.dcm  \n",
      "16  235.980844  360.313610   data/train_images/4646740/3666319702/2.dcm  \n",
      "17  235.980844  360.313610   data/train_images/4646740/3666319702/3.dcm  \n",
      "18  235.980844  360.313610   data/train_images/4646740/3666319702/4.dcm  \n",
      "19  235.980844  360.313610   data/train_images/4646740/3666319702/5.dcm  \n",
      "20  235.980844  360.313610   data/train_images/4646740/3666319702/6.dcm  \n",
      "21  235.980844  360.313610   data/train_images/4646740/3666319702/7.dcm  \n",
      "22  235.980844  360.313610   data/train_images/4646740/3666319702/8.dcm  \n",
      "23  235.980844  360.313610   data/train_images/4646740/3666319702/9.dcm  \n",
      "24  235.980844  360.313610  data/train_images/4646740/3666319702/10.dcm  \n",
      "25  235.980844  360.313610  data/train_images/4646740/3666319702/11.dcm  \n",
      "26  235.980844  360.313610  data/train_images/4646740/3666319702/12.dcm  \n",
      "27  235.980844  360.313610  data/train_images/4646740/3666319702/13.dcm  \n",
      "28  235.980844  360.313610  data/train_images/4646740/3666319702/14.dcm  \n",
      "29  235.980844  360.313610  data/train_images/4646740/3666319702/15.dcm  \n"
     ]
    }
   ],
   "source": [
    "df_end.head(75)   \n",
    "print(df_end[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         study_id  severity                        condition  level   \n",
      "65       10728036       1.0  left neural foraminal narrowing  l5/s1  \\\n",
      "11653  1506063459       1.0  left neural foraminal narrowing  l5/s1   \n",
      "13897  1785782006       1.0  left neural foraminal narrowing  l5/s1   \n",
      "9445   1217477368       1.0  left neural foraminal narrowing  l5/s1   \n",
      "11187  1447821731       1.0  left neural foraminal narrowing  l5/s1   \n",
      "\n",
      "          series_id           x           y   \n",
      "65     2.399638e+09  270.972740  380.878049  \\\n",
      "11653  6.771141e+08  288.355556  352.000000   \n",
      "13897  5.752277e+08  316.835165  527.340659   \n",
      "9445   3.518039e+09  258.867617  370.183299   \n",
      "11187  2.787700e+09  259.836512  364.817439   \n",
      "\n",
      "                                           image_path  \n",
      "65        data/train_images/10728036/3491739931/2.dcm  \n",
      "11653  data/train_images/1506063459/2935542429/12.dcm  \n",
      "13897  data/train_images/1785782006/2680924350/14.dcm  \n",
      "9445       data/train_images/1217477368/370109/15.dcm  \n",
      "11187   data/train_images/1447821731/2225187454/9.dcm  \n",
      "         study_id  severity                        condition  level   \n",
      "6388    824003539       2.0  left neural foraminal narrowing  l5/s1  \\\n",
      "12186  1567179188       2.0  left neural foraminal narrowing  l5/s1   \n",
      "1969    245660566       2.0  left neural foraminal narrowing  l5/s1   \n",
      "10509  1354411109       2.0  left neural foraminal narrowing  l5/s1   \n",
      "16283  2121891805       2.0  left neural foraminal narrowing  l5/s1   \n",
      "\n",
      "          series_id           x           y   \n",
      "6388   2.583852e+09  298.320611  494.809160  \\\n",
      "12186  9.261112e+08  190.945055  289.687912   \n",
      "1969   2.968145e+09  267.397974  329.725036   \n",
      "10509  1.001603e+09  121.664999  178.199851   \n",
      "16283  6.891851e+08  246.012739  401.121019   \n",
      "\n",
      "                                           image_path  \n",
      "6388     data/train_images/824003539/2592406902/8.dcm  \n",
      "12186  data/train_images/1567179188/3433809812/14.dcm  \n",
      "1969    data/train_images/245660566/1542752562/12.dcm  \n",
      "10509  data/train_images/1354411109/3679776577/16.dcm  \n",
      "16283   data/train_images/2121891805/1057985617/2.dcm  \n",
      "         study_id  severity                        condition  level   \n",
      "8082   1028909382       3.0  left neural foraminal narrowing  l5/s1  \\\n",
      "12489  1618233546       3.0  left neural foraminal narrowing  l5/s1   \n",
      "5364    692840069       3.0  left neural foraminal narrowing  l5/s1   \n",
      "4703    624472591       3.0  left neural foraminal narrowing  l5/s1   \n",
      "11213  1449902148       3.0  left neural foraminal narrowing  l5/s1   \n",
      "\n",
      "          series_id           x           y   \n",
      "8082   8.190511e+07  324.887984  485.865580  \\\n",
      "12489  3.577432e+09  163.095723  249.613035   \n",
      "5364   1.297481e+08  230.571019  372.063128   \n",
      "4703   3.620277e+09  160.583736  246.312399   \n",
      "11213  3.855283e+09  261.247853  338.247936   \n",
      "\n",
      "                                           image_path  \n",
      "8082   data/train_images/1028909382/1477339972/24.dcm  \n",
      "12489   data/train_images/1618233546/2816981416/1.dcm  \n",
      "5364    data/train_images/692840069/1130031773/13.dcm  \n",
      "4703     data/train_images/624472591/2757854807/7.dcm  \n",
      "11213   data/train_images/1449902148/3975587764/8.dcm  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>severity</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>series_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>10728036</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>2.399638e+09</td>\n",
       "      <td>270.972740</td>\n",
       "      <td>380.878049</td>\n",
       "      <td>data/train_images/10728036/3491739931/2.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11653</th>\n",
       "      <td>1506063459</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>6.771141e+08</td>\n",
       "      <td>288.355556</td>\n",
       "      <td>352.000000</td>\n",
       "      <td>data/train_images/1506063459/2935542429/12.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13897</th>\n",
       "      <td>1785782006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>5.752277e+08</td>\n",
       "      <td>316.835165</td>\n",
       "      <td>527.340659</td>\n",
       "      <td>data/train_images/1785782006/2680924350/14.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9445</th>\n",
       "      <td>1217477368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>3.518039e+09</td>\n",
       "      <td>258.867617</td>\n",
       "      <td>370.183299</td>\n",
       "      <td>data/train_images/1217477368/370109/15.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11187</th>\n",
       "      <td>1447821731</td>\n",
       "      <td>1.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>2.787700e+09</td>\n",
       "      <td>259.836512</td>\n",
       "      <td>364.817439</td>\n",
       "      <td>data/train_images/1447821731/2225187454/9.dcm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         study_id  severity                        condition  level   \n",
       "65       10728036       1.0  left neural foraminal narrowing  l5/s1  \\\n",
       "11653  1506063459       1.0  left neural foraminal narrowing  l5/s1   \n",
       "13897  1785782006       1.0  left neural foraminal narrowing  l5/s1   \n",
       "9445   1217477368       1.0  left neural foraminal narrowing  l5/s1   \n",
       "11187  1447821731       1.0  left neural foraminal narrowing  l5/s1   \n",
       "\n",
       "          series_id           x           y   \n",
       "65     2.399638e+09  270.972740  380.878049  \\\n",
       "11653  6.771141e+08  288.355556  352.000000   \n",
       "13897  5.752277e+08  316.835165  527.340659   \n",
       "9445   3.518039e+09  258.867617  370.183299   \n",
       "11187  2.787700e+09  259.836512  364.817439   \n",
       "\n",
       "                                           image_path  \n",
       "65        data/train_images/10728036/3491739931/2.dcm  \n",
       "11653  data/train_images/1506063459/2935542429/12.dcm  \n",
       "13897  data/train_images/1785782006/2680924350/14.dcm  \n",
       "9445       data/train_images/1217477368/370109/15.dcm  \n",
       "11187   data/train_images/1447821731/2225187454/9.dcm  "
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_df_random(df, severity, n=100, random_state=42):\n",
    "    severity_df = df[df['severity'] == severity]\n",
    "    return severity_df.sample(n=n, random_state=random_state)\n",
    "\n",
    "RSEED = 42  # Define the random seed\n",
    "\n",
    "df_random_1 = get_df_random(df_end, severity=1, n=100, random_state=RSEED)\n",
    "df_random_2 = get_df_random(df_end, severity=2, n=100, random_state=RSEED)\n",
    "df_random_3 = get_df_random(df_end, severity=3, n=100, random_state=RSEED)\n",
    "\n",
    "random_list = [df_random_1, df_random_2, df_random_3]\n",
    "for ran in random_list:\n",
    "    print(ran.head())  # Display the head of each DataFrame\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df_random = pd.concat(random_list) \n",
    "df_random.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>severity</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>series_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8082</th>\n",
       "      <td>1028909382</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>8.190511e+07</td>\n",
       "      <td>324.887984</td>\n",
       "      <td>485.865580</td>\n",
       "      <td>data/train_images/1028909382/1477339972/24.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12489</th>\n",
       "      <td>1618233546</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>3.577432e+09</td>\n",
       "      <td>163.095723</td>\n",
       "      <td>249.613035</td>\n",
       "      <td>data/train_images/1618233546/2816981416/1.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>692840069</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>1.297481e+08</td>\n",
       "      <td>230.571019</td>\n",
       "      <td>372.063128</td>\n",
       "      <td>data/train_images/692840069/1130031773/13.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>624472591</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>3.620277e+09</td>\n",
       "      <td>160.583736</td>\n",
       "      <td>246.312399</td>\n",
       "      <td>data/train_images/624472591/2757854807/7.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11213</th>\n",
       "      <td>1449902148</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>3.855283e+09</td>\n",
       "      <td>261.247853</td>\n",
       "      <td>338.247936</td>\n",
       "      <td>data/train_images/1449902148/3975587764/8.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>206642334</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>1.498269e+09</td>\n",
       "      <td>189.656176</td>\n",
       "      <td>245.534591</td>\n",
       "      <td>data/train_images/206642334/3618533469/14.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10770</th>\n",
       "      <td>1395246421</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>7.632392e+08</td>\n",
       "      <td>170.373626</td>\n",
       "      <td>249.846154</td>\n",
       "      <td>data/train_images/1395246421/2151810587/14.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>305101752</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>4.479684e+08</td>\n",
       "      <td>282.215146</td>\n",
       "      <td>359.808061</td>\n",
       "      <td>data/train_images/305101752/1882093736/11.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10051</th>\n",
       "      <td>1294500604</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>3.946919e+09</td>\n",
       "      <td>247.784370</td>\n",
       "      <td>272.301013</td>\n",
       "      <td>data/train_images/1294500604/2772049481/11.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15968</th>\n",
       "      <td>2059107661</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left neural foraminal narrowing</td>\n",
       "      <td>l5/s1</td>\n",
       "      <td>2.365056e+09</td>\n",
       "      <td>256.843956</td>\n",
       "      <td>386.250549</td>\n",
       "      <td>data/train_images/2059107661/1284191790/16.dcm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         study_id  severity                        condition  level   \n",
       "8082   1028909382       3.0  left neural foraminal narrowing  l5/s1  \\\n",
       "12489  1618233546       3.0  left neural foraminal narrowing  l5/s1   \n",
       "5364    692840069       3.0  left neural foraminal narrowing  l5/s1   \n",
       "4703    624472591       3.0  left neural foraminal narrowing  l5/s1   \n",
       "11213  1449902148       3.0  left neural foraminal narrowing  l5/s1   \n",
       "...           ...       ...                              ...    ...   \n",
       "1655    206642334       3.0  left neural foraminal narrowing  l5/s1   \n",
       "10770  1395246421       3.0  left neural foraminal narrowing  l5/s1   \n",
       "2386    305101752       3.0  left neural foraminal narrowing  l5/s1   \n",
       "10051  1294500604       3.0  left neural foraminal narrowing  l5/s1   \n",
       "15968  2059107661       3.0  left neural foraminal narrowing  l5/s1   \n",
       "\n",
       "          series_id           x           y   \n",
       "8082   8.190511e+07  324.887984  485.865580  \\\n",
       "12489  3.577432e+09  163.095723  249.613035   \n",
       "5364   1.297481e+08  230.571019  372.063128   \n",
       "4703   3.620277e+09  160.583736  246.312399   \n",
       "11213  3.855283e+09  261.247853  338.247936   \n",
       "...             ...         ...         ...   \n",
       "1655   1.498269e+09  189.656176  245.534591   \n",
       "10770  7.632392e+08  170.373626  249.846154   \n",
       "2386   4.479684e+08  282.215146  359.808061   \n",
       "10051  3.946919e+09  247.784370  272.301013   \n",
       "15968  2.365056e+09  256.843956  386.250549   \n",
       "\n",
       "                                           image_path  \n",
       "8082   data/train_images/1028909382/1477339972/24.dcm  \n",
       "12489   data/train_images/1618233546/2816981416/1.dcm  \n",
       "5364    data/train_images/692840069/1130031773/13.dcm  \n",
       "4703     data/train_images/624472591/2757854807/7.dcm  \n",
       "11213   data/train_images/1449902148/3975587764/8.dcm  \n",
       "...                                               ...  \n",
       "1655    data/train_images/206642334/3618533469/14.dcm  \n",
       "10770  data/train_images/1395246421/2151810587/14.dcm  \n",
       "2386    data/train_images/305101752/1882093736/11.dcm  \n",
       "10051  data/train_images/1294500604/2772049481/11.dcm  \n",
       "15968  data/train_images/2059107661/1284191790/16.dcm  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_random_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first try "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 8082 to 15968\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   study_id    100 non-null    int64  \n",
      " 1   severity    100 non-null    float64\n",
      " 2   condition   100 non-null    object \n",
      " 3   level       100 non-null    object \n",
      " 4   series_id   100 non-null    float64\n",
      " 5   x           100 non-null    float64\n",
      " 6   y           100 non-null    float64\n",
      " 7   image_path  94 non-null     object \n",
      "dtypes: float64(4), int64(1), object(3)\n",
      "memory usage: 7.0+ KB\n",
      "None\n",
      "8082     data/train_images/1028909382/1477339972/24.dcm\n",
      "12489     data/train_images/1618233546/2816981416/1.dcm\n",
      "5364      data/train_images/692840069/1130031773/13.dcm\n",
      "4703       data/train_images/624472591/2757854807/7.dcm\n",
      "11213     data/train_images/1449902148/3975587764/8.dcm\n",
      "Name: image_path, dtype: object\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Check the DataFrame info and types\n",
    "print(df_random_3.info())\n",
    "\n",
    "# Convert image_path to string if necessary\n",
    "df_random_3['image_path'] = df_random_3['image_path'].astype(str)\n",
    "\n",
    "# Print out the image_path values to inspect\n",
    "print(df_random_3['image_path'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in image_path column:\n",
      "Empty DataFrame\n",
      "Columns: [study_id, severity, condition, level, series_id, x, y, image_path]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in image_path column:\n",
      "Empty DataFrame\n",
      "Columns: [study_id, severity, condition, level, series_id, x, y, image_path]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in the image_path column\n",
    "print(\"NaN values in image_path column:\")\n",
    "print(df_random_3[df_random_3['image_path'].isna()])\n",
    "\n",
    "# Option 1: Drop rows with NaN values in image_path\n",
    "df_random_3 = df_random_3.dropna(subset=['image_path'])\n",
    "print(df_random_3.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[425], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m label \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Load DICOM image and convert to grayscale uint8\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m dicom_image \u001b[38;5;241m=\u001b[39m \u001b[43mpydicom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdcmread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m image \u001b[38;5;241m=\u001b[39m dicom_image\u001b[38;5;241m.\u001b[39mpixel_array\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     35\u001b[0m image \u001b[38;5;241m=\u001b[39m (image \u001b[38;5;241m/\u001b[39m image\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Normalize\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\pydicom\\filereader.py:1042\u001b[0m, in \u001b[0;36mdcmread\u001b[1;34m(fp, defer_size, stop_before_pixels, force, specific_tags)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     caller_owns_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1042\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1044\u001b[0m     fp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseek\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtell\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1048\u001b[0m ):\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdcmread: Expected a file path, file-like or readable buffer, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1051\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fp)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1052\u001b[0m     )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nan'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import models, transforms\n",
    "import pydicom\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_random_3 is already defined and contains the necessary columns\n",
    "# df_random_3 should have the following columns: 'image_path', 'x', 'y', 'condition'\n",
    "\n",
    "# Transformations (including conversion to 3 channels)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3 channels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.485, 0.485], std=[0.229, 0.229, 0.229])  # Normalize for 3 channels\n",
    "])\n",
    "\n",
    "# Preprocess Images and Labels\n",
    "images = []\n",
    "labels = []\n",
    "for _, row in df_random_3.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    x, y = int(row['x']), int(row['y'])\n",
    "    label = row['condition']\n",
    "    \n",
    "    # Load DICOM image and convert to grayscale uint8\n",
    "    dicom_image = pydicom.dcmread(image_path)\n",
    "    image = dicom_image.pixel_array.astype(float)\n",
    "    image = (image / image.max() * 255).astype('uint8')  # Normalize\n",
    "\n",
    "    # Add marker for classification or create ROI for localization\n",
    "    annotated_image = image.copy()\n",
    "    cv2.circle(annotated_image, (x, y), 10, (255, 0, 0), -1)  # Marker at (x, y)\n",
    "    annotated_image = transform(annotated_image)  # Apply transformations\n",
    "    \n",
    "    images.append(annotated_image)\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert lists to tensors\n",
    "images = torch.stack(images)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(images, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Load and Modify ResNet-50\n",
    "num_classes = 5  # Adjust this based on your specific conditions\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[375], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([label_mapping[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels])\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Create DataLoader\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Load and Modify ResNet-50\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:205\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:206\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m--> 206\u001b[0m         \u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors\n\u001b[0;32m    207\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import models, transforms\n",
    "import pydicom\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_random_3 is already defined and contains the necessary columns\n",
    "# df_random_3 should have the following columns: 'image_path', 'x', 'y', 'condition'\n",
    "\n",
    "# Transformations (including conversion to 3 channels)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3 channels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.485, 0.485], std=[0.229, 0.229, 0.229])  # Normalize for 3 channels\n",
    "])\n",
    "\n",
    "# Preprocess Images and Labels\n",
    "images = []\n",
    "labels = []\n",
    "for _, row in df_random_3.iterrows():\n",
    "    image_path = str(row['image_path']).strip()\n",
    "    if image_path and image_path.lower() != 'nan':\n",
    "        x, y = int(row['x']), int(row['y'])\n",
    "        label = row['condition']\n",
    "        \n",
    "        # Load DICOM image and convert to grayscale uint8\n",
    "        dicom_image = pydicom.dcmread(image_path)\n",
    "        image = dicom_image.pixel_array.astype(float)\n",
    "        image = (image / image.max() * 255).astype('uint8')  # Normalize\n",
    "\n",
    "        # Add marker for classification or create ROI for localization\n",
    "        annotated_image = image.copy()\n",
    "        cv2.circle(annotated_image, (x, y), 10, (255, 0, 0), -1)  # Marker at (x, y)\n",
    "        annotated_image = transform(annotated_image)  # Apply transformations\n",
    "        \n",
    "        images.append(annotated_image)\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert lists to tensors\n",
    "# Map string labels to integers\n",
    "label_mapping = {label: idx for idx, label in enumerate(df_random_3['condition'].unique())}\n",
    "labels = torch.tensor([label_mapping[label] for label in labels])\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(images, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Load and Modify ResNet-50\n",
    "num_classes = 5  # Adjust this based on your specific conditions\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import pydicom\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, mode='classification', box_size=50):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.box_size = box_size\n",
    "\n",
    "    def create_bounding_box(self, x, y, img_shape):\n",
    "        x_min = max(0, int(x - self.box_size / 2))\n",
    "        y_min = max(0, int(y - self.box_size / 2))\n",
    "        x_max = min(img_shape[1], int(x + self.box_size / 2))\n",
    "        y_max = min(img_shape[0], int(y + self.box_size / 2))\n",
    "        return x_min, y_min, x_max, y_max\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        image_path = row['image_path']\n",
    "        x, y = row['x'], row['y']\n",
    "        label = row['condition'] if self.mode == 'classification' else (x, y)\n",
    "\n",
    "        dicom_image = pydicom.dcmread(image_path)\n",
    "        image = dicom_image.pixel_array.astype(float)\n",
    "        image = (image / image.max() * 255).astype('uint8')  # Normalize\n",
    "\n",
    "        if self.mode == 'localization':\n",
    "            x_min, y_min, x_max, y_max = self.create_bounding_box(x, y, image.shape)\n",
    "            roi = image[y_min:y_max, x_min:x_max]\n",
    "            roi = cv2.resize(roi, (224, 224))\n",
    "            image_tensor = self.transform(roi) if self.transform else roi\n",
    "        else:\n",
    "            annotated_image = image.copy()\n",
    "            cv2.circle(annotated_image, (int(x), int(y)), 10, (255, 0, 0), -1)\n",
    "            annotated_image = cv2.resize(annotated_image, (224, 224))\n",
    "            image_tensor = self.transform(annotated_image) if self.transform else annotated_image\n",
    "\n",
    "        # Convert grayscale (1 channel) to RGB (3 channels)\n",
    "        if image_tensor.ndim == 2:\n",
    "            image_tensor = torch.from_numpy(image_tensor).unsqueeze(0)  # Add channel dimension\n",
    "        image_tensor = image_tensor.repeat(3, 1, 1)  # Duplicate to 3 channels\n",
    "\n",
    "        return image_tensor, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "])\n",
    "\n",
    "# Sample Data Setup\n",
    "data = pd.DataFrame({\n",
    "    'image_path': ['data/train_images/1028909382/1477339972/24.dcm'],\n",
    "    'x': [324.88], 'y': [485.87], 'condition': [0]\n",
    "})\n",
    "dataset = MRIDataset(data=data, transform=transform, mode='classification')\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Load ResNet-50 and Set Mode\n",
    "mode = 'classification'  # or 'localization'\n",
    "num_classes = 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "if mode == 'classification':\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "else:\n",
    "    model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() if mode == 'classification' else nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        if mode == 'classification':\n",
    "            loss = criterion(outputs, labels)\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seond try "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with augumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, index):\n",
    "    row = self.data.iloc[index]\n",
    "    image_path = row['image_path']\n",
    "    x, y = row['x'], row['y']\n",
    "    label = row['condition'] if self.mode == 'classification' else (x, y)\n",
    "\n",
    "    dicom_image = pydicom.dcmread(image_path)\n",
    "    image = dicom_image.pixel_array.astype(float)\n",
    "    image = (image / image.max() * 255).astype('uint8')\n",
    "\n",
    "    # Convert grayscale image to 3-channel (RGB)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    if self.mode == 'localization':\n",
    "        x_min, y_min, x_max, y_max = self.create_bounding_box(x, y, image.shape)\n",
    "        roi = image[y_min:y_max, x_min:x_max]\n",
    "        roi = cv2.resize(roi, (224, 224))\n",
    "        image_tensor = self.transform(roi) if self.transform else roi\n",
    "    else:\n",
    "        annotated_image = image.copy()\n",
    "        cv2.circle(annotated_image, (int(x), int(y)), 10, (255, 0, 0), -1)\n",
    "        annotated_image = cv2.resize(annotated_image, (224, 224))\n",
    "        image_tensor = self.transform(annotated_image) if self.transform else annotated_image\n",
    "\n",
    "    return image_tensor, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.7327\n",
      "Epoch [2/10], Loss: 0.4036\n",
      "Epoch [3/10], Loss: 0.0419\n",
      "Epoch [4/10], Loss: 0.0058\n",
      "Epoch [5/10], Loss: 0.0013\n",
      "Epoch [6/10], Loss: 0.0004\n",
      "Epoch [7/10], Loss: 0.0001\n",
      "Epoch [8/10], Loss: 0.0001\n",
      "Epoch [9/10], Loss: 0.0000\n",
      "Epoch [10/10], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "])\n",
    "\n",
    "# Sample Data Setup\n",
    "data = pd.DataFrame({\n",
    "    'image_path': ['data/train_images/1028909382/1477339972/24.dcm'],\n",
    "    'x': [324.88], 'y': [485.87], 'condition': [0]\n",
    "})\n",
    "dataset = MRIDataset(data=data, transform=transform, mode='classification')\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Load ResNet-50 and Set Mode\n",
    "mode = 'classification'  # or 'localization'\n",
    "num_classes = 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "if mode == 'classification':\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "else:\n",
    "    model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() if mode == 'classification' else nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        if mode == 'classification':\n",
    "            loss = criterion(outputs, labels)\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[278], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msss\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sss' is not defined"
     ]
    }
   ],
   "source": [
    "sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plot for images for different samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def display_images_in_grid(df, images_per_row=3, rows=1):\n",
    "    # Calculate the total number of images to display\n",
    "    total_images = images_per_row * rows\n",
    "    \n",
    "    # Filter for the specified range of images\n",
    "    image_paths = df['image_path'].dropna().iloc[:total_images]\n",
    "\n",
    "    # Initialize the figure\n",
    "    fig, axes = plt.subplots(rows, images_per_row, figsize=(20, rows * 3))\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "    \n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        # Load the DICOM image using SimpleITK\n",
    "        image = sitk.ReadImage(image_path)\n",
    "        image_array = sitk.GetArrayFromImage(image)  # Convert to NumPy array\n",
    "        image_array = np.squeeze(image_array)  # Remove single-dimensional entries\n",
    "\n",
    "        # Convert NumPy array to PIL Image\n",
    "        pil_image = Image.fromarray(image_array)\n",
    "        \n",
    "        # Display the image\n",
    "        axes[i].imshow(pil_image, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Turn off any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "display_images_in_grid(df_random_3, images_per_row=2, rows=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Define the Custom Dataset Class\n",
    "\n",
    "    Create Bounding Boxes or Markers: Annotate the images with bounding boxes or markers around the coordinates during preprocessing.\n",
    "    Transform the Images: Ensure that images are resized to fit the ResNet-50 input size (224x224).\n",
    "    Return Annotations: If you plan to use the data for localization, return the bounding box coordinates as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "%pip install torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, mode='classification', box_size=50):\n",
    "        \"\"\"\n",
    "        data: A DataFrame or list containing image paths, coordinates (x, y), and labels.\n",
    "        transform: Transformations to apply to the image.\n",
    "        mode: 'classification' or 'localization'\n",
    "        box_size: Size of bounding box around the (x, y) coordinates.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.box_size = box_size\n",
    "\n",
    "    def create_bounding_box(self, x, y, img_shape):\n",
    "        x_min = max(0, int(x - self.box_size / 2))\n",
    "        y_min = max(0, int(y - self.box_size / 2))\n",
    "        x_max = min(img_shape[1], int(x + self.box_size / 2))\n",
    "        y_max = min(img_shape[0], int(y + self.box_size / 2))\n",
    "        return x_min, y_min, x_max, y_max\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image path, coordinates, and labels\n",
    "        row = self.data.iloc[index]\n",
    "        image_path = row['image_path']\n",
    "        x, y = row['x'], row['y']\n",
    "        label = row['condition'] if self.mode == 'classification' else (x, y)\n",
    "\n",
    "        # Load DICOM image and convert to a grayscale numpy array\n",
    "        dicom_image = pydicom.dcmread(image_path)\n",
    "        image = dicom_image.pixel_array\n",
    "\n",
    "        # Create bounding box around (x, y) coordinates\n",
    "        if self.mode == 'localization':\n",
    "            x_min, y_min, x_max, y_max = self.create_bounding_box(x, y, image.shape)\n",
    "            roi = image[y_min:y_max, x_min:x_max]\n",
    "            roi = cv2.resize(roi, (224, 224))  # Resize ROI to model input size\n",
    "        else:\n",
    "            # Annotate the image for classification\n",
    "            annotated_image = image.copy()\n",
    "            cv2.circle(annotated_image, (int(x), int(y)), 10, (255, 0, 0), -1)\n",
    "            annotated_image = cv2.resize(annotated_image, (224, 224))\n",
    "\n",
    "        # Convert image to PIL format and apply transformations\n",
    "        if self.transform:\n",
    "            if self.mode == 'localization':\n",
    "                image_tensor = self.transform(roi)\n",
    "            else:\n",
    "                image_tensor = self.transform(annotated_image)\n",
    "\n",
    "        return image_tensor, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Define Transformations and Instantiate the DataLoader\n",
    "\n",
    "We’ll use standard transformations for ResNet-50, including resizing and normalization. Here’s how to set up the data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define transformations for ResNet-50\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])  # Assuming grayscale images\n",
    "])\n",
    "\n",
    "# Assuming `data` is a DataFrame containing columns ['image_path', 'x', 'y', 'condition']\n",
    "dataset = MRIDataset(data=df_random_3, transform=transform, mode='classification')  # or 'localization'\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Set Up ResNet-50 for Classification or Localization\n",
    "\n",
    "    Classification: Use ResNet-50’s default architecture with the final layer modified to output the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load ResNet-50 and modify the final layer\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 1)  # Set to number of conditions since i have got only one damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Localization: Modify final layer to output 4 coordinates (x_min, y_min, x_max, y_max)\n",
    "model.fc = nn.Linear(model.fc.in_features, 4)  # Output bounding box coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Training the Model\n",
    "\n",
    "Finally, set up the training loop to handle either classification or localization. For classification, use CrossEntropyLoss. For localization, you can use SmoothL1Loss for bounding box prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = (image_array / image_array.max() * 255).astype(np.uint8)\n",
    "image_array = image_array.astype(np.float32) / image_array.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "num_epochs = 6 # Define the number of epochs\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() if mode == 'classification' else nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example of loading a DICOM image\n",
    "image_path = 'data/train_images/1028909382/1477339972/24.dcm'\n",
    "dicom_image = pydicom.dcmread(image_path)\n",
    "image_array = dicom_image.pixel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample coordinates\n",
    "x, y = 324.887984, 485.865580\n",
    "\n",
    "plt.imshow(image_array, cmap=\"gray\")\n",
    "plt.scatter(x, y, color='red', s=30)  # s controls marker size\n",
    "plt.title(\"MRI with Point Annotation\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "overfit_and_underfit.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
