{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FklhSI0Gg9R"
   },
   "source": [
    "Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import warnings\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from pydicom.data import get_testdata_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    " # Import functions from the module\n",
    "import importlib\n",
    "import help_files._0_definitions \n",
    "import  help_files._1_visuals_script\n",
    "# import  help_files._01_load_data\n",
    " # Reload the module to apply the changes to the script\n",
    "importlib.reload(help_files._0_definitions)\n",
    "importlib.reload(help_files._1_visuals_script)\n",
    "# importlib.reload(help_files._01_load_data)\n",
    "import  help_files._1_visuals_script  as pauls_vs\n",
    "# Group by 'condition', 'level', and 'severity' and count occurrences\n",
    "from help_files._0_definitions import count_severity_by_condition_level \n",
    "# Define the path\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.width\", 1000)  # Set a large width to prevent line wrapping\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "### In definitions are all the functions that are used in the notebook and globals\n",
    "with open(\"help_files/_0_definitions.py\") as file:\n",
    "    exec(file.read())\n",
    "    ### In definitions are all the functions that are used in the notebook and globals\n",
    "with open(\"help_files/_0_run_definitions.py\") as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames have been loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "file_names = [\"train_df_3_cat.csv\", \"test_df_3_cat.csv\"]\n",
    "# Load the data from the CSV files\n",
    "dataframes = [pd.read_csv(data_path_vor / file_name) for file_name in file_names]\n",
    "# Unpack the dataframes into separate variables\n",
    "train_df, test_df = dataframes\n",
    "\n",
    "print(\"DataFrames have been loaded successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "study_id           int64\n",
       "severity         float64\n",
       "condition          int64\n",
       "level             object\n",
       "series_id        float64\n",
       "x                float64\n",
       "y                float64\n",
       "image_path        object\n",
       "missing_image       bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:red\"> this is a small sample : 48692</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # end sample or small sample    \n",
    "if whole_data_set == True:\n",
    "    print(\"Using the whole data set\")\n",
    "else:\n",
    "    train_df = train_df.sample(n=300, random_state=RSEED)\n",
    "    test_df = test_df.sample(n=300, random_state=RSEED)\n",
    "    display(Markdown('<span style=\"color:red\"> this is a small sample : 48692</span>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ttrasformaiton and dataloader (do not change over models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transformation and class\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# %pip install torch torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import pydicom\n",
    "# %pip install opencv-python\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the transform with augmentation: I already tranformed i tbfore \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    #transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    #transforms.RandomRotation(10),       # Randomly rotate the image by Â±10 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color properties\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "        # Ensure severity is in integer format\n",
    "        self.data['severity'] = self.data['severity'].astype(int)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        image_path = row['image_path']\n",
    "        label = row['severity']  # Use severity for the label\n",
    "\n",
    "        dicom_image = pydicom.dcmread(image_path)\n",
    "        image = dicom_image.pixel_array.astype(float)\n",
    "        image = (image / image.max() * 255).astype('uint8')  # Normalize\n",
    "\n",
    "        # Convert the image to RGB if it is grayscale\n",
    "        if len(image.shape) == 2:  # Grayscale\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        # Apply transformations including augmentation\n",
    "        image_tensor = self.transform(image) if self.transform else torch.from_numpy(image).permute(2, 0, 1)\n",
    "\n",
    "        return image_tensor, torch.tensor(label).long()  # Return label as tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training model resnet50 sotp if validation and train go apart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Setting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/HP1/Desktop/Spiced/capstone-project/mlruns/711328181724227740', creation_time=1731147338980, experiment_id='711328181724227740', last_update_time=1731147338980, lifecycle_stage='active', name='Resnet50_class_seg1_seg1_basic', tags={}>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import random\n",
    "# Set random seed for reproducibility\n",
    "seed = 42  # You can choose any integer\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)  # Set seed for numpy\n",
    "random.seed(seed)  # Set seed for random module\n",
    "\n",
    "# Create a new experiment\n",
    "experiment_name = \"Resnet50_class_seg1_seg1_basic\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import models\n",
    "# %pip install keras\n",
    "# %pip install tensorflow\n",
    "# from tensorflow.keras.callbacks import EarlyStopping  # Import EarlyStopping\n",
    "import numpy as np  # Import numpy for setting the random seed\n",
    "\n",
    "# Create the dataset\n",
    "dataset = MRIDataset(data=train_data, transform=transform)\n",
    "\n",
    "# Split the dataset into training and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4,  shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4,  shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    " \n",
    "# Load ResNet-50 and set up for classification\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = train_df['severity'].nunique()\n",
    "\n",
    "model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss functions and optimizer\n",
    "learining_rate = 0.0001 \n",
    "criterion_cel = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learining_rate)\n",
    "num_epochs = 20\n",
    "\n",
    "# Early stopping parameters\n",
    "# Lists to store loss values for plotting\n",
    "train_losses_cel = []\n",
    "val_losses_cel = []\n",
    "\n",
    "# Early stopping parameters\n",
    "diverge_count = 0              # Counter for divergence-based stopping\n",
    "stop_threshold = 0.4           # Threshold for divergence\n",
    "max_diverge_count = 3          # Max number of epochs with diverging validation loss\n",
    "\n",
    "patience_counter = 0           # Counter for plateau-based stopping    \n",
    "patience = 5                   # Number of epochs for validation loss plateau\n",
    "\n",
    "\n",
    "# Calculate number of layers in the model\n",
    "num_layers = len(list(model.children()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* setting mlflow: end running new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7 due to lack of validation loss improvement.\n",
      "Training complete!\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Expected one of the following types:\n- pandas.DataFrame\n- numpy.ndarray\n- dictionary of (name -> numpy.ndarray)\n- scipy.sparse.csr_matrix\n- scipy.sparse.csc_matrix\n- dict\n- list\n- scalars\n- datetime.datetime\nbut got '<class 'torch.Tensor'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[271], line 115\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Log the final model with MLflow\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpytorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinal_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Plot and log the loss curves\u001b[39;00m\n\u001b[0;32m    118\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\mlflow\\pytorch\\__init__.py:296\u001b[0m, in \u001b[0;36mlog_model\u001b[1;34m(pytorch_model, artifact_path, conda_env, code_paths, pickle_module, registered_model_name, signature, input_example, await_registration_for, requirements_file, extra_files, pip_requirements, extra_pip_requirements, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mLog a PyTorch model as an MLflow artifact for the current run.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m    PyTorch logged models\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    295\u001b[0m pickle_module \u001b[38;5;241m=\u001b[39m pickle_module \u001b[38;5;129;01mor\u001b[39;00m mlflow_pytorch_pickle_module\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpytorch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpytorch_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpytorch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequirements_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequirements_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\mlflow\\models\\model.py:726\u001b[0m, in \u001b[0;36mModel.log\u001b[1;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, **kwargs)\u001b[0m\n\u001b[0;32m    722\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mfluent\u001b[38;5;241m.\u001b[39m_get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m    723\u001b[0m mlflow_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    724\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path, run_id\u001b[38;5;241m=\u001b[39mrun_id, metadata\u001b[38;5;241m=\u001b[39mmetadata, resources\u001b[38;5;241m=\u001b[39mresources\n\u001b[0;32m    725\u001b[0m )\n\u001b[1;32m--> 726\u001b[0m \u001b[43mflavor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result in\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# __pycache__ directories being created in the model directory.\u001b[39;00m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pycache \u001b[38;5;129;01min\u001b[39;00m Path(local_path)\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pycache__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\mlflow\\pytorch\\__init__.py:446\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(pytorch_model, path, conda_env, mlflow_model, code_paths, pickle_module, signature, input_example, requirements_file, extra_files, pip_requirements, extra_pip_requirements, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mlflow_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     mlflow_model \u001b[38;5;241m=\u001b[39m Model()\n\u001b[1;32m--> 446\u001b[0m saved_example \u001b[38;5;241m=\u001b[39m \u001b[43m_save_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m saved_example \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m     wrapped_model \u001b[38;5;241m=\u001b[39m _PyTorchWrapper(pytorch_model, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\mlflow\\models\\utils.py:514\u001b[0m, in \u001b[0;36m_save_example\u001b[1;34m(mlflow_model, input_example, path, no_conversion)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_conversion \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `example_no_conversion` parameter is deprecated since mlflow 2.16.0 and will be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremoved in a future release. This parameter is no longer used and safe to be removed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    512\u001b[0m     )\n\u001b[1;32m--> 514\u001b[0m example \u001b[38;5;241m=\u001b[39m \u001b[43m_Example\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m example\u001b[38;5;241m.\u001b[39msave(path)\n\u001b[0;32m    516\u001b[0m mlflow_model\u001b[38;5;241m.\u001b[39msaved_input_example_info \u001b[38;5;241m=\u001b[39m example\u001b[38;5;241m.\u001b[39minfo\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\mlflow\\models\\utils.py:372\u001b[0m, in \u001b[0;36m_Example.__init__\u001b[1;34m(self, input_example)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserving_input \u001b[38;5;241m=\u001b[39m {INPUTS: model_input}\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException\u001b[38;5;241m.\u001b[39minvalid_parameter_value(\n\u001b[0;32m    373\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected one of the following types:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    374\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- pandas.DataFrame\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    375\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- numpy.ndarray\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- dictionary of (name -> numpy.ndarray)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- scipy.sparse.csr_matrix\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- scipy.sparse.csc_matrix\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- dict\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- list\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- scalars\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- datetime.datetime\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    384\u001b[0m     )\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m    Save input data and params with their respective keys, so we can load them separately.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mMlflowException\u001b[0m: Expected one of the following types:\n- pandas.DataFrame\n- numpy.ndarray\n- dictionary of (name -> numpy.ndarray)\n- scipy.sparse.csr_matrix\n- scipy.sparse.csc_matrix\n- dict\n- list\n- scalars\n- datetime.datetime\nbut got '<class 'torch.Tensor'>'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import models\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create the dataset and DataLoader\n",
    "dataset = MRIDataset(data=train_data, transform=transform)\n",
    "\n",
    "# Split the dataset into training and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "# Load ResNet-50 and set up for classification\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = train_df['severity'].nunique()\n",
    "\n",
    "model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    " \n",
    "# Lists to store loss values for plotting\n",
    "train_losses_cel = []\n",
    "val_losses_cel = []\n",
    "\n",
    "# Start MLflow UI and log parameters\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"learning_rate\", 'learining_rate')\n",
    "    mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "    mlflow.log_param(\"batch_size\", 'batch_size')\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"num_classes\", num_classes)\n",
    "    mlflow.log_param(\"model_architecture\", \"ResNet-50\")\n",
    "    \n",
    "    # Log early stopping parameters\n",
    "    mlflow.log_param(\"stop_threshold\", stop_threshold)\n",
    "    mlflow.log_param(\"max_diverge_count\", max_diverge_count)\n",
    "    mlflow.log_param(\"patience\", patience)\n",
    "\n",
    "    # Example input tensor for logging the model with MLflow\n",
    "    example_input = torch.randn(1, 3, 224, 224)  # Batch size 1, 3 color channels, 224x224 image\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    diverge_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss_cel_train = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss_cel = criterion_cel(outputs, labels)\n",
    "            running_loss_cel_train += loss_cel.item()\n",
    "            \n",
    "            loss_cel.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss_cel_train = running_loss_cel_train / len(train_loader)\n",
    "        train_losses_cel.append(epoch_loss_cel_train)\n",
    "        mlflow.log_metric(\"train_loss_cel\", epoch_loss_cel_train, step=epoch)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss_cel_val = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss_cel = criterion_cel(outputs, labels)\n",
    "                running_loss_cel_val += loss_cel.item()\n",
    "\n",
    "        epoch_loss_cel_val = running_loss_cel_val / len(val_loader)\n",
    "        val_losses_cel.append(epoch_loss_cel_val)\n",
    "        mlflow.log_metric(\"val_loss_cel\", epoch_loss_cel_val, step=epoch)\n",
    "\n",
    "        # Early stopping checks\n",
    "        if epoch_loss_cel_val > epoch_loss_cel_train * (1 + stop_threshold):\n",
    "            diverge_count += 1\n",
    "            if diverge_count >= max_diverge_count:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} due to validation loss diverging.\")\n",
    "                break\n",
    "        else:\n",
    "            diverge_count = 0  # Reset diverge count if validation loss is not diverging\n",
    "\n",
    "        if epoch_loss_cel_val < best_val_loss:\n",
    "            best_val_loss = epoch_loss_cel_val\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), \"best_model_weights.pt\")\n",
    "            mlflow.log_artifact(\"best_model_weights.pt\")\n",
    "            os.remove(\"best_model_weights.pt\")\n",
    "\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} due to lack of validation loss improvement.\")\n",
    "                break\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    # Log the final model with MLflow\n",
    "    mlflow.pytorch.log_model(model, \"final_model\", input_example=example_input)\n",
    "\n",
    "    # Plot and log the loss curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses_cel, label='Train Cross Entropy Loss')\n",
    "    plt.plot(val_losses_cel, label='Validation Cross Entropy Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Cross Entropy Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"cross_entropy_loss.png\")\n",
    "    mlflow.log_artifact(\"cross_entropy_loss.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP1\\AppData\\Local\\Temp\\ipykernel_3704\\149900289.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'{pathtoepoch}/model_weights_epoch_1.pt'))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/HP1/Desktop/Spiced/capstone-project/mlruns/711328181724227740/accfff0beaff48bf9b63a338346cfe64/artifacts/model_weights_epoch_1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[272], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Step 2: Load the weights into the model\u001b[39;00m\n\u001b[0;32m     12\u001b[0m pathtoepoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/HP1/Desktop/Spiced/capstone-project/mlruns/711328181724227740/accfff0beaff48bf9b63a338346cfe64/artifacts\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpathtoepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/model_weights_epoch_1.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Step 3: Check loaded weights (optional)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Print the modelâs state dictionary\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mstate_dict()\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torch\\serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torch\\serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\HP1\\Desktop\\Spiced\\capstone-project\\.venv\\Lib\\site-packages\\torch\\serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/HP1/Desktop/Spiced/capstone-project/mlruns/711328181724227740/accfff0beaff48bf9b63a338346cfe64/artifacts/model_weights_epoch_1.pt'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models  # or your own model class\n",
    "\n",
    "# Step 1: Define your model architecture\n",
    "# Example with ResNet-50 (replace with your model if different)\n",
    "model = models.resnet50()\n",
    "\n",
    "# Redefine the final fully connected layer to match the shape of the weights being loaded\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 3)\n",
    "\n",
    "# Step 2: Load the weights into the model\n",
    "pathtoepoch = \"C:/Users/HP1/Desktop/Spiced/capstone-project/mlruns/711328181724227740/accfff0beaff48bf9b63a338346cfe64/artifacts\"\n",
    "model.load_state_dict(torch.load(f'{pathtoepoch}/model_weights_epoch_1.pt'))\n",
    "\n",
    "# Step 3: Check loaded weights (optional)\n",
    "# Print the modelâs state dictionary\n",
    "for name, param in model.state_dict().items():\n",
    "    print(name, param.shape)  # Shows layer name and parameter shape\n",
    "\n",
    "# Now, model contains weights from epoch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"runs:/<run_id>/artifacts/best_model_weights.pt\"\n",
    "model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sssss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"learning_rate\", 0.0001)\n",
    "    mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "    mlflow.log_param(\"batch_size\", 4)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"num_classes\", num_classes)\n",
    "    mlflow.log_param(\"model_architecture\", \"ResNet-50\")\n",
    "    mlflow.log_param(\"input_size\", \"224x224\")\n",
    "    mlflow.log_param(\"num_layers\", num_layers)\n",
    "    mlflow.log_param(\"activation_function\", \"ReLU\")\n",
    "    mlflow.log_param(\"pretrained_weights\", \"IMAGENET1K_V1\")\n",
    "\n",
    "    # Log early stopping parameters\n",
    "    mlflow.log_param(\"stop_threshold\", stop_threshold)\n",
    "    mlflow.log_param(\"max_diverge_count\", max_diverge_count)\n",
    "    mlflow.log_param(\"patience\", patience)\n",
    "\n",
    "# Set descriptive tags for the model\n",
    "    mlflow.set_tag(\"model_description\", \"ResNet-50 for 3 cat and Sagittal T2/STIR and Sagittal T1 images \")\n",
    "\n",
    "     # Example input tensor with the same shape as the model's expected input\n",
    "    example_input = torch.randn(1, 3, 224, 224)  # Batch size 1, 3 color channels, 224x224 image\n",
    "\n",
    "  \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss_cel_train = 0.0\n",
    "        running_loss_mse_train = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Cross Entropy Loss\n",
    "            loss_cel = criterion_cel(outputs, labels)\n",
    "            running_loss_cel_train += loss_cel.item()\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss_cel.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate average losses\n",
    "        epoch_loss_cel_train = running_loss_cel_train / len(train_loader)\n",
    "        train_losses_cel.append(epoch_loss_cel_train)\n",
    "\n",
    "        # Log training losses to MLflow\n",
    "        mlflow.log_metric(\"train_loss_cel\", epoch_loss_cel_train, step=epoch)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss_cel_val = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Cross Entropy Loss for validation\n",
    "                loss_cel = criterion_cel(outputs, labels)\n",
    "                running_loss_cel_val += loss_cel.item()\n",
    "                \n",
    "        # Calculate validation losses\n",
    "        epoch_loss_cel_val = running_loss_cel_val / len(val_loader)\n",
    "        val_losses_cel.append(epoch_loss_cel_val)\n",
    "\n",
    "        # Log validation losses to MLflow\n",
    "        mlflow.log_metric(\"val_loss_cel\", epoch_loss_cel_val, step=epoch)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "              f'Train Cross Entropy Loss: {epoch_loss_cel_train:.4f}, '\n",
    "              f'Validation Cross Entropy Loss: {epoch_loss_cel_val:.4f}')\n",
    "\n",
    "        # Check for early stopping (divergence-based stopping)\n",
    "        if epoch_loss_cel_val > epoch_loss_cel_train * (1 + stop_threshold):\n",
    "            diverge_count += 1\n",
    "            if diverge_count >= max_diverge_count:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} due to validation loss diverging.\")\n",
    "                break\n",
    "        else:\n",
    "            diverge_count = 0  # Reset diverge count if validation loss is not diverging        \n",
    "\n",
    "        # Check for early stopping (plateau-based stopping)\n",
    "        best_val_loss = float('inf')   # Initialize best validation loss\n",
    "        if epoch_loss_cel_val < best_val_loss:\n",
    "            best_val_loss = epoch_loss_cel_val\n",
    "            patience_counter = 0  # Reset plateau counter if validation loss improves\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} due to lack of validation loss improvement.\")\n",
    "                break\n",
    "        mlflow.log_metric(\"train_loss\", epoch_loss_train, step=epoch)        \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    # Convert example_input to numpy array\n",
    "    example_input_np = example_input.numpy()\n",
    "\n",
    "    # Log the model with input_example\n",
    "    mlflow.pytorch.log_model(model, \"model\", input_example=example_input_np)\n",
    "    \n",
    "    # Plot and log the loss curves as artifacts\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses_cel, label='Train Cross Entropy Loss')\n",
    "    plt.plot(val_losses_cel, label='Validation Cross Entropy Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Cross Entropy Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"cross_entropy_loss.png\")\n",
    "    mlflow.log_artifact(\"cross_entropy_loss.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chek if everything is logged and correct from the run\n",
    "import mlflow.pytorch\n",
    "\n",
    "# Load the model from the specified run ID and path\n",
    "# Replace <run_id> with your actual run ID and <path_to_model> with the artifact path used during logging\n",
    "loaded_model = mlflow.pytorch.load_model(\"runs:/42e13270009f41ba9ce5ea89e851e35f/model\")\n",
    "\n",
    "# Print model parameters to verify\n",
    "print(loaded_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore parameters and metrtics from mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should take prdicted probabilities and not predicted classes: output scores (logits) are converted into probabilities using the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experiment name\n",
    "experiment_name = \"711328181724227740\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Specify the run ID of the logged model\n",
    "run_id = \"42e13270009f41ba9ce5ea89e851e35f\"  # Replace with your actual run ID\n",
    "model_uri = f\"runs:/{run_id}/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class definition\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import pydicom\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))  # Move model to appropriate device\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Prepare data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.data['severity'] = self.data['severity'].astype(int)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        image_path = row['image_path']\n",
    "        label = row['severity']\n",
    "        dicom_image = pydicom.dcmread(image_path)\n",
    "        image = dicom_image.pixel_array.astype(float)\n",
    "        image = (image / image.max() * 255).astype('uint8')\n",
    "        if len(image.shape) == 2:  # Grayscale\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        image_tensor = self.transform(image) if self.transform else torch.from_numpy(image).permute(2, 0, 1)\n",
    "        return image_tensor, torch.tensor(label).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicting probabilities for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate prbabilities and probability list\n",
    "test_dataset = MRIDataset(data=test_data, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Inference loop with probability extraction\n",
    "results = []\n",
    "probabilities_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)  # Ensure labels are also on the correct device\n",
    "        outputs = model(images)\n",
    "        probabilities = torch.softmax(outputs, dim=1)  # Calculate class probabilities\n",
    "        _, predicted_classes = torch.max(outputs, 1)\n",
    "        \n",
    "        # Append predictions and probabilities\n",
    "        results.append(predicted_classes.item())\n",
    "        probabilities_list.append(probabilities.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print predicted classes and their probabilities\n",
    "for i, (pred, probs) in enumerate(zip(results, probabilities_list)):\n",
    "    print(f\"Test image {i}: Predicted class {pred}, Probabilities: {probs}\")\n",
    "\n",
    "# Additional code to plot the confusion matrix can stay as-is:\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    true_labels.extend(labels.numpy())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predicted_classes = torch.max(outputs, 1)\n",
    "        predicted_labels.extend(predicted_classes.cpu().numpy())\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "print(\"True Labels Unique Values:\", np.unique(true_labels))\n",
    "print(\"Predicted Labels Unique Values:\", np.unique(predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of probabilities to a numpy array for easier manipulation\n",
    "probabilities_array = np.vstack(probabilities_list)\n",
    "\n",
    "# Ensure the length of probabilities_array matches the length of test_df\n",
    "probabilities_array = probabilities_array[:len(test_df)]\n",
    "\n",
    "# Add the probabilities to the test_df DataFrame\n",
    "test_df['Probability_Class_0'] = probabilities_array[:, 0]\n",
    "test_df['Probability_Class_1'] = probabilities_array[:, 1]\n",
    "test_df['Probability_Class_2'] = probabilities_array[:, 2]\n",
    "\n",
    "# Round the probabilities to 4 decimal places\n",
    "test_df['Probability_Class_0'] = test_df['Probability_Class_0'].round(4)\n",
    "test_df['Probability_Class_1'] = test_df['Probability_Class_1'].round(4)\n",
    "test_df['Probability_Class_2'] = test_df['Probability_Class_2'].round(4)\n",
    "# Add the predicted classes to the test_df DataFrame\n",
    "test_df['Predicted_Class'] = results\n",
    "\n",
    "\n",
    "\n",
    "# Display the updated DataFrame\n",
    " \n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by severity and sum the Probability_Class_1\n",
    "severity_prob_sum_all_classes = test_df.groupby('severity')[['Probability_Class_0', 'Probability_Class_1', 'Probability_Class_2']].mean()\n",
    "\n",
    "# Print the result\n",
    "severity_prob_sum_all_classes\n",
    "# Use severity_prob_sum_all_classes as confusion matrix\n",
    "conf_matrix_prob_df = severity_prob_sum_all_classes \n",
    "# Create a confusion matrix from severity and predicted class\n",
    "conf_matrix_severity_pred = confusion_matrix(test_df['severity'], test_df['Predicted_Class'])\n",
    "\n",
    "# Create a DataFrame from the confusion matrix\n",
    "conf_matrix_severity_pred_df = pd.DataFrame(\n",
    "    conf_matrix_severity_pred, \n",
    "    index=[f\"Actual {i}\" for i in range(len(conf_matrix_severity_pred))], \n",
    "    columns=[f\"Predicted {i}\" for i in range(len(conf_matrix_severity_pred[0]))]\n",
    ")\n",
    "\n",
    "# Print the confusion matrix DataFrame\n",
    "print(conf_matrix_severity_pred_df)\n",
    "\n",
    "# Optionally, display it using a more formatted view (e.g., in Jupyter Notebook)\n",
    "conf_matrix_severity_pred_df.style.background_gradient(cmap='Blues')\n",
    "# Print the confusion matrix DataFrame\n",
    "print(conf_matrix_prob_df)\n",
    "\n",
    "# Optionally, display it using a more formatted view (e.g., in Jupyter Notebook)\n",
    "conf_matrix_prob_df.style.background_gradient(cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_severity_pred_df.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure true_labels and predicted_labels have the same length\n",
    "min_length = min(len(true_labels), len(predicted_labels))\n",
    "true_labels = true_labels[:min_length]\n",
    "predicted_labels = predicted_labels[:min_length]\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix\n",
    "conf_matrix_df = pd.DataFrame(\n",
    "    conf_matrix, \n",
    "    index=[f\"Actual {i}\" for i in range(len(conf_matrix))], \n",
    "    columns=[f\"Predicted {i}\" for i in range(len(conf_matrix[0]))]\n",
    ")\n",
    "\n",
    "# Print the confusion matrix DataFrame\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Optionally, display it using a more formatted view (e.g., in Jupyter Notebook)\n",
    "conf_matrix_df.style.background_gradient(cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "# Calculate precision, recall, and accuracy using mean_probabilities_df\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "overfit_and_underfit.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
